{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 76,
=======
   "execution_count": 1,
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from Models import get_model\n",
    "from Process import *\n",
    "import torch.nn.functional as F\n",
    "from Optim import CosineWithRestarts\n",
    "from Batch import create_masks\n",
    "import dill as pickle\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import os\n",
    "import whoosh, glob, time, pickle\n",
    "import whoosh.fields as wf\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import index\n",
    "import threading\n",
    "from whoosh import filedb\n",
    "from whoosh.filedb.filestore import FileStorage\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from InMemorySearch import *\n",
    "from client import *\n",
<<<<<<< HEAD
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from logger import Logger\n",
    "logger = Logger('./logs')"
=======
    "from pathlib import Path"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#At first checking our super clients\n",
    "# query_list = [\"european crime records\", \"crime records\", \"european crime\", \"european records\", \"crime crimes violent sheriff enforcement re criminals stresak bill strikes\", \"LA times corpus\", \"crime records\"]    \n",
    "# super_client = SuperClient()\n",
    "# print(super_client.hosts)\n",
    "# final_result = super_client.query_expansion_distributed(query_list)\n",
    "# print(len(final_result))"
=======
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.141.0.104', '10.141.0.146', '10.141.0.134', '10.141.0.120', '10.141.0.121']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#At first checking our super clients\n",
    "query_list = [\"european crime records\", \"crime records\", \"european crime\", \"european records\", \"crime crimes violent sheriff enforcement re criminals stresak bill strikes\", \"LA times corpus\", \"crime records\"]    \n",
    "super_client = SuperClient()\n",
    "print(super_client.hosts)\n",
    "final_result = super_client.query_expansion_distributed(query_list)\n",
    "print(len(final_result))"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 78,
=======
   "execution_count": 3,
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 79,
=======
   "execution_count": 4,
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#If we are working on small dataset\n",
    "small = 0\n",
    "#If we want to activate relevance based training\n",
    "relevance_training = 0\n",
    "    \n",
    "if small==1:\n",
    "    parser.add_argument('-src_data', type=str, default='data/italian_small.txt')\n",
    "    parser.add_argument('-trg_data', type=str, default='data/english_small.txt')\n",
    "    parser.add_argument('-trg_data_retrieval', type=str, default='data/english_retrieval.txt')\n",
    "\n",
    "else:\n",
    "    parser.add_argument('-src_data', type=str, default='data/italian.txt')\n",
    "    parser.add_argument('-trg_data', type=str, default='data/english.txt')  \n",
    "    parser.add_argument('-trg_data_retrieval', type=str, default='data/LATIMESTEXT2.txt')\n",
<<<<<<< HEAD
    "    parser.add_argument('-rm_data', type=str, default='data/english_rm.txt') ##\n",
=======
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "\n",
    "parser.add_argument('-src_lang', type=str, default='it')\n",
    "parser.add_argument('-trg_lang', type=str, default='en')\n",
    "parser.add_argument('-no_cuda', action='store_true')\n",
    "parser.add_argument('-SGDR', action='store_true')\n",
<<<<<<< HEAD
    "parser.add_argument('-epochs', type=int, default=10)\n",
=======
    "parser.add_argument('-epochs', type=int, default=1)\n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "parser.add_argument('-d_model', type=int, default=200)\n",
    "parser.add_argument('-n_layers', type=int, default=6)\n",
    "parser.add_argument('-heads', type=int, default=8)\n",
    "parser.add_argument('-dropout', type=int, default=0.1)\n",
    "parser.add_argument('-batchsize', type=int, default=1000)\n",
<<<<<<< HEAD
    "parser.add_argument('-printevery', type=int, default=5)\n",
=======
    "parser.add_argument('-printevery', type=int, default=50)\n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "parser.add_argument('-load_vocab', type=str, default='clir_it_en')\n",
    "\n",
    "if relevance_training == 1:\n",
    "    my_file = Path(\"weights/model_weights\")\n",
    "    if my_file.is_file():\n",
    "        parser.add_argument('-load_weights', type=str, default='weights')\n",
    "    else:\n",
    "        parser.add_argument('-load_weights', type=str, default=None)\n",
    "    parser.add_argument('-lr', type=int, default=0.01)\n",
    "else: \n",
    "    my_file = Path(\"weights/model_weights\")\n",
    "    if my_file.is_file():\n",
    "        parser.add_argument('-load_weights', type=str, default='weights')\n",
    "    else:\n",
    "        parser.add_argument('-load_weights', type=str, default=None)         \n",
    "    parser.add_argument('-lr', type=int, default=0.0001)\n",
    "    \n",
    "parser.add_argument('-create_valset', action='store_true')\n",
    "parser.add_argument('-max_strlen', type=int, default=80)\n",
    "parser.add_argument('-floyd', action='store_true')\n",
    "parser.add_argument('-checkpoint', type=int, default=5)\n",
    "\n",
    "opt = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 80,
=======
   "execution_count": 5,
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):  # create a tokenizer function\n",
    "    return text.split()\n",
    "    \n",
    "def create_fields(opt):    \n",
    "    print(\"loading tokenizers...\") \n",
    "    TRG = data.Field(lower=True, tokenize=tokenizer, init_token='<sos>', eos_token='<eos>')\n",
<<<<<<< HEAD
    "    TRG_REL = data.Field(lower=True, tokenize=tokenizer, init_token='<sos>', eos_token='<eos>')    \n",
    "    #RM = data.Field(lower=True, tokenize=tokenizer, init_token='<sos>', eos_token='<eos>') ##     \n",
    "    SRC = data.Field(lower=True, tokenize=tokenizer)   \n",
    "    SRC = pickle.load(open(f'{opt.load_vocab}/SRC.pkl', 'rb'))\n",
    "    TRG = pickle.load(open(f'{opt.load_vocab}/TRG.pkl', 'rb'))\n",
    "    TRG_REL = pickle.load(open(f'{opt.load_vocab}/TRG.pkl', 'rb'))\n",
    "    return(SRC, TRG, TRG_REL)\n",
    "\n",
    "#this function will consider both europarl and CLEF\n",
    "def create_dataset(opt, SRC, TRG, TRG_REL):\n",
    "    print(\"creating dataset and iterator... \")\n",
    "    translation_data = [line for line in opt.trg_data] ###\n",
    "    relevance_data = [line for line in open(opt.rm_data)] ###    \n",
    "    \n",
    "    raw_data = {'src' : [line.strip() for line in opt.src_data], 'trg': translation_data, 'trg_rel': relevance_data} ###  \n",
    "    raw_data_retrieval = {'trg': [line for line in opt.trg_data_retrieval]}\n",
    "    \n",
    "    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\", \"trg_rel\"])\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(use_idf=True)\n",
    "    vectorizer.fit_transform(raw_data['trg'] + raw_data_retrieval['trg'])\n",
    "    \n",
    "    tokens = vectorizer.get_feature_names()\n",
    "    idf_values = vectorizer.idf_\n",
    "    opt.idf_dict = {}\n",
    "     \n",
    "    for i in range(len(tokens)):\n",
    "        opt.idf_dict.setdefault(tokens[i],idf_values[i]) \n",
    "    \n",
=======
    "    SRC = data.Field(lower=True, tokenize=tokenizer)   \n",
    "    SRC = pickle.load(open(f'{opt.load_vocab}/SRC.pkl', 'rb'))\n",
    "    TRG = pickle.load(open(f'{opt.load_vocab}/TRG.pkl', 'rb'))\n",
    "    return(SRC, TRG)\n",
    "\n",
    "#this function will consider both europarl and CLEF\n",
    "def create_dataset(opt, SRC, TRG):\n",
    "    print(\"creating dataset and iterator... \")\n",
    "    \n",
    "    raw_data = {'src' : [line for line in opt.src_data], 'trg': [line for line in opt.trg_data]}\n",
    "    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\"])\n",
    "\n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "    mask = (df['src'].str.count(' ') < opt.max_strlen) & (df['trg'].str.count(' ') < opt.max_strlen)\n",
    "    df = df.loc[mask]\n",
    "\n",
    "    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n",
    "\n",
<<<<<<< HEAD
    "    data_fields = [('src', SRC), ('trg', TRG) , ('trg_rel', TRG_REL)]\n",
    "    \n",
=======
    "    data_fields = [('src', SRC), ('trg', TRG)]\n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n",
    "\n",
    "    train_iter = MyIterator(train, batch_size=opt.batchsize, device=opt.device,\n",
    "                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                        batch_size_fn=batch_size_fn, train=True, shuffle=True)\n",
    "      \n",
    "    os.remove('translate_transformer_temp.csv')   \n",
    "    \n",
    "    if opt.load_vocab is None:\n",
    "        print(\"creating dataset for retrieval corpus... \")\n",
    "        raw_data = {'trg': [line for line in opt.trg_data_retrieval]}\n",
    "        df = pd.DataFrame(raw_data, columns=[\"trg\"])\n",
    "        mask = (df['trg'].str.count(' ') > 1)\n",
    "        df = df.loc[mask]\n",
    "        df.to_csv(\"translate_transformer_retrieval_temp.csv\", index=False)\n",
    "        data_fields = [('trg', TRG)]\n",
    "        train_retrieval = data.TabularDataset('./translate_transformer_retrieval_temp.csv', format='csv', fields=data_fields)\n",
    "        os.remove('translate_transformer_retrieval_temp.csv')    \n",
    "\n",
    "        print(\"building vocabulary for both europarl and retrieval corpus\")\n",
    "\n",
    "        SRC.build_vocab(train)\n",
    "        TRG.build_vocab(train, train_retrieval)\n",
    "\n",
    "    opt.src_pad = SRC.vocab.stoi['<pad>']\n",
    "    opt.trg_pad = TRG.vocab.stoi['<pad>']\n",
<<<<<<< HEAD
    "    opt.trg_pad = TRG.vocab.stoi['<pad>']\n",
    "    \n",
=======
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "    opt.train_len = get_len(train_iter)\n",
    "    return train_iter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 81,
=======
   "execution_count": 6,
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loading tokenizers...\n",
<<<<<<< HEAD
      "creating dataset and iterator... \n",
      "1894217\n",
      "1894217\n"
=======
      "creating dataset and iterator... \n"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
=======
      "loading pretrained weights...\n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
      "model weights will be saved every 5 minutes and at end of epoch to directory weights/\n"
     ]
    }
   ],
   "source": [
    "opt.device = 0 if opt.no_cuda is False else -1\n",
    "if opt.device == 0:\n",
    "    assert torch.cuda.is_available()\n",
    "print(opt.device)\n",
    "read_data(opt)\n",
    "\n",
<<<<<<< HEAD
    "SRC, TRG, TRG_REL = create_fields(opt)\n",
    "opt.train = create_dataset(opt, SRC, TRG, TRG_REL)\n",
    "dst = ''\n",
    "#TRG = create_retrieval_vocabulary(opt, TRG)\n",
=======
    "SRC, TRG = create_fields(opt)\n",
    "opt.train = create_dataset(opt, SRC, TRG)\n",
    "dst = ''\n",
    "#TRG = create_retrieval_vocabulary(opt, TRG)\n",
    "model = get_model(opt, len(SRC.vocab), len(TRG.vocab))\n",
    "\n",
    "opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "if opt.SGDR == True:\n",
    "    opt.sched = CosineWithRestarts(opt.optimizer, T_max=opt.train_len)\n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "\n",
    "if opt.checkpoint > 0:\n",
    "    print(\"model weights will be saved every %d minutes and at end of epoch to directory weights/\"%(opt.checkpoint))\n",
    "    \n",
    "if opt.load_vocab is None:\n",
    "    pickle.dump(SRC, open(f'{dst}/SRC.pkl', 'wb'))\n",
    "    pickle.dump(TRG, open(f'{dst}/TRG.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained weights...\n",
      "<unk>\n",
      "240229\n"
     ]
    }
   ],
   "source": [
    "model = get_model(opt, len(SRC.vocab), len(TRG.vocab))\n",
    "opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "if opt.SGDR == True:\n",
    "    opt.sched = CosineWithRestarts(opt.optimizer, T_max=opt.train_len)\n",
    "    \n",
    "import subprocess \n",
    "super_client = SuperClient()\n",
    "print(TRG.vocab.itos[0])\n",
    "print(len(TRG.vocab))\n",
    "opt.idf_dict[\"<sos>\"] = 1\n",
    "opt.idf_dict[\"<eos>\"] = 1\n",
    "class_weights = []\n",
    "for i in range(len(TRG.vocab)):\n",
    "    if TRG.vocab.itos[i] in opt.idf_dict:\n",
    "        class_weights.append(opt.idf_dict[TRG.vocab.itos[i]])\n",
    "    else:\n",
    "        class_weights.append(0.0001)\n",
    "class_weights = torch.FloatTensor(class_weights)"
=======
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_client = SuperClient()"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.checkpoint = 1\n",
    "def train_model(model, opt, SRC, TRG):\n",
    "    torch.cuda.empty_cache()\n",
    "    best_mAP = 0.15\n",
    "    inmem = WhooshInMemorySearch()\n",
    "    print(\"training model...\")\n",
    "    opt.idf_dict[\"<sos>\"] = 1\n",
    "    opt.idf_dict[\"<eos>\"] = 1\n",
    "    class_weights = []\n",
    "    for i in range(len(TRG.vocab)):\n",
    "        if TRG.vocab.itos[i] in opt.idf_dict:\n",
    "            class_weights.append(opt.idf_dict[TRG.vocab.itos[i]])            \n",
    "        else:\n",
    "            class_weights.append(0.0001)\n",
    "    \n",
    "    class_weights = torch.FloatTensor(class_weights)\n",
    "    model.train()\n",
    "    class_weights = class_weights.cuda()\n",
    "    start = time.time()\n",
    "    if opt.checkpoint > 0:\n",
    "        cptime = time.time()\n",
    "    \n",
    "    global_step = 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        #print(\"beginning epoch:\")\n",
    "        total_loss = 0\n",
    "        \n",
    "        #print(\"   %dm: epoch %d [%s]  %d%%  loss = %s\" %\\\n",
    "        #((time.time() - start)//60, epoch + 1, \"\".join(' '*20), 0, '...'), end='\\r')\n",
    "\n",
=======
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, opt, SRC, TRG):\n",
    "    torch.cuda.empty_cache()\n",
    "    inmem = WhooshInMemorySearch()\n",
    "    print(\"training model...\")\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    if opt.checkpoint > 0:\n",
    "        cptime = time.time()\n",
    "                    \n",
    "    for epoch in range(opt.epochs):\n",
    "        total_loss = 0\n",
    "        if opt.floyd is False:\n",
    "            print(\"   %dm: epoch %d [%s]  %d%%  loss = %s\" %\\\n",
    "            ((time.time() - start)//60, epoch + 1, \"\".join(' '*20), 0, '...'), end='\\r')\n",
    "        \n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "        if opt.checkpoint > 0:\n",
    "            torch.save(model.state_dict(), 'weights/model_weights')\n",
    "                    \n",
    "        for i, batch in enumerate(opt.train):\n",
    "            torch.cuda.empty_cache()\n",
    "            start = time.clock()\n",
    "            src = batch.src.transpose(0,1) # src_size = (187, 4)\n",
    "            trg = batch.trg.transpose(0,1) # trg_size = (187, 8)             \n",
<<<<<<< HEAD
    "#             trg_idf = [[opt.idf_dict[TRG.vocab.itos[ind]] for ind in ex] for ex in trg]\n",
    "#             trg_idf = np.array(trg_idf)\n",
    "#             trg_idf = torch.FloatTensor(trg_idf)\n",
    "            #print (trg_idf.size())\n",
    "            \n",
    "            if relevance_training == 1:\n",
    "                trg_strings = [' '.join([TRG.vocab.itos[ind] for ind in ex]) for ex in trg]               \n",
    "                trg_strings_rm = super_client.query_expansion_distributed(trg_strings)                \n",
=======
    "            if relevance_training == 1:\n",
    "                trg_strings = [' '.join([TRG.vocab.itos[ind] for ind in ex]) for ex in trg]\n",
    "                trg_strings_rm = super_client.query_expansion_distributed(trg_strings)\n",
    "                \n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "                trg_strings_rm_id = torch.LongTensor([[TRG.vocab.stoi[token] for token in sentence] for sentence in trg_strings_rm]).cuda()            \n",
    "                \n",
    "                embed_trg = model.decoder.embed(trg_strings_rm_id)\n",
    "                #old loss\n",
    "                #embed_trg = embed_trg.view(embed_trg.size(0), -1)\n",
    "                #new loss \n",
    "                embed_trg = embed_trg.sum(1)\n",
    "            \n",
<<<<<<< HEAD
    "            \n",
=======
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "            trg_input = trg[:, :-1]\n",
    "            src_mask, trg_mask = create_masks(src, trg_input, opt)            \n",
    "            src_mask = src_mask.cuda()            \n",
    "            trg_mask = trg_mask.cuda()\n",
    "            src = src.cuda() \n",
    "            trg_input = trg_input.cuda()                                  \n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            \n",
    "            #the goal is to find the embedding of the predictions \n",
    "            if relevance_training == 1: \n",
    "                out = F.softmax(preds, dim=-1)\n",
    "                probs, ix = out[:, :].data.topk(1)\n",
    "                preds_token_ids = ix.view(ix.size(0), -1)\n",
    "                #new loss function \n",
    "                embed_pred = model.decoder.embed(preds_token_ids)\n",
    "                embed_pred = embed_pred.sum(1)\n",
    "                #print(\"embed preds size \" + str(embed_pred_sum.size()))            \n",
    "\n",
    "                #old loss function\n",
    "#                 pred_strings = [' '.join([TRG.vocab.itos[ind] for ind in ex]) for ex in preds_token_ids]\n",
    "#                 pred_strings_rm = super_client.query_expansion_distributed(pred_strings)                                \n",
    "#                 pred_strings_rm_id = torch.LongTensor([[TRG.vocab.stoi[token] for token in sentence] for sentence in pred_strings_rm]).cuda()            \n",
    "#                 embed_pred = model.decoder.embed(pred_strings_rm_id)\n",
    "#                 embed_pred = embed_pred.view(embed_pred.size(0), -1)            \n",
    "                     \n",
<<<<<<< HEAD
    "            #ys_w = trg_idf[:, 1:].contiguous().view(-1).cuda()\n",
    "            ys = trg[:, 1:].contiguous().view(-1).cuda()\n",
=======
    "            \n",
    "            ys = trg[:, 1:].contiguous().view(-1).cuda()\n",
    "            \n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "            opt.optimizer.zero_grad()\n",
    "            \n",
    "            if relevance_training==1:\n",
    "                #loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad).add(\n",
    "                #((embed_trg.cuda() - embed_pred.cuda()) **2).mean())\n",
<<<<<<< HEAD
    "                loss1 = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, weight=ys_w, ignore_index=opt.trg_pad)              \n",
    "                loss2 = ((embed_trg.cuda() - embed_pred.cuda()) **2).mean()\n",
    "                \n",
    "                print(\"batch loss nmt\\t\" + str(loss1.item()) + \"\\tbatch loss relevance\\t\" + str(loss2.item()))\n",
    "                loss1.backward(retain_graph=True)\n",
    "                loss2.backward()               \n",
    "            else:\n",
    "                loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, weight=class_weights, ignore_index=opt.trg_pad)              \n",
    "                #loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad)              \n",
    "                loss.backward()             \n",
    "            \n",
    "            opt.optimizer.step()\n",
    "            \n",
    "            if opt.SGDR == True: \n",
    "                opt.sched.step()\n",
    "            #total_loss += loss1.item() + loss2.item()\n",
    "            total_loss+= loss.item()\n",
    "            \n",
    "            if (i + 1) % opt.printevery == 0:\n",
    "                #print(\"lost after some iterations \" + str(total_loss))\n",
    "                \n",
    "                p = int(100 * (i + 1) / opt.train_len)\n",
    "                avg_loss = total_loss/opt.printevery\n",
    "                \n",
    "                #print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                #((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss), end='\\r')\n",
    "                #print(avg_loss)\n",
    "                total_loss = 0\n",
    "            #We are saving the model every five minutes \n",
    "            if opt.checkpoint > 0 and ((time.time()-cptime)//60) // opt.checkpoint >= 1:\n",
    "                torch.save(model.state_dict(), 'weights/model_weights')                            \n",
    "                p = subprocess.Popen('CUDA_VISIBLE_DEVICES=2 python translate_validation.py', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "                line = p.stdout.readlines()[0]\n",
    "                #print(line)\n",
    "                mAP = float(line.decode(\"utf-8\").strip().split()[1])\n",
    "                #print(\"current mAP is\\t\" + str(mAP))\n",
    "                #print(\"best mAP so far is\\t\" + str(best_mAP))     \n",
    "                print(str(global_step) + \"\\t\" + str(loss.item()) + \"\\t\" + str(mAP))\n",
    "                if mAP > best_mAP:\n",
    "                    #print(\"best mAP so far is \" + str(mAP)) \n",
    "                    #print(\"saving the model at model_weights_best_validation\")\n",
    "                    best_mAP = mAP\n",
    "                    torch.save(model.state_dict(), 'weights/model_weights_best_validation')\n",
    "                \n",
    "                #torch.save(model.state_dict(), 'weights/model_weights')  \n",
    "                \n",
    "                cptime = time.time()\n",
    "                # 1. Log scalar values (scalar summary)\n",
    "                info = { 'loss': loss.item(), 'map': mAP}\n",
    "                for tag, value in info.items():\n",
    "                    logger.scalar_summary(tag, value, global_step+1)\n",
    "                global_step+=1\n",
    "        print(\"%dm: epoch %d [%s%s]  %d%%  loss = %.3f\\nepoch %d complete, loss = %.03f\" %\\\n",
    "        ((time.time() - start)//60, epoch + 1, \"\".join('#'*(100//5)), \"\".join(' '*(20-(100//5))), 100, avg_loss, epoch + 1, avg_loss))\n",
    "        torch.save(model.state_dict(), 'weights/model_weights_8_' + str(epoch))"
=======
    "                loss1 = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad)              \n",
    "                loss2 = ((embed_trg.cuda() - embed_pred.cuda()) **2).mean()\n",
    "                print(\"batch loss nmt\\t\" + str(loss1.item()) + \"\\tbatch loss relevance\\t\" + str(loss2.item()))\n",
    "                loss1.backward(retain_graph=True)\n",
    "                loss2.backward(retain_graph=True)               \n",
    "            else:\n",
    "                loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad)              \n",
    "                loss.backward()             \n",
    "            \n",
    "            opt.optimizer.step()\n",
    "                \n",
    "            if opt.SGDR == True: \n",
    "                opt.sched.step()\n",
    "            total_loss += loss1.item() + loss2.item()\n",
    "            \n",
    "            if (i + 1) % opt.printevery == 0:\n",
    "                 p = int(100 * (i + 1) / opt.train_len)\n",
    "                 avg_loss = total_loss/opt.printevery\n",
    "                 if opt.floyd is False:\n",
    "                    print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                    ((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss), end='\\r')\n",
    "                 else:\n",
    "                    print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                    ((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss))\n",
    "                 total_loss = 0\n",
    "            \n",
    "            if opt.checkpoint > 0 and ((time.time()-cptime)//60) // opt.checkpoint >= 1:\n",
    "                torch.save(model.state_dict(), 'weights/model_weights')\n",
    "                cptime = time.time()\n",
    "                        \n",
    "        print(\"%dm: epoch %d [%s%s]  %d%%  loss = %.3f\\nepoch %d complete, loss = %.03f\" %\\\n",
    "        ((time.time() - start)//60, epoch + 1, \"\".join('#'*(100//5)), \"\".join(' '*(20-(100//5))), 100, avg_loss, epoch + 1, avg_loss))\n"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
=======
   "execution_count": 9,
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n",
<<<<<<< HEAD
      "0\t3.7884838581085205\t0.1225\n",
      "1\t4.234820365905762\t0.1164\n",
      "2\t3.9458653926849365\t0.1252\n",
      "3\t6.230319499969482\t0.1449\n",
      "4\t3.608670234680176\t0.1403\n",
      "5\t3.5625908374786377\t0.1311\n",
      "6\t3.8527517318725586\t0.1347\n",
      "7\t4.155653953552246\t0.1222\n",
      "8\t4.225128173828125\t0.0879\n",
      "9\t4.1235198974609375\t0.0984\n",
      "10\t3.967794418334961\t0.1268\n",
      "11\t4.156708240509033\t0.1415\n",
      "12\t4.160446643829346\t0.1336\n",
      "13\t3.8999078273773193\t0.1091\n",
      "14\t3.716236114501953\t0.1027\n",
      "15\t4.504022121429443\t0.1351\n",
      "16\t3.8989346027374268\t0.1444\n",
      "17\t4.1869025230407715\t0.1426\n",
      "18\t3.788221597671509\t0.1398\n",
      "19\t4.45277738571167\t0.094\n",
      "20\t3.871441602706909\t0.1389\n",
      "21\t3.6745269298553467\t0.137\n",
      "22\t2.9278037548065186\t0.1282\n",
      "23\t3.819335699081421\t0.1138\n",
      "24\t4.125905513763428\t0.1326\n",
      "25\t3.6772305965423584\t0.1392\n",
      "26\t3.890035629272461\t0.1518\n",
      "27\t3.9780538082122803\t0.1411\n",
      "28\t4.294170379638672\t0.1271\n",
      "29\t3.6222739219665527\t0.1125\n",
      "30\t3.8926122188568115\t0.1188\n",
      "31\t4.538330078125\t0.1179\n",
      "32\t4.631744384765625\t0.1103\n",
      "33\t3.634626865386963\t0.1023\n",
      "34\t4.408799648284912\t0.1385\n",
      "35\t4.12120246887207\t0.118\n",
      "36\t3.9404807090759277\t0.1452\n",
      "37\t4.254159450531006\t0.1346\n",
      "38\t4.0202155113220215\t0.1344\n",
      "39\t3.766936779022217\t0.1522\n",
      "40\t3.94270396232605\t0.1295\n",
      "41\t3.6906237602233887\t0.1528\n",
      "42\t2.830595016479492\t0.1433\n",
      "43\t3.67138409614563\t0.1558\n",
      "44\t3.6494369506835938\t0.1459\n",
      "45\t3.618882417678833\t0.1315\n",
      "46\t4.198955059051514\t0.1459\n",
      "47\t3.916611433029175\t0.1434\n",
      "48\t4.27268123626709\t0.1471\n",
      "49\t3.624645948410034\t0.1416\n",
      "50\t4.37923526763916\t0.1362\n",
      "51\t4.1200666427612305\t0.1529\n",
      "52\t3.75400972366333\t0.1228\n",
      "53\t3.275911569595337\t0.1558\n",
      "54\t4.554801940917969\t0.116\n",
      "55\t3.945227861404419\t0.1382\n",
      "56\t4.255743026733398\t0.148\n",
      "57\t4.07435941696167\t0.1329\n",
      "58\t3.7149078845977783\t0.1337\n",
      "59\t3.6685268878936768\t0.1494\n",
      "60\t4.289419174194336\t0.1327\n",
      "61\t3.6989967823028564\t0.1376\n",
      "62\t3.878528356552124\t0.1334\n",
      "63\t3.6356046199798584\t0.1236\n",
      "64\t3.8784382343292236\t0.1312\n",
      "65\t3.6951842308044434\t0.1175\n",
      "66\t4.052004814147949\t0.1254\n",
      "67\t4.995370388031006\t0.1367\n",
      "68\t3.4747867584228516\t0.1176\n",
      "69\t4.539793491363525\t0.1379\n",
      "70\t3.646291971206665\t0.1397\n",
      "71\t4.429090976715088\t0.1448\n",
      "72\t3.735353469848633\t0.119\n",
      "73\t4.252101898193359\t0.1385\n",
      "74\t4.235543251037598\t0.1365\n",
      "75\t3.6915485858917236\t0.1232\n",
      "76\t3.6549925804138184\t0.1013\n",
      "77\t3.7607452869415283\t0.1198\n",
      "78\t3.8917720317840576\t0.1399\n",
      "79\t4.249714374542236\t0.0972\n",
      "80\t3.3401265144348145\t0.1253\n",
      "81\t3.8874995708465576\t0.1357\n",
      "82\t3.8983154296875\t0.1367\n",
      "83\t3.7479848861694336\t0.1297\n",
      "84\t3.8502118587493896\t0.1123\n",
      "85\t4.0792317390441895\t0.1579\n",
      "86\t3.7838592529296875\t0.1196\n",
      "87\t4.066050052642822\t0.1403\n",
      "88\t3.7024569511413574\t0.0962\n",
      "89\t3.6402385234832764\t0.1087\n",
      "90\t4.68551778793335\t0.1141\n",
      "91\t3.632761240005493\t0.1028\n",
      "92\t4.149399757385254\t0.1202\n",
      "93\t4.046103000640869\t0.1026\n",
      "94\t4.438033580780029\t0.1251\n",
      "95\t4.350517749786377\t0.1337\n",
      "96\t3.6991453170776367\t0.1143\n",
      "97\t4.340528964996338\t0.1174\n",
      "98\t3.9053149223327637\t0.1145\n",
      "99\t3.835841655731201\t0.1387\n",
      "100\t3.649318218231201\t0.1298\n",
      "101\t3.804295063018799\t0.1208\n",
      "102\t4.7929840087890625\t0.1191\n",
      "103\t3.895665168762207\t0.1409\n",
      "104\t3.7934176921844482\t0.1454\n",
      "105\t3.9429571628570557\t0.1164\n",
      "106\t3.5394062995910645\t0.1531\n",
      "107\t3.581589460372925\t0.1343\n",
      "108\t4.222898006439209\t0.16\n",
      "109\t3.88993239402771\t0.1378\n",
      "110\t3.7201249599456787\t0.1561\n",
      "111\t3.6086065769195557\t0.1013\n",
      "112\t4.217131614685059\t0.1061\n",
      "113\t4.185116767883301\t0.1086\n",
      "114\t3.796088933944702\t0.1406\n",
      "115\t4.080997943878174\t0.1135\n",
      "116\t3.931384563446045\t0.1356\n",
      "117\t3.8090991973876953\t0.1416\n",
      "118\t4.114957332611084\t0.1424\n",
      "119\t3.4247403144836426\t0.1172\n",
      "120\t3.6655876636505127\t0.1696\n",
      "121\t3.936568260192871\t0.1418\n",
      "122\t3.702504873275757\t0.1353\n",
      "123\t3.835325002670288\t0.1377\n",
      "124\t3.358037233352661\t0.1221\n",
      "125\t3.666076898574829\t0.1166\n",
      "126\t3.9094645977020264\t0.1326\n",
      "127\t3.862516403198242\t0.1133\n",
      "128\t4.228300094604492\t0.122\n",
      "129\t3.8250131607055664\t0.1257\n",
      "130\t4.068791389465332\t0.1199\n",
      "131\t3.7906711101531982\t0.1337\n",
      "132\t3.8781957626342773\t0.1467\n",
      "133\t3.631291151046753\t0.1211\n",
      "134\t4.478201866149902\t0.1482\n",
      "135\t3.995116949081421\t0.1508\n",
      "136\t3.7998578548431396\t0.1368\n",
      "137\t3.6747241020202637\t0.1484\n",
      "138\t4.1401591300964355\t0.0985\n",
      "139\t3.8587827682495117\t0.1294\n",
      "140\t3.840001106262207\t0.1437\n",
      "141\t4.757163047790527\t0.1323\n",
      "142\t3.576521635055542\t0.1114\n",
      "143\t3.6228621006011963\t0.1398\n",
      "144\t3.6053576469421387\t0.1293\n",
      "145\t3.604579448699951\t0.1292\n",
      "146\t3.70623517036438\t0.1477\n",
      "147\t3.9605371952056885\t0.1314\n",
      "148\t3.709620237350464\t0.1259\n",
      "149\t3.6896283626556396\t0.1086\n",
      "150\t3.824298620223999\t0.1342\n",
      "151\t3.9096670150756836\t0.107\n",
      "152\t3.6624667644500732\t0.1185\n",
      "153\t3.8777050971984863\t0.1318\n",
      "154\t3.6583752632141113\t0.1259\n",
      "155\t3.81435489654541\t0.1227\n",
      "156\t3.935037136077881\t0.1001\n",
      "157\t3.956935167312622\t0.119\n",
      "158\t4.6547112464904785\t0.0934\n",
      "159\t3.81266450881958\t0.1047\n",
      "160\t3.8305442333221436\t0.1104\n",
      "161\t4.024970531463623\t0.1006\n",
      "162\t3.948024034500122\t0.0985\n",
      "163\t4.092216491699219\t0.1358\n",
      "164\t4.023827075958252\t0.1218\n",
      "165\t4.128114700317383\t0.1315\n",
      "166\t3.8450868129730225\t0.1188\n",
      "167\t3.6345930099487305\t0.1307\n",
      "168\t3.9509835243225098\t0.1044\n",
      "169\t3.6374945640563965\t0.1379\n",
      "170\t3.825409173965454\t0.1364\n",
      "171\t4.02919340133667\t0.1439\n",
      "172\t3.5460991859436035\t0.1086\n",
      "173\t3.805877923965454\t0.1431\n",
      "174\t3.6586709022521973\t0.1233\n",
      "175\t3.6552255153656006\t0.1368\n",
      "176\t3.7946531772613525\t0.1225\n",
      "177\t3.6872503757476807\t0.1339\n",
      "178\t4.290874481201172\t0.1346\n",
      "179\t4.12180233001709\t0.1232\n",
      "180\t3.8021302223205566\t0.1146\n",
      "181\t3.856332778930664\t0.127\n",
      "182\t4.404448986053467\t0.1292\n",
      "183\t4.291302680969238\t0.125\n",
      "184\t3.6113948822021484\t0.1217\n",
      "185\t3.8481626510620117\t0.1209\n",
      "186\t3.9504663944244385\t0.1239\n",
      "187\t3.616541862487793\t0.1187\n",
      "188\t4.01279878616333\t0.124\n",
      "189\t4.302597522735596\t0.1056\n",
      "190\t3.504467010498047\t0.116\n",
      "191\t4.369464874267578\t0.1223\n",
      "192\t3.6431972980499268\t0.1233\n",
      "193\t3.5217854976654053\t0.1339\n",
      "194\t3.7067558765411377\t0.1107\n",
      "195\t4.489256858825684\t0.1311\n",
      "196\t3.6025636196136475\t0.1364\n",
      "197\t4.314231872558594\t0.112\n",
      "198\t4.022974491119385\t0.1052\n",
      "199\t3.568350076675415\t0.1064\n",
      "200\t4.062739372253418\t0.1149\n",
      "201\t4.001182556152344\t0.1288\n",
      "202\t4.213492393493652\t0.1058\n",
      "203\t3.966399669647217\t0.1193\n",
      "204\t3.6215405464172363\t0.1102\n",
      "205\t4.836109638214111\t0.1275\n",
      "206\t3.8366358280181885\t0.1309\n",
      "207\t3.7509865760803223\t0.129\n",
      "208\t3.461388111114502\t0.1311\n",
      "209\t4.080687046051025\t0.1243\n",
      "210\t3.8764820098876953\t0.1382\n",
      "211\t3.620426654815674\t0.1181\n",
      "212\t3.993588924407959\t0.1102\n",
      "213\t4.262438774108887\t0.1192\n",
      "214\t3.5950369834899902\t0.1073\n",
      "215\t3.836998224258423\t0.1133\n",
      "216\t3.5216822624206543\t0.1098\n",
      "217\t3.9666521549224854\t0.1268\n",
      "218\t4.249114990234375\t0.1209\n",
      "219\t4.153464317321777\t0.1299\n",
      "220\t3.6756742000579834\t0.0957\n",
      "221\t3.8920814990997314\t0.135\n",
      "222\t5.059423923492432\t0.126\n",
      "223\t4.786459445953369\t0.1164\n",
      "224\t3.923225164413452\t0.1174\n",
      "225\t3.5875399112701416\t0.1162\n",
      "226\t4.259035110473633\t0.0926\n",
      "227\t3.5735082626342773\t0.1116\n",
      "228\t4.112349987030029\t0.1233\n",
      "229\t1.6125545501708984\t0.1404\n",
      "230\t3.7468245029449463\t0.1091\n",
      "231\t3.608689546585083\t0.1196\n",
      "232\t3.539208173751831\t0.1474\n",
      "233\t4.214618682861328\t0.1524\n",
      "234\t3.553417921066284\t0.1301\n",
      "235\t3.686718225479126\t0.0951\n",
      "236\t3.688018560409546\t0.1009\n",
      "237\t3.811617374420166\t0.1109\n",
      "238\t3.7106101512908936\t0.1361\n",
      "239\t3.9305379390716553\t0.1263\n",
      "240\t3.391839027404785\t0.1033\n",
      "241\t3.727079391479492\t0.1391\n",
      "242\t3.840085983276367\t0.0964\n",
      "243\t4.125241279602051\t0.1276\n",
      "244\t4.166757106781006\t0.1363\n",
      "245\t3.611163854598999\t0.1315\n",
      "246\t4.05658483505249\t0.1458\n",
      "247\t4.25109338760376\t0.1057\n",
      "248\t3.5122909545898438\t0.1163\n",
      "249\t4.15136194229126\t0.1133\n",
      "250\t3.956389904022217\t0.1417\n",
      "251\t3.4040639400482178\t0.1324\n",
      "252\t4.687286853790283\t0.1233\n",
      "253\t4.83812141418457\t0.0959\n",
      "254\t4.089211463928223\t0.1296\n",
      "255\t3.746089458465576\t0.1493\n",
      "256\t4.373818397521973\t0.1557\n",
      "257\t3.71982741355896\t0.1215\n",
      "258\t3.6649057865142822\t0.1377\n",
      "259\t3.805938243865967\t0.1105\n",
      "260\t4.680771350860596\t0.1229\n",
      "261\t3.663198232650757\t0.1532\n",
      "262\t3.687347412109375\t0.1601\n",
      "263\t3.528639078140259\t0.1213\n",
      "264\t3.3384146690368652\t0.1438\n",
      "265\t4.071770668029785\t0.1532\n",
      "266\t3.883960008621216\t0.1487\n",
      "267\t3.905466079711914\t0.1382\n",
      "268\t3.8799896240234375\t0.1186\n",
      "269\t3.8771486282348633\t0.1425\n",
      "270\t3.9800190925598145\t0.145\n",
      "271\t3.9564855098724365\t0.1028\n",
      "272\t3.696049928665161\t0.1159\n",
      "273\t3.999630928039551\t0.1476\n",
      "274\t4.269918441772461\t0.1362\n",
      "275\t3.637850761413574\t0.1542\n",
      "276\t4.1750712394714355\t0.1593\n",
      "277\t1.3676549196243286\t0.145\n",
      "278\t3.962766170501709\t0.1534\n",
      "279\t3.448394536972046\t0.1569\n",
      "280\t3.337618827819824\t0.1117\n",
      "281\t4.05487060546875\t0.0915\n",
      "282\t3.930065155029297\t0.1229\n",
      "283\t3.67527437210083\t0.11\n"
=======
      "batch loss nmt\t3.3910601139068604\tbatch loss relevance\t0.001179350889287889\n",
      "batch loss nmt\t3.0724680423736572\tbatch loss relevance\t0.0008094001677818596\n",
      "batch loss nmt\t4.594939708709717\tbatch loss relevance\t0.0011161633301526308\n",
      "batch loss nmt\t5.234333515167236\tbatch loss relevance\t0.0010094906901940703\n",
      "batch loss nmt\t3.8060078620910645\tbatch loss relevance\t0.0011968103935942054\n",
      "batch loss nmt\t3.247288942337036\tbatch loss relevance\t0.0012827636674046516\n",
      "batch loss nmt\t3.505147933959961\tbatch loss relevance\t0.0011120610870420933\n",
      "batch loss nmt\t4.531473159790039\tbatch loss relevance\t0.0006579987821169198\n",
      "batch loss nmt\t3.927861213684082\tbatch loss relevance\t0.001077174092642963\n",
      "batch loss nmt\t3.511997938156128\tbatch loss relevance\t0.0009162729838863015\n",
      "batch loss nmt\t3.5104730129241943\tbatch loss relevance\t0.0010013490682467818\n",
      "batch loss nmt\t3.3216309547424316\tbatch loss relevance\t0.0011692022671923041\n",
      "batch loss nmt\t3.335780143737793\tbatch loss relevance\t0.0012965165078639984\n",
      "batch loss nmt\t3.4984328746795654\tbatch loss relevance\t0.0013164051342755556\n",
      "batch loss nmt\t3.7082550525665283\tbatch loss relevance\t0.0011455153580754995\n",
      "batch loss nmt\t3.489914655685425\tbatch loss relevance\t0.0010303591843694448\n",
      "batch loss nmt\t5.229833126068115\tbatch loss relevance\t0.0007734469836577773\n",
      "batch loss nmt\t3.350281238555908\tbatch loss relevance\t0.0007497594924643636\n",
      "batch loss nmt\t3.978595018386841\tbatch loss relevance\t0.0012334608472883701\n",
      "batch loss nmt\t4.447625160217285\tbatch loss relevance\t0.0011870978632941842\n",
      "batch loss nmt\t4.823034763336182\tbatch loss relevance\t0.0012781444238498807\n",
      "batch loss nmt\t3.7170350551605225\tbatch loss relevance\t0.0010517146438360214\n",
      "batch loss nmt\t3.305298328399658\tbatch loss relevance\t0.0009830722119659185\n",
      "batch loss nmt\t2.6619374752044678\tbatch loss relevance\t0.0008470660541206598\n",
      "batch loss nmt\t3.562354564666748\tbatch loss relevance\t0.0011650356464087963\n",
      "batch loss nmt\t3.4061226844787598\tbatch loss relevance\t0.0011268083471804857\n",
      "batch loss nmt\t3.3018670082092285\tbatch loss relevance\t0.0010655899532139301\n",
      "batch loss nmt\t3.6048760414123535\tbatch loss relevance\t0.0010280301794409752\n",
      "batch loss nmt\t3.5632996559143066\tbatch loss relevance\t0.0012625375529751182\n",
      "batch loss nmt\t3.926320791244507\tbatch loss relevance\t0.0010713968658819795\n",
      "batch loss nmt\t3.5124666690826416\tbatch loss relevance\t0.0011349489213898778\n",
      "batch loss nmt\t3.3428187370300293\tbatch loss relevance\t0.0009731745230965316\n",
      "batch loss nmt\t3.4873712062835693\tbatch loss relevance\t0.0012967478251084685\n",
      "batch loss nmt\t4.871427059173584\tbatch loss relevance\t0.0012675134930759668\n",
      "batch loss nmt\t3.3818199634552\tbatch loss relevance\t0.0009408362675458193\n",
      "batch loss nmt\t2.9630444049835205\tbatch loss relevance\t0.0008966918685473502\n",
      "batch loss nmt\t2.9187779426574707\tbatch loss relevance\t0.0012779912212863564\n",
      "batch loss nmt\t3.5144577026367188\tbatch loss relevance\t0.0011881225509569049\n",
      "batch loss nmt\t3.512643814086914\tbatch loss relevance\t0.0008546218159608543\n",
      "batch loss nmt\t3.72831392288208\tbatch loss relevance\t0.0012150985421612859\n",
      "batch loss nmt\t3.0366406440734863\tbatch loss relevance\t0.0010785057675093412\n",
      "batch loss nmt\t3.3060035705566406\tbatch loss relevance\t0.000997727271169424\n",
      "batch loss nmt\t3.5640251636505127\tbatch loss relevance\t0.0013020108453929424\n",
      "batch loss nmt\t3.14951229095459\tbatch loss relevance\t0.0007489968556910753\n",
      "batch loss nmt\t2.859506368637085\tbatch loss relevance\t0.0007663503638468683\n",
      "batch loss nmt\t3.633739948272705\tbatch loss relevance\t0.0011782973306253552\n",
      "batch loss nmt\t3.6056039333343506\tbatch loss relevance\t0.001119365100748837\n",
      "batch loss nmt\t3.208346366882324\tbatch loss relevance\t0.0010640228865668178\n",
      "batch loss nmt\t3.6218996047973633\tbatch loss relevance\t0.0011490307515487075\n",
      "batch loss nmt\t4.895326137542725\tbatch loss relevance\t0.0013423894997686148\n",
      "batch loss nmt\t3.626980781555176\tbatch loss relevance\t0.0011462216498330235\n",
      "batch loss nmt\t3.577744245529175\tbatch loss relevance\t0.0010838797315955162\n",
      "batch loss nmt\t2.959994316101074\tbatch loss relevance\t0.0008095040684565902\n",
      "batch loss nmt\t3.521723508834839\tbatch loss relevance\t0.001351010869257152\n",
      "batch loss nmt\t4.171388626098633\tbatch loss relevance\t0.0012116413563489914\n",
      "batch loss nmt\t3.5675950050354004\tbatch loss relevance\t0.0010479568736627698\n",
      "batch loss nmt\t3.1834774017333984\tbatch loss relevance\t0.0011834210017696023\n",
      "batch loss nmt\t4.127345085144043\tbatch loss relevance\t0.0011402266100049019\n",
      "batch loss nmt\t4.037251949310303\tbatch loss relevance\t0.0010403981432318687\n",
      "batch loss nmt\t4.149605751037598\tbatch loss relevance\t0.001114599872380495\n",
      "batch loss nmt\t3.364572286605835\tbatch loss relevance\t0.001214243471622467\n",
      "batch loss nmt\t3.4960250854492188\tbatch loss relevance\t0.0008751599816605449\n",
      "batch loss nmt\t3.47542405128479\tbatch loss relevance\t0.0010546286357566714\n",
      "batch loss nmt\t4.005695819854736\tbatch loss relevance\t0.0011486097937449813\n",
      "batch loss nmt\t3.59908127784729\tbatch loss relevance\t0.0010527374688535929\n",
      "batch loss nmt\t2.888131856918335\tbatch loss relevance\t0.000786593125667423\n",
      "batch loss nmt\t3.4780380725860596\tbatch loss relevance\t0.0010157491778954864\n",
      "batch loss nmt\t2.4508142471313477\tbatch loss relevance\t0.000766983546782285\n",
      "batch loss nmt\t3.625049352645874\tbatch loss relevance\t0.0009330049506388605\n",
      "batch loss nmt\t3.2426772117614746\tbatch loss relevance\t0.0010257476242259145\n",
      "batch loss nmt\t3.2749056816101074\tbatch loss relevance\t0.0010461595375090837\n",
      "batch loss nmt\t3.4972450733184814\tbatch loss relevance\t0.0010330548975616693\n",
      "batch loss nmt\t3.661625862121582\tbatch loss relevance\t0.0013098487397655845\n",
      "batch loss nmt\t3.8138697147369385\tbatch loss relevance\t0.0011712382547557354\n",
      "batch loss nmt\t3.4275546073913574\tbatch loss relevance\t0.0012291939929127693\n",
      "batch loss nmt\t3.817918062210083\tbatch loss relevance\t0.0009663259843364358\n",
      "batch loss nmt\t3.440293788909912\tbatch loss relevance\t0.0010385691421106458\n",
      "batch loss nmt\t3.722599744796753\tbatch loss relevance\t0.0012679940555244684\n",
      "batch loss nmt\t4.4563069343566895\tbatch loss relevance\t0.0012735454365611076\n",
      "batch loss nmt\t3.1206154823303223\tbatch loss relevance\t0.0010998460929840803\n",
      "batch loss nmt\t4.637211322784424\tbatch loss relevance\t0.0013273876393213868\n",
      "batch loss nmt\t3.691472291946411\tbatch loss relevance\t0.0011737773893401027\n",
      "batch loss nmt\t4.258241653442383\tbatch loss relevance\t0.0009061701712198555\n",
      "batch loss nmt\t3.3251404762268066\tbatch loss relevance\t0.0010926291579380631\n",
      "batch loss nmt\t4.0909953117370605\tbatch loss relevance\t0.0010521018411964178\n",
      "batch loss nmt\t3.451781749725342\tbatch loss relevance\t0.0009560283506289124\n",
      "batch loss nmt\t3.570984363555908\tbatch loss relevance\t0.001203065039590001\n",
      "batch loss nmt\t3.1693553924560547\tbatch loss relevance\t0.0009519869927316904\n",
      "batch loss nmt\t4.0979156494140625\tbatch loss relevance\t0.0010281383292749524\n",
      "batch loss nmt\t4.398630142211914\tbatch loss relevance\t0.0012633492005988955\n",
      "batch loss nmt\t3.705350399017334\tbatch loss relevance\t0.0012361370027065277\n",
      "batch loss nmt\t3.4472920894622803\tbatch loss relevance\t0.0013556798221543431\n",
      "batch loss nmt\t3.573265552520752\tbatch loss relevance\t0.001052259118296206\n",
      "batch loss nmt\t3.702572822570801\tbatch loss relevance\t0.001089403871446848\n",
      "batch loss nmt\t3.390037775039673\tbatch loss relevance\t0.0010523847304284573\n",
      "batch loss nmt\t2.8325915336608887\tbatch loss relevance\t0.000824449525680393\n",
      "batch loss nmt\t4.839597702026367\tbatch loss relevance\t0.0011826481204479933\n",
      "batch loss nmt\t4.7928290367126465\tbatch loss relevance\t0.0011190749937668443\n",
      "batch loss nmt\t3.515634059906006\tbatch loss relevance\t0.0010201395489275455\n",
      "batch loss nmt\t3.951528787612915\tbatch loss relevance\t0.0011758829932659864\n",
      "batch loss nmt\t3.5350887775421143\tbatch loss relevance\t0.0011300729820504785\n",
      "batch loss nmt\t4.014527320861816\tbatch loss relevance\t0.0008533560903742909\n",
      "batch loss nmt\t3.356870174407959\tbatch loss relevance\t0.0010754800168797374\n",
      "batch loss nmt\t3.988563060760498\tbatch loss relevance\t0.0012155595468357205\n",
      "batch loss nmt\t3.3240740299224854\tbatch loss relevance\t0.0010771910892799497\n",
      "batch loss nmt\t3.384699583053589\tbatch loss relevance\t0.001138328923843801\n",
      "batch loss nmt\t4.206461429595947\tbatch loss relevance\t0.0013830161187797785\n",
      "batch loss nmt\t4.329399108886719\tbatch loss relevance\t0.000999725074507296\n"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "284\t4.180558204650879\t0.149\n",
      "285\t3.5520238876342773\t0.1088\n",
      "286\t3.931853771209717\t0.1124\n",
      "287\t3.9226174354553223\t0.1156\n",
      "288\t3.5832507610321045\t0.1366\n",
      "289\t3.6951212882995605\t0.1289\n",
      "290\t3.846214532852173\t0.1246\n",
      "291\t3.5974676609039307\t0.1269\n",
      "292\t3.8336257934570312\t0.1038\n",
      "293\t4.22176456451416\t0.136\n",
      "294\t4.41612434387207\t0.1252\n",
      "295\t4.144439697265625\t0.1213\n",
      "296\t3.6642966270446777\t0.1218\n",
      "297\t3.780883312225342\t0.1264\n",
      "298\t3.8099570274353027\t0.105\n",
      "299\t4.332866668701172\t0.1353\n",
      "300\t4.009336948394775\t0.1134\n",
      "301\t4.259526252746582\t0.1452\n",
      "302\t3.9161629676818848\t0.1094\n",
      "303\t4.116866588592529\t0.1009\n",
      "304\t4.424443244934082\t0.1304\n",
      "305\t4.112651824951172\t0.1157\n",
      "306\t4.087150573730469\t0.1109\n",
      "307\t4.200462341308594\t0.1361\n",
      "308\t3.2811808586120605\t0.1141\n",
      "309\t4.295328617095947\t0.1267\n",
      "310\t2.2064003944396973\t0.1093\n",
      "311\t4.091166019439697\t0.1177\n",
      "312\t3.575411796569824\t0.1109\n",
      "313\t3.7301833629608154\t0.1091\n",
      "314\t4.081258773803711\t0.1181\n",
      "315\t3.1733953952789307\t0.1012\n",
      "316\t3.768211603164673\t0.116\n",
      "317\t3.287606716156006\t0.1077\n",
      "318\t4.180471420288086\t0.1184\n",
      "319\t3.6795289516448975\t0.1451\n",
      "320\t3.901918649673462\t0.1351\n",
      "321\t3.5636985301971436\t0.1058\n",
      "322\t4.243492126464844\t0.1193\n",
      "323\t3.794502019882202\t0.1219\n",
      "324\t4.040070533752441\t0.1152\n",
      "325\t4.629956245422363\t0.1057\n",
      "326\t3.8951704502105713\t0.0977\n",
      "327\t3.5991766452789307\t0.1047\n",
      "328\t3.736088514328003\t0.1611\n",
      "329\t3.342822790145874\t0.1261\n",
      "330\t3.4681339263916016\t0.1355\n",
      "331\t3.685535430908203\t0.1573\n",
      "332\t4.525730133056641\t0.1277\n",
      "333\t3.6485743522644043\t0.1256\n",
      "334\t4.007820129394531\t0.1274\n",
      "335\t4.3712592124938965\t0.136\n",
      "336\t3.969463586807251\t0.1168\n",
      "337\t3.7730772495269775\t0.13\n",
      "338\t3.9024572372436523\t0.121\n",
      "339\t4.357235908508301\t0.126\n",
      "340\t3.59155011177063\t0.1294\n",
      "341\t4.106928825378418\t0.1219\n",
      "342\t3.8718597888946533\t0.1279\n",
      "343\t4.507061004638672\t0.1246\n",
      "344\t3.455264091491699\t0.1259\n",
      "345\t0.1845232993364334\t0.1264\n",
      "346\t4.070279598236084\t0.1445\n",
      "347\t3.855714797973633\t0.1474\n",
      "348\t4.637484073638916\t0.1324\n",
      "349\t3.772860050201416\t0.1487\n",
      "350\t3.9115803241729736\t0.145\n",
      "351\t4.11955451965332\t0.1176\n",
      "352\t3.986337423324585\t0.1117\n",
      "353\t3.7920162677764893\t0.1171\n",
      "354\t3.9213967323303223\t0.1217\n",
      "355\t3.7040374279022217\t0.1472\n",
      "356\t4.065990924835205\t0.1136\n",
      "357\t3.915372848510742\t0.1193\n",
      "358\t3.492083787918091\t0.1238\n",
      "359\t3.6670761108398438\t0.1051\n",
      "360\t3.759671688079834\t0.1083\n",
      "361\t3.3469808101654053\t0.1184\n",
      "362\t3.826911687850952\t0.11\n",
      "363\t4.591104507446289\t0.1007\n",
      "364\t4.04056978225708\t0.128\n",
      "365\t3.88362979888916\t0.1343\n",
      "366\t3.2580082416534424\t0.1091\n",
      "367\t3.8533689975738525\t0.1002\n",
      "368\t3.6039624214172363\t0.12\n",
      "369\t3.430239200592041\t0.1169\n",
      "370\t3.60286808013916\t0.1054\n",
      "371\t3.9491817951202393\t0.1326\n",
      "372\t3.6687302589416504\t0.1099\n",
      "373\t4.163804054260254\t0.1276\n",
      "374\t4.299777507781982\t0.1161\n",
      "375\t3.646636724472046\t0.127\n",
      "376\t4.582789421081543\t0.1356\n",
      "377\t3.7987844944000244\t0.1331\n",
      "378\t3.1988394260406494\t0.1155\n",
      "379\t3.081707000732422\t0.1259\n",
      "380\t3.58242130279541\t0.1224\n",
      "381\t4.241805076599121\t0.1184\n",
      "382\t3.9263627529144287\t0.1235\n",
      "383\t3.784926176071167\t0.1166\n",
      "384\t4.431690216064453\t0.118\n",
      "385\t3.5793237686157227\t0.1392\n",
      "386\t3.7213127613067627\t0.1417\n",
      "387\t3.9256467819213867\t0.0981\n",
      "388\t3.3254950046539307\t0.1117\n",
      "389\t4.096802711486816\t0.1437\n",
      "390\t3.43471622467041\t0.1244\n",
      "391\t3.4767234325408936\t0.1447\n",
      "392\t3.9165327548980713\t0.1189\n",
      "393\t4.055421829223633\t0.1292\n",
      "394\t3.9386353492736816\t0.1239\n",
      "395\t4.160141944885254\t0.1006\n",
      "396\t3.800197124481201\t0.0937\n",
      "397\t3.5917203426361084\t0.117\n",
      "398\t3.745814561843872\t0.1097\n",
      "399\t4.29567289352417\t0.1132\n",
      "400\t3.4902992248535156\t0.1092\n",
      "401\t3.8965749740600586\t0.126\n",
      "402\t3.9111828804016113\t0.0925\n",
      "403\t3.5077221393585205\t0.1291\n",
      "404\t3.9584474563598633\t0.1578\n",
      "405\t3.867466688156128\t0.1286\n",
      "406\t4.083051681518555\t0.1319\n",
      "407\t4.140568256378174\t0.1247\n",
      "408\t3.825552225112915\t0.1139\n",
      "409\t4.316129684448242\t0.1095\n",
      "410\t4.048329830169678\t0.1178\n",
      "411\t4.839705944061279\t0.1427\n",
      "412\t3.7608702182769775\t0.123\n",
      "413\t3.9798784255981445\t0.119\n",
      "414\t3.855273485183716\t0.1221\n",
      "415\t3.7670092582702637\t0.1344\n",
      "416\t3.30928635597229\t0.0985\n",
      "417\t3.3144686222076416\t0.1142\n",
      "418\t3.9413084983825684\t0.1234\n",
      "419\t3.723074436187744\t0.1165\n",
      "420\t3.3919293880462646\t0.1359\n",
      "421\t3.9560582637786865\t0.1345\n",
      "422\t4.055492877960205\t0.1361\n",
      "423\t3.6719236373901367\t0.1285\n",
      "424\t3.2723701000213623\t0.1273\n",
      "425\t4.057528495788574\t0.1291\n",
      "426\t3.980555772781372\t0.1382\n",
      "427\t3.555201292037964\t0.1124\n",
      "428\t3.6976754665374756\t0.1367\n",
      "429\t3.9950575828552246\t0.1368\n",
      "430\t4.457656383514404\t0.14\n",
      "431\t3.8900609016418457\t0.1293\n",
      "432\t3.7627172470092773\t0.1215\n",
      "433\t3.6864397525787354\t0.1191\n",
      "434\t3.372248888015747\t0.1157\n",
      "435\t3.810883045196533\t0.1195\n",
      "436\t3.6935007572174072\t0.1126\n",
      "437\t1.126662015914917\t0.1166\n",
      "438\t3.752443552017212\t0.1204\n",
      "439\t3.8683600425720215\t0.1219\n",
      "440\t3.7447402477264404\t0.1119\n",
      "441\t3.7213399410247803\t0.128\n",
      "442\t3.945537567138672\t0.125\n",
      "443\t3.9755308628082275\t0.1531\n",
      "444\t3.63692569732666\t0.1093\n",
      "445\t3.601168632507324\t0.139\n",
      "446\t3.9621963500976562\t0.1292\n",
      "447\t3.648171901702881\t0.1257\n",
      "448\t4.332463264465332\t0.1316\n",
      "449\t3.835505723953247\t0.1169\n",
      "450\t3.5881993770599365\t0.1251\n",
      "451\t3.6288084983825684\t0.11\n",
      "452\t4.234906196594238\t0.098\n",
      "453\t3.559242010116577\t0.1224\n",
      "454\t3.7929983139038086\t0.1006\n",
      "455\t4.23481559753418\t0.1229\n",
      "456\t3.9911773204803467\t0.1078\n",
      "457\t3.4609124660491943\t0.1034\n",
      "458\t3.7959160804748535\t0.1186\n",
      "459\t3.804521083831787\t0.1206\n",
      "460\t3.8598008155822754\t0.1268\n",
      "461\t4.382070064544678\t0.0975\n",
      "462\t3.5648245811462402\t0.1055\n",
      "463\t3.5801103115081787\t0.1127\n",
      "464\t3.7745659351348877\t0.1181\n",
      "465\t3.5107593536376953\t0.117\n",
      "466\t3.8320202827453613\t0.1171\n",
      "467\t4.0825676918029785\t0.1074\n",
      "468\t3.975492238998413\t0.1331\n",
      "469\t4.089849472045898\t0.1237\n",
      "470\t6.398855209350586\t0.0957\n",
      "471\t3.968411922454834\t0.1083\n",
      "472\t4.178274154663086\t0.1263\n",
      "473\t3.7263126373291016\t0.1378\n",
      "25823649m: epoch 1 [####################]  100%  loss = 3.835\n",
      "epoch 1 complete, loss = 3.835\n",
      "474\t3.892916440963745\t0.1138\n",
      "475\t3.9346611499786377\t0.1108\n",
      "476\t4.569705963134766\t0.0989\n",
      "477\t3.526531219482422\t0.132\n",
      "478\t3.7782177925109863\t0.1162\n",
      "479\t3.6798810958862305\t0.1159\n",
      "480\t4.534987926483154\t0.1445\n",
      "481\t3.6059463024139404\t0.1254\n",
      "482\t3.414926528930664\t0.1492\n",
      "483\t4.0629096031188965\t0.1151\n",
      "484\t3.811462163925171\t0.1156\n",
      "485\t3.588923931121826\t0.1101\n",
      "486\t4.032083034515381\t0.116\n",
      "487\t3.407548666000366\t0.1157\n",
      "488\t3.8635690212249756\t0.1281\n",
      "489\t3.787313461303711\t0.1133\n",
      "490\t4.012941360473633\t0.1034\n",
      "491\t4.3075666427612305\t0.1315\n",
      "492\t3.5557892322540283\t0.1367\n",
      "493\t3.4608285427093506\t0.1243\n",
      "494\t3.78070068359375\t0.1117\n",
      "495\t3.6398165225982666\t0.1227\n",
      "496\t3.7857565879821777\t0.1256\n",
      "497\t3.574347972869873\t0.1022\n",
      "498\t3.4830503463745117\t0.1274\n",
      "499\t3.8677773475646973\t0.1365\n",
      "500\t3.5544159412384033\t0.1106\n",
      "501\t3.447998285293579\t0.1236\n",
      "502\t3.8056273460388184\t0.1059\n",
      "503\t5.246589660644531\t0.1244\n",
      "504\t3.9496943950653076\t0.1112\n",
      "505\t4.000967025756836\t0.107\n",
      "506\t3.6366164684295654\t0.1301\n",
      "507\t3.2831931114196777\t0.1191\n",
      "508\t3.9130775928497314\t0.1064\n",
      "509\t3.3965578079223633\t0.1391\n",
      "510\t3.790043354034424\t0.1375\n",
      "511\t3.0210115909576416\t0.16\n",
      "512\t4.152797698974609\t0.1277\n",
      "513\t4.24473762512207\t0.1111\n",
      "514\t4.04093074798584\t0.1072\n",
      "515\t3.7192790508270264\t0.1387\n",
      "516\t3.652585506439209\t0.1232\n",
      "517\t3.4122660160064697\t0.1396\n",
      "518\t3.465284585952759\t0.1486\n",
      "519\t3.995673894882202\t0.1362\n",
      "520\t3.883725881576538\t0.1293\n",
      "521\t3.666335344314575\t0.1392\n",
      "522\t3.7781152725219727\t0.1276\n",
      "523\t4.106687545776367\t0.1329\n",
      "524\t4.0467352867126465\t0.1152\n",
      "525\t3.733558177947998\t0.1039\n",
      "526\t3.8519349098205566\t0.1353\n",
      "527\t3.940807819366455\t0.1107\n",
      "528\t3.702303171157837\t0.1637\n",
      "529\t3.950918197631836\t0.1283\n",
      "530\t4.013375759124756\t0.1212\n",
      "531\t4.040633201599121\t0.1574\n",
      "532\t4.015963077545166\t0.1284\n",
      "533\t3.6413888931274414\t0.119\n",
      "534\t3.5476763248443604\t0.1387\n",
      "535\t3.860042095184326\t0.1386\n",
      "536\t3.272977352142334\t0.1144\n",
      "537\t3.501972198486328\t0.1244\n",
      "538\t3.42167067527771\t0.1152\n",
      "539\t3.9145920276641846\t0.1284\n",
      "540\t3.464768886566162\t0.1363\n",
      "541\t3.6899545192718506\t0.0997\n",
      "542\t3.8935387134552\t0.125\n",
      "543\t3.691490888595581\t0.1054\n",
      "544\t4.203343868255615\t0.1192\n",
      "545\t3.5925328731536865\t0.1232\n",
      "546\t3.5985538959503174\t0.1054\n",
      "547\t3.8137850761413574\t0.1432\n",
      "548\t4.166223526000977\t0.122\n",
      "549\t3.206617593765259\t0.134\n",
      "550\t3.580195426940918\t0.0892\n",
      "551\t3.797199249267578\t0.0947\n",
      "552\t4.15365743637085\t0.1091\n",
      "553\t3.8398759365081787\t0.1154\n",
      "554\t3.4057810306549072\t0.112\n",
      "555\t4.0742316246032715\t0.1182\n",
      "556\t4.161370754241943\t0.1186\n",
      "557\t4.087749004364014\t0.1354\n",
      "558\t3.3254079818725586\t0.1144\n",
      "559\t3.8945791721343994\t0.1134\n",
      "560\t3.375393867492676\t0.114\n",
      "561\t4.106378078460693\t0.1478\n"
=======
      "batch loss nmt\t3.77309250831604\tbatch loss relevance\t0.0010114996694028378\n",
      "batch loss nmt\t4.187644004821777\tbatch loss relevance\t0.001288336468860507\n",
      "batch loss nmt\t3.607799768447876\tbatch loss relevance\t0.0012973634293302894\n",
      "batch loss nmt\t3.7129287719726562\tbatch loss relevance\t0.001068801968358457\n",
      "batch loss nmt\t3.99247670173645\tbatch loss relevance\t0.001211467431858182\n",
      "batch loss nmt\t3.52329421043396\tbatch loss relevance\t0.0009779214160516858\n",
      "batch loss nmt\t4.660335063934326\tbatch loss relevance\t0.0010085196699947119\n",
      "batch loss nmt\t3.7223405838012695\tbatch loss relevance\t0.0010498896008357406\n",
      "batch loss nmt\t3.7080397605895996\tbatch loss relevance\t0.0009707325953058898\n",
      "batch loss nmt\t2.552656650543213\tbatch loss relevance\t0.000947442022152245\n",
      "batch loss nmt\t3.2609405517578125\tbatch loss relevance\t0.0011436794884502888\n",
      "batch loss nmt\t3.8715507984161377\tbatch loss relevance\t0.0012464092578738928\n",
      "batch loss nmt\t3.2597594261169434\tbatch loss relevance\t0.001089209457859397\n",
      "batch loss nmt\t3.753079891204834\tbatch loss relevance\t0.0011229285737499595\n",
      "batch loss nmt\t2.967176914215088\tbatch loss relevance\t0.0007309257634915411\n",
      "batch loss nmt\t4.743607044219971\tbatch loss relevance\t0.0009577353484928608\n",
      "batch loss nmt\t3.0125234127044678\tbatch loss relevance\t0.0009975926950573921\n",
      "batch loss nmt\t4.237148761749268\tbatch loss relevance\t0.0010372453834861517\n",
      "batch loss nmt\t3.212012529373169\tbatch loss relevance\t0.001085010007955134\n",
      "batch loss nmt\t3.4673328399658203\tbatch loss relevance\t0.001269840169698\n",
      "batch loss nmt\t3.7707200050354004\tbatch loss relevance\t0.0010885385563597083\n",
      "batch loss nmt\t3.4271693229675293\tbatch loss relevance\t0.0010984028922393918\n",
      "batch loss nmt\t4.2771196365356445\tbatch loss relevance\t0.001041484298184514\n",
      "batch loss nmt\t3.672076940536499\tbatch loss relevance\t0.0010398925514891744\n",
      "batch loss nmt\t3.864509344100952\tbatch loss relevance\t0.0011595574906095862\n",
      "batch loss nmt\t3.324542999267578\tbatch loss relevance\t0.0008057992090471089\n",
      "batch loss nmt\t3.101269245147705\tbatch loss relevance\t0.0008928781608119607\n",
      "batch loss nmt\t3.139126777648926\tbatch loss relevance\t0.0010303285671398044\n",
      "batch loss nmt\t3.5292952060699463\tbatch loss relevance\t0.0009386165183968842\n",
      "batch loss nmt\t3.5159316062927246\tbatch loss relevance\t0.0011645553167909384\n",
      "batch loss nmt\t3.242795705795288\tbatch loss relevance\t0.0010535408509895205\n",
      "batch loss nmt\t3.931532621383667\tbatch loss relevance\t0.0009734801133163273\n",
      "batch loss nmt\t3.1043193340301514\tbatch loss relevance\t0.0008128176559694111\n",
      "batch loss nmt\t3.4272327423095703\tbatch loss relevance\t0.0012118577724322677\n",
      "batch loss nmt\t4.298079967498779\tbatch loss relevance\t0.0010051163844764233\n",
      "batch loss nmt\t3.1756844520568848\tbatch loss relevance\t0.0010943632805719972\n",
      "batch loss nmt\t3.616023063659668\tbatch loss relevance\t0.0010881531052291393\n",
      "batch loss nmt\t4.73473596572876\tbatch loss relevance\t0.0009855430107563734\n",
      "batch loss nmt\t3.1332271099090576\tbatch loss relevance\t0.0008803422097116709\n",
      "batch loss nmt\t3.250188112258911\tbatch loss relevance\t0.0009478983702138066\n",
      "batch loss nmt\t3.2223105430603027\tbatch loss relevance\t0.0011172915110364556\n",
      "batch loss nmt\t3.703066825866699\tbatch loss relevance\t0.0010400181636214256\n",
      "batch loss nmt\t3.7099428176879883\tbatch loss relevance\t0.0010992070892825723\n",
      "batch loss nmt\t3.8457388877868652\tbatch loss relevance\t0.0012101855827495456\n",
      "batch loss nmt\t3.3213298320770264\tbatch loss relevance\t0.0009917239658534527\n",
      "batch loss nmt\t3.403550386428833\tbatch loss relevance\t0.0009362185373902321\n",
      "batch loss nmt\t3.66050386428833\tbatch loss relevance\t0.0010584781412035227\n",
      "batch loss nmt\t3.532320499420166\tbatch loss relevance\t0.000860016152728349\n",
      "batch loss nmt\t3.351154088973999\tbatch loss relevance\t0.0008245097706094384\n",
      "batch loss nmt\t3.5046403408050537\tbatch loss relevance\t0.0011081864358857274\n",
      "batch loss nmt\t4.228479385375977\tbatch loss relevance\t0.001131913042627275\n",
      "batch loss nmt\t3.372265100479126\tbatch loss relevance\t0.0011123534059152007\n",
      "batch loss nmt\t2.7327215671539307\tbatch loss relevance\t0.0008809620048850775\n",
      "batch loss nmt\t3.3897342681884766\tbatch loss relevance\t0.001213287585414946\n",
      "batch loss nmt\t4.202864646911621\tbatch loss relevance\t0.0010077127953991294\n",
      "batch loss nmt\t3.053725481033325\tbatch loss relevance\t0.0009816847741603851\n",
      "batch loss nmt\t3.7127296924591064\tbatch loss relevance\t0.001116346102207899\n",
      "batch loss nmt\t3.376462697982788\tbatch loss relevance\t0.0013336316915228963\n",
      "batch loss nmt\t3.3422374725341797\tbatch loss relevance\t0.0011285750661045313\n",
      "batch loss nmt\t5.603038311004639\tbatch loss relevance\t0.0007311950321309268\n",
      "batch loss nmt\t2.9793894290924072\tbatch loss relevance\t0.0007749701035209\n",
      "batch loss nmt\t3.725921869277954\tbatch loss relevance\t0.0009741479298099875\n",
      "batch loss nmt\t3.2485039234161377\tbatch loss relevance\t0.001065600081346929\n",
      "batch loss nmt\t3.8530335426330566\tbatch loss relevance\t0.001183990272693336\n",
      "batch loss nmt\t3.438119888305664\tbatch loss relevance\t0.0009519960731267929\n",
      "batch loss nmt\t3.444236993789673\tbatch loss relevance\t0.001108835218474269\n",
      "batch loss nmt\t4.155533313751221\tbatch loss relevance\t0.0010950943687930703\n",
      "batch loss nmt\t3.403019428253174\tbatch loss relevance\t0.0009702792740426958\n",
      "batch loss nmt\t3.9194483757019043\tbatch loss relevance\t0.0012573441490530968\n",
      "batch loss nmt\t3.63006854057312\tbatch loss relevance\t0.0011065409053117037\n",
      "batch loss nmt\t3.8035309314727783\tbatch loss relevance\t0.0011959525290876627\n",
      "batch loss nmt\t4.658357620239258\tbatch loss relevance\t0.0012054538819938898\n",
      "batch loss nmt\t3.5363869667053223\tbatch loss relevance\t0.0009169802651740611\n",
      "batch loss nmt\t4.224828243255615\tbatch loss relevance\t0.001052651321515441\n",
      "batch loss nmt\t3.590907335281372\tbatch loss relevance\t0.0010419829050078988\n",
      "batch loss nmt\t3.6483705043792725\tbatch loss relevance\t0.0009891302324831486\n",
      "batch loss nmt\t4.399130344390869\tbatch loss relevance\t0.0013334787217900157\n",
      "batch loss nmt\t4.8089704513549805\tbatch loss relevance\t0.0009855963289737701\n",
      "batch loss nmt\t3.865058183670044\tbatch loss relevance\t0.0010771009838208556\n",
      "batch loss nmt\t3.6805200576782227\tbatch loss relevance\t0.0011004672851413488\n",
      "batch loss nmt\t3.6171984672546387\tbatch loss relevance\t0.0011610232759267092\n",
      "batch loss nmt\t3.7829718589782715\tbatch loss relevance\t0.0010870962869375944\n",
      "batch loss nmt\t3.956918239593506\tbatch loss relevance\t0.0012707171263173223\n",
      "batch loss nmt\t2.9463891983032227\tbatch loss relevance\t0.0011390920262783766\n",
      "batch loss nmt\t3.438469171524048\tbatch loss relevance\t0.0012351205805316567\n",
      "batch loss nmt\t3.209965229034424\tbatch loss relevance\t0.0009338725940324366\n",
      "batch loss nmt\t3.811523199081421\tbatch loss relevance\t0.0011919784592464566\n",
      "batch loss nmt\t3.2445507049560547\tbatch loss relevance\t0.0008940807892940938\n",
      "batch loss nmt\t3.3379502296447754\tbatch loss relevance\t0.0010395710123702884\n",
      "batch loss nmt\t3.956066370010376\tbatch loss relevance\t0.0011861241655424237\n",
      "batch loss nmt\t3.6014175415039062\tbatch loss relevance\t0.0011376506881788373\n",
      "batch loss nmt\t3.2949392795562744\tbatch loss relevance\t0.0008729397086426616\n",
      "batch loss nmt\t3.602147102355957\tbatch loss relevance\t0.001131532364524901\n",
      "batch loss nmt\t3.19797420501709\tbatch loss relevance\t0.001024670316837728\n",
      "batch loss nmt\t3.44954776763916\tbatch loss relevance\t0.0011174026876688004\n",
      "batch loss nmt\t3.9082672595977783\tbatch loss relevance\t0.0009393604705110192\n",
      "batch loss nmt\t3.4222216606140137\tbatch loss relevance\t0.0012023582821711898\n",
      "batch loss nmt\t3.7361199855804443\tbatch loss relevance\t0.0009603066719137132\n",
      "batch loss nmt\t3.595886468887329\tbatch loss relevance\t0.0009709826554171741\n",
      "batch loss nmt\t3.344886302947998\tbatch loss relevance\t0.0010467731626704335\n",
      "batch loss nmt\t3.6877784729003906\tbatch loss relevance\t0.001048035454005003\n",
      "batch loss nmt\t3.600062370300293\tbatch loss relevance\t0.0009840137790888548\n",
      "batch loss nmt\t3.9496161937713623\tbatch loss relevance\t0.0009817997924983501\n",
      "batch loss nmt\t3.7796456813812256\tbatch loss relevance\t0.0008315601735375822\n",
      "batch loss nmt\t4.219177722930908\tbatch loss relevance\t0.0009975354187190533\n",
      "batch loss nmt\t3.3615124225616455\tbatch loss relevance\t0.0010518970666453242\n",
      "batch loss nmt\t3.453660726547241\tbatch loss relevance\t0.0009920677402988076\n",
      "batch loss nmt\t3.6697373390197754\tbatch loss relevance\t0.0011169278295710683\n"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "562\t4.026952743530273\t0.1288\n",
      "563\t3.7012569904327393\t0.1161\n",
      "564\t3.9194936752319336\t0.1258\n",
      "565\t3.9520022869110107\t0.1287\n",
      "566\t3.6345441341400146\t0.1138\n",
      "567\t3.899383068084717\t0.1072\n",
      "568\t4.044710636138916\t0.1083\n",
      "569\t3.638409376144409\t0.1269\n",
      "570\t3.497030019760132\t0.14\n",
      "571\t3.4805984497070312\t0.1396\n",
      "572\t3.638235569000244\t0.1509\n",
      "573\t3.4710140228271484\t0.113\n",
      "574\t3.617884874343872\t0.1044\n",
      "575\t3.409316062927246\t0.1212\n",
      "576\t4.45103645324707\t0.1242\n",
      "577\t3.4970669746398926\t0.1239\n",
      "578\t3.3639256954193115\t0.1421\n",
      "579\t4.9568657875061035\t0.1146\n",
      "580\t3.9203896522521973\t0.1337\n",
      "581\t3.8524386882781982\t0.146\n",
      "582\t3.6283345222473145\t0.1085\n",
      "583\t3.6385562419891357\t0.096\n",
      "584\t3.705982208251953\t0.1192\n",
      "585\t3.5681405067443848\t0.1334\n",
      "586\t3.7330286502838135\t0.1329\n",
      "587\t3.6243698596954346\t0.115\n",
      "588\t3.38537859916687\t0.1223\n",
      "589\t3.7507612705230713\t0.1216\n",
      "590\t3.3929483890533447\t0.1184\n",
      "591\t3.860651969909668\t0.1341\n",
      "592\t2.9980154037475586\t0.1315\n",
      "593\t4.1174726486206055\t0.1327\n",
      "594\t3.728353977203369\t0.1265\n",
      "595\t4.090984344482422\t0.1372\n",
      "596\t3.600748300552368\t0.1218\n",
      "597\t3.990502119064331\t0.1084\n",
      "598\t3.618299722671509\t0.1328\n",
      "599\t3.6736366748809814\t0.1358\n",
      "600\t4.107479095458984\t0.1168\n",
      "601\t3.1915364265441895\t0.1042\n",
      "602\t3.658458709716797\t0.1201\n",
      "603\t3.4234867095947266\t0.1478\n",
      "604\t3.586681842803955\t0.1159\n",
      "605\t3.9184696674346924\t0.1209\n",
      "606\t4.002195358276367\t0.1183\n",
      "607\t3.4464187622070312\t0.1056\n",
      "608\t3.765930652618408\t0.1031\n",
      "609\t3.9406304359436035\t0.1319\n",
      "610\t3.2011406421661377\t0.1368\n",
      "611\t4.339470386505127\t0.117\n",
      "612\t3.4018208980560303\t0.1164\n",
      "613\t3.459650993347168\t0.1329\n",
      "614\t3.982935905456543\t0.114\n",
      "615\t2.7736024856567383\t0.1362\n",
      "616\t4.046878337860107\t0.1244\n",
      "617\t3.7583816051483154\t0.1431\n",
      "618\t3.905574083328247\t0.1199\n",
      "619\t3.754405975341797\t0.1247\n",
      "620\t3.767007827758789\t0.1213\n",
      "621\t3.794839859008789\t0.1283\n",
      "622\t3.7041714191436768\t0.1238\n",
      "623\t3.8986167907714844\t0.1038\n",
      "624\t3.8770627975463867\t0.1031\n",
      "625\t3.4774956703186035\t0.1213\n",
      "626\t3.970538377761841\t0.1139\n",
      "627\t2.978307008743286\t0.101\n",
      "628\t4.221346855163574\t0.1158\n",
      "629\t3.898117780685425\t0.0933\n",
      "630\t3.5850069522857666\t0.1131\n",
      "631\t3.834815502166748\t0.1355\n",
      "632\t3.2949793338775635\t0.1422\n",
      "633\t3.689210891723633\t0.1123\n",
      "634\t3.8975915908813477\t0.0978\n",
      "635\t3.528446674346924\t0.1073\n",
      "636\t4.294792652130127\t0.1268\n",
      "637\t4.233399868011475\t0.1085\n",
      "638\t4.221960544586182\t0.107\n",
      "639\t3.5095818042755127\t0.1009\n",
      "640\t4.246638298034668\t0.1172\n",
      "641\t3.713707208633423\t0.1429\n",
      "642\t0.5627553462982178\t0.1256\n",
      "643\t3.3928210735321045\t0.1235\n",
      "644\t3.770010232925415\t0.1216\n",
      "645\t3.8123743534088135\t0.1275\n",
      "646\t4.219485282897949\t0.1381\n",
      "647\t4.022872447967529\t0.1508\n",
      "648\t3.485078811645508\t0.1384\n",
      "649\t3.9299352169036865\t0.1278\n",
      "650\t3.710665464401245\t0.1218\n",
      "651\t4.272150039672852\t0.1223\n",
      "652\t3.7691962718963623\t0.095\n",
      "653\t3.6737923622131348\t0.1136\n",
      "654\t3.4744203090667725\t0.1182\n",
      "655\t3.5193746089935303\t0.126\n",
      "656\t3.915215492248535\t0.1165\n",
      "657\t3.6398024559020996\t0.114\n",
      "658\t4.144503116607666\t0.1364\n",
      "659\t4.066447734832764\t0.1229\n",
      "660\t3.7219901084899902\t0.1207\n",
      "661\t3.805294990539551\t0.1306\n",
      "662\t3.8296093940734863\t0.1253\n",
      "663\t3.7078511714935303\t0.1131\n",
      "664\t3.4499294757843018\t0.1369\n",
      "665\t3.2554240226745605\t0.1384\n",
      "666\t3.4150121212005615\t0.1269\n",
      "667\t3.7830653190612793\t0.1308\n",
      "668\t4.141863822937012\t0.1409\n",
      "669\t3.6082851886749268\t0.1196\n",
      "670\t4.095395088195801\t0.1185\n",
      "671\t3.523953437805176\t0.1143\n",
      "672\t3.6217687129974365\t0.1224\n",
      "673\t4.017801761627197\t0.1238\n",
      "674\t3.548891544342041\t0.1194\n",
      "675\t3.7300426959991455\t0.1339\n",
      "676\t3.8624448776245117\t0.1308\n",
      "677\t3.847379207611084\t0.1344\n",
      "678\t3.785959005355835\t0.1094\n",
      "679\t3.2807836532592773\t0.1218\n",
      "680\t3.9981539249420166\t0.1353\n",
      "681\t3.9805638790130615\t0.1084\n",
      "682\t3.557253360748291\t0.1593\n",
      "683\t4.061285018920898\t0.144\n",
      "684\t3.6518235206604004\t0.1251\n",
      "685\t3.793940544128418\t0.1227\n",
      "686\t3.30960750579834\t0.1578\n",
      "687\t3.6602141857147217\t0.1146\n",
      "688\t3.741417169570923\t0.1151\n",
      "689\t3.864466905593872\t0.1264\n",
      "690\t1.9809296131134033\t0.105\n",
      "691\t3.808734893798828\t0.1384\n",
      "692\t3.6735546588897705\t0.1368\n",
      "693\t3.6533451080322266\t0.1087\n",
      "694\t3.775538444519043\t0.1378\n",
      "695\t3.617358922958374\t0.0839\n",
      "696\t4.00778341293335\t0.118\n",
      "697\t3.3916749954223633\t0.136\n",
      "698\t3.4433822631835938\t0.1089\n",
      "699\t3.6120734214782715\t0.1049\n",
      "700\t3.4389781951904297\t0.1045\n",
      "701\t4.144984722137451\t0.0914\n",
      "702\t3.772831678390503\t0.1338\n",
      "703\t3.3435568809509277\t0.1358\n",
      "704\t3.5641541481018066\t0.1136\n",
      "705\t4.150755882263184\t0.1276\n",
      "706\t3.7215466499328613\t0.1414\n",
      "707\t3.334289789199829\t0.1099\n",
      "708\t3.689793586730957\t0.096\n",
      "709\t3.6537563800811768\t0.1329\n",
      "710\t4.280359745025635\t0.118\n",
      "711\t4.242412567138672\t0.1258\n",
      "712\t4.212873458862305\t0.1216\n",
      "713\t3.9848952293395996\t0.1324\n",
      "714\t3.539741277694702\t0.1368\n",
      "715\t3.763657569885254\t0.122\n",
      "716\t3.6177682876586914\t0.1195\n",
      "717\t3.61891770362854\t0.147\n",
      "718\t3.7873291969299316\t0.1351\n",
      "719\t3.5999624729156494\t0.1348\n",
      "720\t3.415947437286377\t0.1327\n",
      "721\t3.4706077575683594\t0.1396\n",
      "722\t3.701246500015259\t0.1406\n",
      "723\t3.7185163497924805\t0.1136\n",
      "724\t4.253828048706055\t0.1191\n",
      "725\t3.7490992546081543\t0.1156\n",
      "726\t3.8242781162261963\t0.1279\n",
      "727\t3.523639678955078\t0.11\n",
      "728\t5.230822563171387\t0.1287\n",
      "729\t3.723968744277954\t0.1136\n",
      "730\t3.7021985054016113\t0.1283\n",
      "731\t4.290334701538086\t0.114\n",
      "732\t3.7531578540802\t0.1256\n",
      "733\t3.7272815704345703\t0.1452\n",
      "734\t4.030740261077881\t0.1084\n",
      "735\t3.675081729888916\t0.1237\n",
      "736\t3.324098587036133\t0.1306\n",
      "737\t3.88352370262146\t0.1247\n",
      "738\t4.009068012237549\t0.1064\n",
      "739\t4.187717914581299\t0.1103\n",
      "740\t4.241209030151367\t0.1084\n",
      "741\t4.55808162689209\t0.1112\n",
      "742\t3.381455898284912\t0.1079\n",
      "743\t3.618112087249756\t0.1379\n",
      "744\t3.449676513671875\t0.1241\n",
      "745\t3.843655824661255\t0.1399\n",
      "746\t3.8441312313079834\t0.1242\n",
      "747\t3.4725992679595947\t0.1339\n",
      "748\t3.4117774963378906\t0.1302\n",
      "749\t3.7326622009277344\t0.1313\n",
      "750\t3.3138716220855713\t0.1404\n",
      "751\t3.5448074340820312\t0.1313\n",
      "752\t3.787595272064209\t0.1023\n",
      "753\t3.651839017868042\t0.1281\n",
      "754\t3.518950939178467\t0.1366\n",
      "755\t4.032787322998047\t0.158\n",
      "756\t4.167116165161133\t0.1312\n",
      "757\t3.730396032333374\t0.1266\n",
      "758\t3.9532642364501953\t0.1259\n",
      "759\t4.015796661376953\t0.1051\n",
      "760\t3.4244349002838135\t0.1408\n",
      "761\t3.617323637008667\t0.1098\n",
      "762\t3.398361921310425\t0.1155\n",
      "763\t3.676621198654175\t0.1421\n",
      "764\t4.2062788009643555\t0.1337\n",
      "765\t4.019139289855957\t0.1287\n",
      "766\t4.055509567260742\t0.1375\n",
      "767\t3.6457574367523193\t0.1459\n",
      "768\t4.0118279457092285\t0.1312\n",
      "769\t3.416771411895752\t0.1263\n",
      "770\t3.8586971759796143\t0.1385\n",
      "771\t3.5841100215911865\t0.1137\n",
      "772\t3.763979911804199\t0.1274\n",
      "773\t3.7189528942108154\t0.1624\n",
      "774\t3.617597818374634\t0.1196\n",
      "775\t3.6751163005828857\t0.1043\n",
      "776\t3.690650224685669\t0.1317\n",
      "777\t3.8453171253204346\t0.128\n",
      "778\t4.088212966918945\t0.14\n",
      "779\t3.7541983127593994\t0.1388\n",
      "780\t3.860689640045166\t0.1414\n",
      "781\t3.5553605556488037\t0.1532\n",
      "782\t3.829646348953247\t0.1373\n",
      "783\t3.5754029750823975\t0.1204\n",
      "784\t3.60113787651062\t0.13\n",
      "785\t3.714738607406616\t0.1298\n",
      "786\t3.8112382888793945\t0.1238\n",
      "787\t3.5787885189056396\t0.1249\n",
      "788\t3.752730131149292\t0.106\n",
      "789\t3.8830292224884033\t0.1124\n",
      "790\t3.7614004611968994\t0.1147\n",
      "791\t3.657496690750122\t0.127\n",
      "792\t3.6742892265319824\t0.1193\n",
      "793\t3.8683407306671143\t0.1266\n",
      "794\t3.6699278354644775\t0.1406\n",
      "795\t4.0437092781066895\t0.1193\n",
      "796\t3.6982524394989014\t0.1134\n",
      "797\t4.56431245803833\t0.1261\n",
      "798\t3.3013241291046143\t0.1183\n",
      "799\t3.6994059085845947\t0.1419\n",
      "800\t3.5613906383514404\t0.0992\n",
      "801\t3.6958563327789307\t0.125\n",
      "802\t3.452152729034424\t0.1158\n",
      "803\t3.6052589416503906\t0.0939\n",
      "804\t3.181318521499634\t0.0839\n",
      "805\t3.8486416339874268\t0.1341\n",
      "806\t3.965024948120117\t0.1124\n",
      "807\t3.352855920791626\t0.1587\n",
      "808\t3.819504976272583\t0.1323\n",
      "809\t3.846158027648926\t0.1205\n",
      "810\t3.836740493774414\t0.1194\n",
      "811\t4.127979278564453\t0.1193\n",
      "812\t3.4022340774536133\t0.1168\n",
      "813\t4.109687328338623\t0.1181\n",
      "814\t3.913564920425415\t0.1193\n",
      "815\t3.5135343074798584\t0.1275\n",
      "816\t3.862086534500122\t0.1404\n",
      "817\t3.426621198654175\t0.1081\n",
      "818\t3.325183868408203\t0.121\n",
      "819\t3.6870360374450684\t0.1181\n",
      "820\t3.6273961067199707\t0.1009\n",
      "821\t4.354398250579834\t0.1148\n",
      "822\t4.272198677062988\t0.1258\n",
      "823\t3.5723817348480225\t0.1179\n",
      "824\t3.6259982585906982\t0.1207\n",
      "825\t3.6485936641693115\t0.1143\n",
      "826\t3.41428804397583\t0.139\n",
      "827\t4.0351786613464355\t0.1182\n",
      "828\t4.212143898010254\t0.1293\n",
      "829\t3.92146372795105\t0.1325\n",
      "830\t3.9024529457092285\t0.1292\n",
      "831\t3.5669562816619873\t0.1199\n",
      "832\t3.914269208908081\t0.1245\n",
      "833\t3.8256676197052\t0.108\n",
      "834\t3.719663619995117\t0.1174\n",
      "835\t3.703773260116577\t0.1131\n",
      "836\t3.4348955154418945\t0.1388\n",
      "837\t3.82521653175354\t0.1011\n",
      "838\t3.9237122535705566\t0.1546\n",
      "839\t4.492525100708008\t0.1185\n",
      "840\t4.113147258758545\t0.1312\n",
      "841\t3.6343443393707275\t0.104\n"
=======
      "batch loss nmt\t3.916616439819336\tbatch loss relevance\t0.0010815797140821815\n",
      "batch loss nmt\t2.956608533859253\tbatch loss relevance\t0.001271490822546184\n",
      "batch loss nmt\t3.2485358715057373\tbatch loss relevance\t0.0009092307300306857\n",
      "batch loss nmt\t5.3271636962890625\tbatch loss relevance\t0.0008951313211582601\n",
      "batch loss nmt\t3.921205997467041\tbatch loss relevance\t0.001148649607785046\n",
      "batch loss nmt\t4.175078868865967\tbatch loss relevance\t0.001282929559238255\n",
      "batch loss nmt\t3.473825693130493\tbatch loss relevance\t0.000978829455561936\n",
      "batch loss nmt\t3.271925210952759\tbatch loss relevance\t0.0011589991627261043\n",
      "batch loss nmt\t3.895723819732666\tbatch loss relevance\t0.001215469092130661\n",
      "batch loss nmt\t3.3283004760742188\tbatch loss relevance\t0.0010154631454497576\n",
      "batch loss nmt\t2.3892605304718018\tbatch loss relevance\t0.0007606518338434398\n",
      "batch loss nmt\t3.9296040534973145\tbatch loss relevance\t0.0010820127790793777\n",
      "batch loss nmt\t3.375784397125244\tbatch loss relevance\t0.0009171876590698957\n",
      "batch loss nmt\t3.116689920425415\tbatch loss relevance\t0.0009828906040638685\n",
      "batch loss nmt\t3.1779680252075195\tbatch loss relevance\t0.0010339143918827176\n",
      "batch loss nmt\t3.556091070175171\tbatch loss relevance\t0.0010511077707633376\n",
      "batch loss nmt\t4.339078903198242\tbatch loss relevance\t0.0008131446084007621\n",
      "batch loss nmt\t3.37284779548645\tbatch loss relevance\t0.0011488485615700483\n",
      "batch loss nmt\t3.5154151916503906\tbatch loss relevance\t0.0010986420093104243\n",
      "batch loss nmt\t4.31063985824585\tbatch loss relevance\t0.0011465824209153652\n",
      "batch loss nmt\t3.84562611579895\tbatch loss relevance\t0.001119166612625122\n",
      "batch loss nmt\t3.719040632247925\tbatch loss relevance\t0.0011521176202222705\n",
      "batch loss nmt\t4.469767093658447\tbatch loss relevance\t0.0008523165597580373\n",
      "batch loss nmt\t3.07879638671875\tbatch loss relevance\t0.0009567175293341279\n",
      "batch loss nmt\t3.5802173614501953\tbatch loss relevance\t0.0010172930778935552\n",
      "batch loss nmt\t3.8655009269714355\tbatch loss relevance\t0.0009520901367068291\n",
      "batch loss nmt\t3.959709644317627\tbatch loss relevance\t0.0010145669803023338\n",
      "batch loss nmt\t4.509698867797852\tbatch loss relevance\t0.0013214487116783857\n",
      "batch loss nmt\t3.55263090133667\tbatch loss relevance\t0.001176112680695951\n",
      "batch loss nmt\t3.553278684616089\tbatch loss relevance\t0.0010532180313020945\n",
      "batch loss nmt\t4.345617294311523\tbatch loss relevance\t0.001057033659890294\n",
      "batch loss nmt\t3.5730140209198\tbatch loss relevance\t0.001001246739178896\n",
      "batch loss nmt\t3.9180004596710205\tbatch loss relevance\t0.0011364379897713661\n",
      "batch loss nmt\t3.5825092792510986\tbatch loss relevance\t0.0010234961519017816\n",
      "batch loss nmt\t3.3165159225463867\tbatch loss relevance\t0.0008444178383797407\n",
      "batch loss nmt\t3.2998335361480713\tbatch loss relevance\t0.0012359031243249774\n",
      "batch loss nmt\t3.4721503257751465\tbatch loss relevance\t0.0010978039354085922\n",
      "batch loss nmt\t3.449049472808838\tbatch loss relevance\t0.0009522614418528974\n",
      "batch loss nmt\t3.4381496906280518\tbatch loss relevance\t0.0008910546312108636\n",
      "batch loss nmt\t3.3529458045959473\tbatch loss relevance\t0.0010801941389217973\n",
      "batch loss nmt\t3.7419793605804443\tbatch loss relevance\t0.0010347453644499183\n",
      "batch loss nmt\t3.151691198348999\tbatch loss relevance\t0.0010413939598947763\n",
      "batch loss nmt\t3.869126319885254\tbatch loss relevance\t0.0011406148551031947\n",
      "batch loss nmt\t3.2503409385681152\tbatch loss relevance\t0.0012834869557991624\n",
      "batch loss nmt\t2.9360885620117188\tbatch loss relevance\t0.0008967079338617623\n",
      "batch loss nmt\t3.8316614627838135\tbatch loss relevance\t0.0010987090645357966\n",
      "batch loss nmt\t3.0575459003448486\tbatch loss relevance\t0.0007961525116115808\n",
      "batch loss nmt\t3.6657838821411133\tbatch loss relevance\t0.0011433311738073826\n",
      "batch loss nmt\t3.3274714946746826\tbatch loss relevance\t0.0010418633464723825\n",
      "batch loss nmt\t3.2251973152160645\tbatch loss relevance\t0.0007450862904079258\n",
      "batch loss nmt\t3.349997043609619\tbatch loss relevance\t0.0009663683013059199\n",
      "batch loss nmt\t6.46989107131958\tbatch loss relevance\t0.00081686518387869\n",
      "batch loss nmt\t3.1605193614959717\tbatch loss relevance\t0.00097790511790663\n",
      "batch loss nmt\t3.122302770614624\tbatch loss relevance\t0.0006748611340299249\n",
      "batch loss nmt\t3.9170379638671875\tbatch loss relevance\t0.001184322638437152\n",
      "batch loss nmt\t3.5282909870147705\tbatch loss relevance\t0.001050194725394249\n",
      "batch loss nmt\t3.4633917808532715\tbatch loss relevance\t0.0010999678634107113\n",
      "batch loss nmt\t3.2550954818725586\tbatch loss relevance\t0.0009147122618742287\n",
      "batch loss nmt\t3.5588901042938232\tbatch loss relevance\t0.0011747869430109859\n",
      "batch loss nmt\t2.8051278591156006\tbatch loss relevance\t0.0009140478214249015\n",
      "batch loss nmt\t3.5956101417541504\tbatch loss relevance\t0.0008970057824626565\n",
      "batch loss nmt\t2.8598341941833496\tbatch loss relevance\t0.0008845246047712862\n",
      "batch loss nmt\t3.2664694786071777\tbatch loss relevance\t0.0011512364726513624\n",
      "batch loss nmt\t3.363398551940918\tbatch loss relevance\t0.0009097235160879791\n",
      "batch loss nmt\t4.013720989227295\tbatch loss relevance\t0.0008123236475512385\n",
      "batch loss nmt\t3.6411631107330322\tbatch loss relevance\t0.0011593590024858713\n",
      "batch loss nmt\t3.7121543884277344\tbatch loss relevance\t0.001334065687842667\n",
      "batch loss nmt\t3.322584867477417\tbatch loss relevance\t0.0009752810001373291\n",
      "batch loss nmt\t3.2501790523529053\tbatch loss relevance\t0.0008290673140436411\n",
      "batch loss nmt\t3.06170392036438\tbatch loss relevance\t0.000940922589506954\n",
      "batch loss nmt\t3.2397067546844482\tbatch loss relevance\t0.0010146290296688676\n",
      "batch loss nmt\t3.2524917125701904\tbatch loss relevance\t0.0009652200969867408\n",
      "batch loss nmt\t3.161609411239624\tbatch loss relevance\t0.0009256055345758796\n",
      "batch loss nmt\t3.261073112487793\tbatch loss relevance\t0.0008334108279086649\n",
      "batch loss nmt\t3.4783995151519775\tbatch loss relevance\t0.001087909797206521\n",
      "batch loss nmt\t3.0485923290252686\tbatch loss relevance\t0.0009418470435775816\n",
      "batch loss nmt\t3.8876562118530273\tbatch loss relevance\t0.0010705121094360948\n",
      "batch loss nmt\t3.896940231323242\tbatch loss relevance\t0.001232558861374855\n",
      "batch loss nmt\t3.694507360458374\tbatch loss relevance\t0.0010186131112277508\n",
      "batch loss nmt\t3.199373483657837\tbatch loss relevance\t0.0008879505912773311\n",
      "batch loss nmt\t3.76892352104187\tbatch loss relevance\t0.0013194875791668892\n",
      "batch loss nmt\t3.2424092292785645\tbatch loss relevance\t0.000982845900580287\n",
      "batch loss nmt\t2.962207555770874\tbatch loss relevance\t0.0007868658867664635\n",
      "batch loss nmt\t3.7625441551208496\tbatch loss relevance\t0.0007502197404392064\n",
      "batch loss nmt\t5.137088298797607\tbatch loss relevance\t0.0010760911973193288\n",
      "batch loss nmt\t3.6251955032348633\tbatch loss relevance\t0.0009668354759924114\n",
      "batch loss nmt\t3.7116053104400635\tbatch loss relevance\t0.0011752453865483403\n",
      "batch loss nmt\t3.287248134613037\tbatch loss relevance\t0.0010686070891097188\n",
      "batch loss nmt\t3.332665205001831\tbatch loss relevance\t0.000989989610388875\n",
      "batch loss nmt\t3.6952426433563232\tbatch loss relevance\t0.0007525641121901572\n",
      "batch loss nmt\t3.199305534362793\tbatch loss relevance\t0.0011515722144395113\n",
      "batch loss nmt\t3.660205602645874\tbatch loss relevance\t0.0010552628664299846\n",
      "batch loss nmt\t3.979879856109619\tbatch loss relevance\t0.000949580455198884\n",
      "batch loss nmt\t3.4970386028289795\tbatch loss relevance\t0.0011300895130261779\n",
      "batch loss nmt\t3.599804639816284\tbatch loss relevance\t0.001191231538541615\n",
      "batch loss nmt\t5.907283306121826\tbatch loss relevance\t0.0008604605100117624\n",
      "batch loss nmt\t3.3953301906585693\tbatch loss relevance\t0.0010955698089674115\n",
      "batch loss nmt\t3.8440732955932617\tbatch loss relevance\t0.0010542868403717875\n",
      "batch loss nmt\t3.6633288860321045\tbatch loss relevance\t0.0011109350016340613\n",
      "batch loss nmt\t3.898737668991089\tbatch loss relevance\t0.001255696639418602\n",
      "batch loss nmt\t3.262995481491089\tbatch loss relevance\t0.0010159999364987016\n",
      "batch loss nmt\t3.654824733734131\tbatch loss relevance\t0.0010077145416289568\n",
      "batch loss nmt\t3.580820322036743\tbatch loss relevance\t0.001216920674778521\n",
      "batch loss nmt\t4.673273086547852\tbatch loss relevance\t0.0010996379423886538\n",
      "batch loss nmt\t3.5477001667022705\tbatch loss relevance\t0.0009771467885002494\n",
      "batch loss nmt\t3.6177451610565186\tbatch loss relevance\t0.0011911559849977493\n",
      "batch loss nmt\t3.250913143157959\tbatch loss relevance\t0.0009787328308448195\n",
      "batch loss nmt\t3.393822193145752\tbatch loss relevance\t0.00115560507401824\n"
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "842\t3.574740171432495\t0.1106\n",
      "843\t3.537802219390869\t0.1079\n",
      "844\t7.040840148925781\t0.0944\n",
      "845\t4.069217681884766\t0.104\n",
      "846\t3.348811149597168\t0.0935\n",
      "847\t3.695591926574707\t0.1206\n",
      "848\t3.8270301818847656\t0.1011\n",
      "849\t3.8808112144470215\t0.1365\n",
      "850\t3.49353289604187\t0.1263\n",
      "851\t3.6216282844543457\t0.1278\n",
      "852\t3.261204242706299\t0.1332\n",
      "853\t3.35603666305542\t0.1339\n",
      "854\t3.7005863189697266\t0.1251\n",
      "855\t3.9174134731292725\t0.1088\n",
      "856\t3.4096601009368896\t0.1229\n",
      "857\t3.904186248779297\t0.1366\n",
      "858\t3.3514020442962646\t0.1401\n",
      "859\t4.511240005493164\t0.1239\n",
      "860\t4.234770774841309\t0.1205\n",
      "861\t4.186304569244385\t0.1551\n",
      "862\t4.093225955963135\t0.1288\n",
      "863\t3.710198402404785\t0.1189\n",
      "864\t3.616549015045166\t0.1462\n",
      "865\t3.551891803741455\t0.1349\n",
      "866\t3.7881581783294678\t0.1336\n",
      "867\t3.323939561843872\t0.1244\n",
      "868\t3.6540143489837646\t0.1142\n",
      "869\t3.884939193725586\t0.1357\n",
      "870\t3.5279858112335205\t0.1024\n",
      "871\t3.713823080062866\t0.1145\n",
      "872\t3.917747974395752\t0.147\n",
      "873\t4.324295520782471\t0.1444\n",
      "874\t4.28816556930542\t0.1314\n",
      "875\t3.5879554748535156\t0.1184\n",
      "876\t3.7903223037719727\t0.1187\n",
      "877\t3.8717808723449707\t0.1229\n",
      "878\t3.711318254470825\t0.1215\n",
      "879\t4.314592361450195\t0.1128\n",
      "880\t3.545069932937622\t0.1033\n",
      "881\t3.7235641479492188\t0.1368\n",
      "882\t3.83858060836792\t0.1406\n",
      "883\t3.539257287979126\t0.1301\n",
      "884\t3.4901034832000732\t0.1469\n",
      "885\t3.7928528785705566\t0.1322\n",
      "886\t4.387236595153809\t0.1347\n",
      "887\t4.00874137878418\t0.1405\n",
      "888\t2.5813026428222656\t0.1343\n",
      "889\t4.062050819396973\t0.1365\n",
      "890\t3.4034805297851562\t0.1122\n",
      "891\t3.5712361335754395\t0.1294\n",
      "892\t4.456344127655029\t0.1305\n",
      "893\t3.803093433380127\t0.1157\n",
      "894\t4.011409759521484\t0.1499\n",
      "895\t3.5386881828308105\t0.1494\n",
      "896\t3.356067180633545\t0.1101\n",
      "897\t3.3985934257507324\t0.1402\n",
      "898\t3.750072717666626\t0.1357\n",
      "899\t3.6495957374572754\t0.1363\n",
      "900\t3.767773389816284\t0.1141\n",
      "901\t4.090635299682617\t0.1165\n",
      "902\t3.529747486114502\t0.1409\n",
      "903\t3.9046144485473633\t0.1174\n",
      "904\t4.253521919250488\t0.1312\n",
      "905\t3.2213780879974365\t0.1288\n",
      "906\t3.305046558380127\t0.1399\n",
      "907\t3.7588648796081543\t0.1257\n",
      "908\t5.2511773109436035\t0.1458\n",
      "909\t3.2264113426208496\t0.126\n",
      "910\t4.049945831298828\t0.1338\n",
      "911\t3.550093173980713\t0.1269\n",
      "912\t3.424879550933838\t0.1238\n",
      "913\t3.6254146099090576\t0.1239\n",
      "914\t3.689638376235962\t0.1099\n",
      "915\t3.1593666076660156\t0.1297\n",
      "916\t3.88517689704895\t0.0977\n",
      "917\t3.6249709129333496\t0.1186\n",
      "918\t3.7419960498809814\t0.1419\n",
      "919\t3.7539079189300537\t0.1014\n",
      "920\t3.3784046173095703\t0.1218\n",
      "921\t4.696004867553711\t0.1003\n",
      "922\t3.3314778804779053\t0.1051\n",
      "923\t3.5960071086883545\t0.1115\n",
      "924\t4.614121913909912\t0.1149\n",
      "925\t3.7702996730804443\t0.1268\n",
      "926\t3.6464450359344482\t0.0997\n",
      "927\t4.168426990509033\t0.1159\n",
      "928\t3.1730270385742188\t0.1053\n",
      "929\t3.886803388595581\t0.1033\n",
      "930\t4.264165878295898\t0.0902\n",
      "931\t3.3665213584899902\t0.099\n",
      "932\t3.795675039291382\t0.1224\n",
      "933\t4.594769477844238\t0.1135\n",
      "934\t3.7098147869110107\t0.1293\n",
      "935\t4.106024742126465\t0.1425\n",
      "936\t3.608376979827881\t0.116\n",
      "937\t3.3508448600769043\t0.1293\n",
      "938\t3.9190256595611572\t0.1362\n",
      "939\t4.158244609832764\t0.1236\n",
      "940\t2.363457441329956\t0.1013\n",
      "25823944m: epoch 2 [####################]  100%  loss = 3.581\n",
      "epoch 2 complete, loss = 3.581\n",
      "941\t2.369723320007324\t0.1125\n",
      "942\t4.15231990814209\t0.0954\n",
      "943\t3.419142007827759\t0.1458\n",
      "944\t3.645662307739258\t0.1321\n",
      "945\t3.362238883972168\t0.1336\n",
      "946\t4.149392604827881\t0.1171\n",
      "947\t4.400598049163818\t0.1258\n",
      "948\t3.46882700920105\t0.0942\n",
      "949\t3.8612070083618164\t0.0991\n",
      "950\t4.033749580383301\t0.1611\n",
      "951\t3.5138468742370605\t0.1026\n",
      "952\t4.2239251136779785\t0.1234\n",
      "953\t3.7642602920532227\t0.1304\n",
      "954\t3.5983598232269287\t0.1396\n",
      "955\t3.6616604328155518\t0.1171\n",
      "956\t3.5670166015625\t0.1372\n",
      "957\t3.5877318382263184\t0.1184\n",
      "958\t3.841691732406616\t0.118\n",
      "959\t3.923116445541382\t0.1402\n",
      "960\t3.6098837852478027\t0.1249\n",
      "961\t4.308462619781494\t0.1298\n",
      "962\t3.345775842666626\t0.1213\n",
      "963\t3.4243993759155273\t0.1299\n",
      "964\t3.580791711807251\t0.1347\n",
      "965\t3.7197165489196777\t0.1147\n",
      "966\t2.718130111694336\t0.1003\n",
      "967\t4.0009684562683105\t0.1059\n",
      "968\t3.88311505317688\t0.1177\n",
      "969\t3.7033886909484863\t0.1229\n",
      "970\t4.738832950592041\t0.0946\n",
      "971\t3.5469446182250977\t0.1377\n",
      "972\t3.65454363822937\t0.1265\n",
      "973\t3.783616781234741\t0.1251\n",
      "974\t3.8776814937591553\t0.1154\n",
      "975\t3.4153435230255127\t0.0897\n",
      "976\t3.3018598556518555\t0.1353\n",
      "977\t3.4411959648132324\t0.1199\n",
      "978\t3.2649030685424805\t0.1274\n",
      "979\t3.651482105255127\t0.1108\n",
      "980\t4.2509307861328125\t0.132\n",
      "981\t3.6356756687164307\t0.1228\n",
      "982\t4.14185905456543\t0.1233\n",
      "983\t3.429711103439331\t0.1014\n",
      "984\t3.498185634613037\t0.126\n",
      "985\t3.6141369342803955\t0.1313\n",
      "986\t3.427546262741089\t0.1109\n",
      "987\t3.6966071128845215\t0.124\n",
      "988\t3.2535762786865234\t0.1182\n",
      "989\t3.708214282989502\t0.1339\n",
      "990\t3.5096662044525146\t0.1364\n",
      "991\t3.917982578277588\t0.1572\n",
      "992\t4.036849498748779\t0.1454\n",
      "993\t3.50833797454834\t0.1426\n",
      "994\t3.9210727214813232\t0.1231\n",
      "995\t3.4424688816070557\t0.1237\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '(most'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-54f5f479f5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#torch.cuda.empty_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-1ce3ca2585d0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, opt, SRC, TRG)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m#print(line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mmAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0;31m#print(\"current mAP is\\t\" + str(mAP))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m#print(\"best mAP so far is\\t\" + str(best_mAP))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '(most'"
=======
      "batch loss nmt\t3.434131383895874\tbatch loss relevance\t0.001101725036278367\n",
      "batch loss nmt\t3.371295213699341\tbatch loss relevance\t0.0010491220746189356\n",
      "batch loss nmt\t3.0639970302581787\tbatch loss relevance\t0.0007825753418728709\n",
      "batch loss nmt\t3.508134603500366\tbatch loss relevance\t0.0008919449173845351\n",
      "batch loss nmt\t3.9266021251678467\tbatch loss relevance\t0.0010746612679213285\n",
      "batch loss nmt\t3.4207589626312256\tbatch loss relevance\t0.0011934656649827957\n",
      "batch loss nmt\t2.602370500564575\tbatch loss relevance\t0.0007537811761721969\n",
      "batch loss nmt\t3.696828603744507\tbatch loss relevance\t0.0012311340542510152\n",
      "batch loss nmt\t3.4184460639953613\tbatch loss relevance\t0.0011694120476022363\n",
      "batch loss nmt\t4.117323398590088\tbatch loss relevance\t0.0012014230014756322\n",
      "batch loss nmt\t3.443277359008789\tbatch loss relevance\t0.0010439546313136816\n",
      "batch loss nmt\t3.0759878158569336\tbatch loss relevance\t0.0011171289952471852\n",
      "batch loss nmt\t4.273647308349609\tbatch loss relevance\t0.001235686126165092\n",
      "batch loss nmt\t3.560701370239258\tbatch loss relevance\t0.0011154194362461567\n",
      "batch loss nmt\t3.0281424522399902\tbatch loss relevance\t0.0009441311121918261\n",
      "batch loss nmt\t3.411083459854126\tbatch loss relevance\t0.0012615752639248967\n",
      "batch loss nmt\t3.1548850536346436\tbatch loss relevance\t0.0012258619535714388\n",
      "batch loss nmt\t3.989537239074707\tbatch loss relevance\t0.0011524599976837635\n",
      "batch loss nmt\t2.990156888961792\tbatch loss relevance\t0.000869213545229286\n",
      "batch loss nmt\t3.8986432552337646\tbatch loss relevance\t0.0012140043545514345\n",
      "batch loss nmt\t4.109518051147461\tbatch loss relevance\t0.0011143888114020228\n",
      "batch loss nmt\t3.6533255577087402\tbatch loss relevance\t0.0011459427187219262\n",
      "batch loss nmt\t3.388441801071167\tbatch loss relevance\t0.0011434168554842472\n",
      "batch loss nmt\t3.487265110015869\tbatch loss relevance\t0.0009773304918780923\n",
      "batch loss nmt\t3.86966609954834\tbatch loss relevance\t0.0012718592770397663\n",
      "batch loss nmt\t4.223562240600586\tbatch loss relevance\t0.0012939084554091096\n",
      "batch loss nmt\t3.630722761154175\tbatch loss relevance\t0.0009982117917388678\n",
      "batch loss nmt\t3.4934375286102295\tbatch loss relevance\t0.001103507704101503\n",
      "batch loss nmt\t3.232262134552002\tbatch loss relevance\t0.001238020253367722\n",
      "batch loss nmt\t3.0560715198516846\tbatch loss relevance\t0.000955430616158992\n",
      "batch loss nmt\t3.5290374755859375\tbatch loss relevance\t0.0012455626856535673\n",
      "batch loss nmt\t2.5857608318328857\tbatch loss relevance\t0.0007341548334807158\n",
      "batch loss nmt\t3.8577346801757812\tbatch loss relevance\t0.001221419544890523\n",
      "batch loss nmt\t3.0034797191619873\tbatch loss relevance\t0.0007241078419610858\n",
      "batch loss nmt\t3.522076368331909\tbatch loss relevance\t0.0011402061209082603\n",
      "batch loss nmt\t3.3637399673461914\tbatch loss relevance\t0.001113707316108048\n",
      "batch loss nmt\t3.707688331604004\tbatch loss relevance\t0.0009684301330707967\n",
      "batch loss nmt\t3.17822527885437\tbatch loss relevance\t0.0010919517371803522\n",
      "batch loss nmt\t3.2587804794311523\tbatch loss relevance\t0.001026407117024064\n",
      "batch loss nmt\t3.590432643890381\tbatch loss relevance\t0.001143897883594036\n",
      "batch loss nmt\t2.9323766231536865\tbatch loss relevance\t0.0009382349089719355\n",
      "batch loss nmt\t3.146235942840576\tbatch loss relevance\t0.0010162630351260304\n",
      "batch loss nmt\t3.554468870162964\tbatch loss relevance\t0.0010699514532461762\n",
      "batch loss nmt\t3.44985032081604\tbatch loss relevance\t0.0009100415045395494\n",
      "batch loss nmt\t3.963186502456665\tbatch loss relevance\t0.0009696830529719591\n",
      "batch loss nmt\t3.2251458168029785\tbatch loss relevance\t0.00116869923658669\n",
      "batch loss nmt\t3.0397391319274902\tbatch loss relevance\t0.0008089190232567489\n",
      "batch loss nmt\t3.2187509536743164\tbatch loss relevance\t0.001013091066852212\n",
      "batch loss nmt\t4.248065948486328\tbatch loss relevance\t0.0012440055143088102\n",
      "batch loss nmt\t2.9126527309417725\tbatch loss relevance\t0.0008348295232281089\n",
      "batch loss nmt\t3.3419172763824463\tbatch loss relevance\t0.0009267253335565329\n",
      "batch loss nmt\t4.144440174102783\tbatch loss relevance\t0.0011371779255568981\n",
      "batch loss nmt\t3.3684582710266113\tbatch loss relevance\t0.0010463199578225613\n",
      "batch loss nmt\t3.589512586593628\tbatch loss relevance\t0.0012234365567564964\n",
      "batch loss nmt\t5.536183834075928\tbatch loss relevance\t0.0008589593344368041\n",
      "batch loss nmt\t3.470637559890747\tbatch loss relevance\t0.000624434498604387\n",
      "batch loss nmt\t3.371131658554077\tbatch loss relevance\t0.0009936676360666752\n",
      "batch loss nmt\t3.6646945476531982\tbatch loss relevance\t0.0009427218465134501\n",
      "batch loss nmt\t3.653367519378662\tbatch loss relevance\t0.0012132630217820406\n",
      "batch loss nmt\t4.009143352508545\tbatch loss relevance\t0.001056527136825025\n",
      "batch loss nmt\t3.5797669887542725\tbatch loss relevance\t0.0011158768320456147\n",
      "batch loss nmt\t3.347029685974121\tbatch loss relevance\t0.0010727145709097385\n",
      "batch loss nmt\t3.6662395000457764\tbatch loss relevance\t0.0009108109516091645\n",
      "batch loss nmt\t3.4557955265045166\tbatch loss relevance\t0.0010270876809954643\n",
      "batch loss nmt\t3.8639416694641113\tbatch loss relevance\t0.0009447126067243516\n",
      "batch loss nmt\t3.6328177452087402\tbatch loss relevance\t0.0011349041014909744\n",
      "batch loss nmt\t3.343956470489502\tbatch loss relevance\t0.0008858799701556563\n",
      "batch loss nmt\t3.5881049633026123\tbatch loss relevance\t0.0010507525876164436\n",
      "batch loss nmt\t3.2674577236175537\tbatch loss relevance\t0.0009330080356448889\n",
      "batch loss nmt\t3.453418254852295\tbatch loss relevance\t0.0011563090374693274\n",
      "batch loss nmt\t3.8648369312286377\tbatch loss relevance\t0.001264646416530013\n",
      "batch loss nmt\t3.3830933570861816\tbatch loss relevance\t0.0011807912960648537\n",
      "batch loss nmt\t3.711167097091675\tbatch loss relevance\t0.0010354956611990929\n",
      "batch loss nmt\t3.3033907413482666\tbatch loss relevance\t0.0009794372599571943\n",
      "batch loss nmt\t3.541882276535034\tbatch loss relevance\t0.0008695420692674816\n",
      "batch loss nmt\t3.6243703365325928\tbatch loss relevance\t0.0008620687294751406\n",
      "batch loss nmt\t2.925077438354492\tbatch loss relevance\t0.0010248272446915507\n",
      "batch loss nmt\t2.972536563873291\tbatch loss relevance\t0.0008614305406808853\n",
      "batch loss nmt\t3.4831485748291016\tbatch loss relevance\t0.0010200547985732555\n",
      "batch loss nmt\t3.2214150428771973\tbatch loss relevance\t0.0011178326094523072\n",
      "batch loss nmt\t3.8444859981536865\tbatch loss relevance\t0.0009778653038665652\n",
      "batch loss nmt\t3.1574018001556396\tbatch loss relevance\t0.001174601842649281\n",
      "batch loss nmt\t3.8068490028381348\tbatch loss relevance\t0.0009831476490944624\n",
      "batch loss nmt\t3.3342902660369873\tbatch loss relevance\t0.0011970613850280643\n",
      "batch loss nmt\t3.3227152824401855\tbatch loss relevance\t0.0009300297242589295\n",
      "batch loss nmt\t3.3130056858062744\tbatch loss relevance\t0.0009415671811439097\n",
      "batch loss nmt\t3.690955877304077\tbatch loss relevance\t0.0012397661339491606\n",
      "batch loss nmt\t3.334951877593994\tbatch loss relevance\t0.0012432707007974386\n",
      "batch loss nmt\t3.7282493114471436\tbatch loss relevance\t0.0010690190829336643\n",
      "batch loss nmt\t3.263272523880005\tbatch loss relevance\t0.0009981166804209352\n",
      "batch loss nmt\t3.746950626373291\tbatch loss relevance\t0.0011792469304054976\n",
      "batch loss nmt\t4.467623710632324\tbatch loss relevance\t0.0008249198435805738\n",
      "batch loss nmt\t3.608139991760254\tbatch loss relevance\t0.0009924101177603006\n",
      "batch loss nmt\t3.4977242946624756\tbatch loss relevance\t0.0011023682309314609\n",
      "batch loss nmt\t3.4461419582366943\tbatch loss relevance\t0.001035583671182394\n",
      "batch loss nmt\t3.8020546436309814\tbatch loss relevance\t0.0010434795403853059\n",
      "batch loss nmt\t3.113638401031494\tbatch loss relevance\t0.0011525667505338788\n",
      "batch loss nmt\t3.7174196243286133\tbatch loss relevance\t0.0010059423511847854\n",
      "batch loss nmt\t4.538175582885742\tbatch loss relevance\t0.0010918936459347606\n",
      "batch loss nmt\t5.2985734939575195\tbatch loss relevance\t0.0009637156035751104\n",
      "batch loss nmt\t3.8422691822052\tbatch loss relevance\t0.00119536102283746\n",
      "batch loss nmt\t3.275212049484253\tbatch loss relevance\t0.0007303277961909771\n",
      "batch loss nmt\t4.402937412261963\tbatch loss relevance\t0.0012497976422309875\n",
      "batch loss nmt\t3.377547264099121\tbatch loss relevance\t0.0009052612003870308\n",
      "batch loss nmt\t3.9287824630737305\tbatch loss relevance\t0.0009788359748199582\n",
      "batch loss nmt\t4.043777942657471\tbatch loss relevance\t0.0011707418598234653\n",
      "batch loss nmt\t3.9248578548431396\tbatch loss relevance\t0.0009836418321356177\n",
      "batch loss nmt\t4.0781145095825195\tbatch loss relevance\t0.0008633379475213587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss nmt\t3.3501813411712646\tbatch loss relevance\t0.0010094150202348828\n",
      "batch loss nmt\t3.655226707458496\tbatch loss relevance\t0.0011737587628886104\n",
      "batch loss nmt\t4.398533821105957\tbatch loss relevance\t0.001104828086681664\n",
      "batch loss nmt\t3.6219351291656494\tbatch loss relevance\t0.0010510438587516546\n",
      "batch loss nmt\t4.000452518463135\tbatch loss relevance\t0.001125519396737218\n",
      "batch loss nmt\t3.450496196746826\tbatch loss relevance\t0.0011298557510599494\n",
      "batch loss nmt\t4.014549732208252\tbatch loss relevance\t0.0009687395649962127\n",
      "batch loss nmt\t3.1225223541259766\tbatch loss relevance\t0.0011117263929918408\n",
      "batch loss nmt\t2.9937846660614014\tbatch loss relevance\t0.0009498040308244526\n",
      "batch loss nmt\t3.500291585922241\tbatch loss relevance\t0.0010741642909124494\n",
      "batch loss nmt\t3.617668628692627\tbatch loss relevance\t0.0008513002539984882\n",
      "batch loss nmt\t3.2518739700317383\tbatch loss relevance\t0.000814013066701591\n",
      "batch loss nmt\t3.4443349838256836\tbatch loss relevance\t0.0008819758077152073\n",
      "batch loss nmt\t4.47337532043457\tbatch loss relevance\t0.0011726584052667022\n",
      "batch loss nmt\t2.9490928649902344\tbatch loss relevance\t0.0008518221438862383\n",
      "batch loss nmt\t2.9692258834838867\tbatch loss relevance\t0.0010811794782057405\n",
      "batch loss nmt\t3.4561140537261963\tbatch loss relevance\t0.0010160267120227218\n",
      "batch loss nmt\t3.7271153926849365\tbatch loss relevance\t0.0011301510967314243\n",
      "batch loss nmt\t3.3136098384857178\tbatch loss relevance\t0.0011299713514745235\n",
      "batch loss nmt\t4.401864051818848\tbatch loss relevance\t0.001230721129104495\n",
      "batch loss nmt\t3.5015859603881836\tbatch loss relevance\t0.0011230668751522899\n",
      "batch loss nmt\t3.6365654468536377\tbatch loss relevance\t0.0011352119036018848\n",
      "batch loss nmt\t3.7799179553985596\tbatch loss relevance\t0.0009756016661413014\n",
      "batch loss nmt\t3.2409427165985107\tbatch loss relevance\t0.001290066516958177\n",
      "batch loss nmt\t3.340564012527466\tbatch loss relevance\t0.0010024865623563528\n",
      "batch loss nmt\t4.786174297332764\tbatch loss relevance\t0.0011773682199418545\n",
      "batch loss nmt\t3.4051764011383057\tbatch loss relevance\t0.0010607052827253938\n",
      "batch loss nmt\t3.17792010307312\tbatch loss relevance\t0.0009727374999783933\n",
      "batch loss nmt\t5.337592601776123\tbatch loss relevance\t0.0008676698780618608\n",
      "batch loss nmt\t3.366302013397217\tbatch loss relevance\t0.0009629697306081653\n",
      "batch loss nmt\t3.241482973098755\tbatch loss relevance\t0.0010582056129351258\n",
      "batch loss nmt\t3.2511110305786133\tbatch loss relevance\t0.0009287609718739986\n",
      "batch loss nmt\t3.692333936691284\tbatch loss relevance\t0.0012035876279696822\n",
      "batch loss nmt\t3.796687364578247\tbatch loss relevance\t0.0010798840085044503\n",
      "batch loss nmt\t4.123923301696777\tbatch loss relevance\t0.001155347446911037\n",
      "batch loss nmt\t3.268277883529663\tbatch loss relevance\t0.0012260820949450135\n",
      "batch loss nmt\t3.568720817565918\tbatch loss relevance\t0.001213282928802073\n",
      "batch loss nmt\t3.670840263366699\tbatch loss relevance\t0.0010752319358289242\n",
      "batch loss nmt\t3.330263376235962\tbatch loss relevance\t0.0012078575091436505\n",
      "batch loss nmt\t3.219538927078247\tbatch loss relevance\t0.0008826861740089953\n",
      "batch loss nmt\t3.566171407699585\tbatch loss relevance\t0.0010263690492138267\n",
      "batch loss nmt\t3.2362608909606934\tbatch loss relevance\t0.0009493962861597538\n",
      "batch loss nmt\t3.3747875690460205\tbatch loss relevance\t0.001127945608459413\n",
      "batch loss nmt\t3.8187508583068848\tbatch loss relevance\t0.0010426443768665195\n",
      "batch loss nmt\t5.679965496063232\tbatch loss relevance\t0.0011694591958075762\n",
      "batch loss nmt\t3.233328342437744\tbatch loss relevance\t0.0009831123752519488\n",
      "batch loss nmt\t3.239518404006958\tbatch loss relevance\t0.0010686847381293774\n",
      "batch loss nmt\t3.193310260772705\tbatch loss relevance\t0.0010207880986854434\n",
      "batch loss nmt\t3.335073947906494\tbatch loss relevance\t0.0009754183702170849\n",
      "batch loss nmt\t3.114457607269287\tbatch loss relevance\t0.0009931889362633228\n",
      "batch loss nmt\t3.3209409713745117\tbatch loss relevance\t0.0010900890920311213\n",
      "batch loss nmt\t3.789459705352783\tbatch loss relevance\t0.0011335295857861638\n",
      "batch loss nmt\t3.4234328269958496\tbatch loss relevance\t0.001031647901982069\n",
      "batch loss nmt\t4.53875732421875\tbatch loss relevance\t0.0008903073612600565\n",
      "batch loss nmt\t3.541067361831665\tbatch loss relevance\t0.0011248771334066987\n",
      "batch loss nmt\t3.8592429161071777\tbatch loss relevance\t0.0010204605059698224\n",
      "batch loss nmt\t4.067707538604736\tbatch loss relevance\t0.0008179770666174591\n",
      "batch loss nmt\t3.641615152359009\tbatch loss relevance\t0.0009569323738105595\n",
      "batch loss nmt\t3.0751917362213135\tbatch loss relevance\t0.001028324943035841\n",
      "batch loss nmt\t3.3253939151763916\tbatch loss relevance\t0.0010571943130344152\n",
      "batch loss nmt\t4.316145896911621\tbatch loss relevance\t0.0008938480168581009\n",
      "batch loss nmt\t3.0505285263061523\tbatch loss relevance\t0.0007903147488832474\n",
      "batch loss nmt\t3.1676888465881348\tbatch loss relevance\t0.0010458461474627256\n",
      "batch loss nmt\t3.6237587928771973\tbatch loss relevance\t0.0010197373339906335\n",
      "batch loss nmt\t3.243408679962158\tbatch loss relevance\t0.001006114762276411\n",
      "batch loss nmt\t3.678811550140381\tbatch loss relevance\t0.0009016160038299859\n",
      "batch loss nmt\t3.4210622310638428\tbatch loss relevance\t0.0012336556101217866\n",
      "batch loss nmt\t3.538592576980591\tbatch loss relevance\t0.0010763248428702354\n",
      "batch loss nmt\t3.8996152877807617\tbatch loss relevance\t0.0012049030046910048\n",
      "batch loss nmt\t3.3436331748962402\tbatch loss relevance\t0.0009294587071053684\n",
      "batch loss nmt\t2.946281909942627\tbatch loss relevance\t0.000853774428833276\n",
      "batch loss nmt\t3.9148409366607666\tbatch loss relevance\t0.0010419809259474277\n",
      "batch loss nmt\t4.954179286956787\tbatch loss relevance\t0.0011769860284402966\n",
      "batch loss nmt\t3.6025822162628174\tbatch loss relevance\t0.0011015110649168491\n",
      "batch loss nmt\t4.843647003173828\tbatch loss relevance\t0.0010898886248469353\n",
      "batch loss nmt\t3.4284496307373047\tbatch loss relevance\t0.001147763105109334\n",
      "batch loss nmt\t4.121034145355225\tbatch loss relevance\t0.0012526323553174734\n",
      "batch loss nmt\t3.2067275047302246\tbatch loss relevance\t0.0010897570755332708\n",
      "batch loss nmt\t3.256032943725586\tbatch loss relevance\t0.0010346267372369766\n",
      "batch loss nmt\t3.686171293258667\tbatch loss relevance\t0.0011713213752955198\n",
      "batch loss nmt\t3.272777557373047\tbatch loss relevance\t0.00107249291613698\n",
      "batch loss nmt\t3.174612045288086\tbatch loss relevance\t0.0010661440901458263\n",
      "batch loss nmt\t3.714571714401245\tbatch loss relevance\t0.0011363448575139046\n",
      "batch loss nmt\t3.44020938873291\tbatch loss relevance\t0.0010477957548573613\n",
      "batch loss nmt\t2.9797096252441406\tbatch loss relevance\t0.0008117348770610988\n",
      "batch loss nmt\t3.679572582244873\tbatch loss relevance\t0.0011803947854787111\n",
      "batch loss nmt\t3.8188984394073486\tbatch loss relevance\t0.0010489998385310173\n",
      "batch loss nmt\t4.665490627288818\tbatch loss relevance\t0.000855863734614104\n",
      "batch loss nmt\t3.596616268157959\tbatch loss relevance\t0.0010562363313511014\n",
      "batch loss nmt\t4.0118184089660645\tbatch loss relevance\t0.0009890845976769924\n",
      "batch loss nmt\t3.45198655128479\tbatch loss relevance\t0.0010860117617994547\n",
      "batch loss nmt\t3.414017915725708\tbatch loss relevance\t0.0010475760791450739\n",
      "batch loss nmt\t3.7108259201049805\tbatch loss relevance\t0.0010992309544235468\n",
      "batch loss nmt\t3.554154872894287\tbatch loss relevance\t0.0011229778174310923\n",
      "batch loss nmt\t4.320909023284912\tbatch loss relevance\t0.0012683751992881298\n",
      "batch loss nmt\t3.083674907684326\tbatch loss relevance\t0.0009871050715446472\n",
      "batch loss nmt\t3.505012035369873\tbatch loss relevance\t0.0010555589105933905\n",
      "batch loss nmt\t3.4677157402038574\tbatch loss relevance\t0.0010524133685976267\n",
      "batch loss nmt\t4.0340495109558105\tbatch loss relevance\t0.0011557464022189379\n",
      "batch loss nmt\t2.6999764442443848\tbatch loss relevance\t0.0007056889007799327\n",
      "batch loss nmt\t5.179861545562744\tbatch loss relevance\t0.001049714395776391\n",
      "batch loss nmt\t3.353990316390991\tbatch loss relevance\t0.0008927489398047328\n",
      "batch loss nmt\t3.87509822845459\tbatch loss relevance\t0.0010443443898111582\n",
      "batch loss nmt\t3.4523935317993164\tbatch loss relevance\t0.0008996230317279696\n",
      "batch loss nmt\t4.36236047744751\tbatch loss relevance\t0.0010808606166392565\n",
      "batch loss nmt\t2.5748937129974365\tbatch loss relevance\t0.0007471415447071195\n",
      "batch loss nmt\t4.414102077484131\tbatch loss relevance\t0.0007780235027894378\n",
      "batch loss nmt\t3.636979103088379\tbatch loss relevance\t0.0010856931330636144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss nmt\t3.2850611209869385\tbatch loss relevance\t0.0008649654919281602\n",
      "batch loss nmt\t4.749572277069092\tbatch loss relevance\t0.00113286345731467\n",
      "batch loss nmt\t3.3607540130615234\tbatch loss relevance\t0.0010453517315909266\n",
      "batch loss nmt\t3.341212511062622\tbatch loss relevance\t0.0011175594991073012\n",
      "batch loss nmt\t3.3006882667541504\tbatch loss relevance\t0.0010221737902611494\n",
      "batch loss nmt\t3.2338407039642334\tbatch loss relevance\t0.0012224962702021003\n",
      "batch loss nmt\t3.5007705688476562\tbatch loss relevance\t0.000978245516307652\n",
      "batch loss nmt\t3.441756248474121\tbatch loss relevance\t0.0010811160318553448\n",
      "batch loss nmt\t3.258087158203125\tbatch loss relevance\t0.0010499297641217709\n",
      "batch loss nmt\t3.938767433166504\tbatch loss relevance\t0.0010282793082296848\n",
      "batch loss nmt\t2.9457530975341797\tbatch loss relevance\t0.0007913286099210382\n",
      "batch loss nmt\t3.592405080795288\tbatch loss relevance\t0.0009995202999562025\n",
      "batch loss nmt\t3.6032285690307617\tbatch loss relevance\t0.001006580307148397\n",
      "batch loss nmt\t3.641040325164795\tbatch loss relevance\t0.0009563596686348319\n",
      "batch loss nmt\t3.637929677963257\tbatch loss relevance\t0.0009708238067105412\n",
      "batch loss nmt\t3.6990106105804443\tbatch loss relevance\t0.0009915438713505864\n",
      "batch loss nmt\t3.632946252822876\tbatch loss relevance\t0.0010762412566691637\n",
      "batch loss nmt\t3.4076156616210938\tbatch loss relevance\t0.0010381530737504363\n",
      "batch loss nmt\t3.8093020915985107\tbatch loss relevance\t0.0009594059083610773\n",
      "batch loss nmt\t3.5984528064727783\tbatch loss relevance\t0.0009717968059703708\n",
      "batch loss nmt\t2.8833913803100586\tbatch loss relevance\t0.0008548918995074928\n",
      "batch loss nmt\t4.092278957366943\tbatch loss relevance\t0.0010332211386412382\n",
      "batch loss nmt\t3.275678873062134\tbatch loss relevance\t0.001010495936498046\n",
      "batch loss nmt\t3.5009775161743164\tbatch loss relevance\t0.001029205392114818\n",
      "batch loss nmt\t3.3257226943969727\tbatch loss relevance\t0.0009091689717024565\n",
      "batch loss nmt\t3.4219560623168945\tbatch loss relevance\t0.0009741949033923447\n",
      "batch loss nmt\t3.795511484146118\tbatch loss relevance\t0.001083052484318614\n",
      "batch loss nmt\t3.510183334350586\tbatch loss relevance\t0.0012596682645380497\n",
      "batch loss nmt\t3.621882677078247\tbatch loss relevance\t0.0009653475135564804\n",
      "batch loss nmt\t4.150726318359375\tbatch loss relevance\t0.0010946064721792936\n",
      "batch loss nmt\t3.834625720977783\tbatch loss relevance\t0.0010356223210692406\n",
      "batch loss nmt\t3.415675640106201\tbatch loss relevance\t0.0012645613169297576\n",
      "batch loss nmt\t3.2056992053985596\tbatch loss relevance\t0.0009745629504323006\n",
      "batch loss nmt\t3.2201108932495117\tbatch loss relevance\t0.0008978077676147223\n",
      "batch loss nmt\t3.2343146800994873\tbatch loss relevance\t0.0010234764777123928\n",
      "batch loss nmt\t3.3558735847473145\tbatch loss relevance\t0.0011856473283842206\n",
      "batch loss nmt\t3.3649885654449463\tbatch loss relevance\t0.0011784778907895088\n",
      "batch loss nmt\t3.2244133949279785\tbatch loss relevance\t0.001015585963614285\n",
      "batch loss nmt\t4.632187843322754\tbatch loss relevance\t0.0010995997581630945\n",
      "batch loss nmt\t3.991164445877075\tbatch loss relevance\t0.0010479718912392855\n",
      "batch loss nmt\t3.6736562252044678\tbatch loss relevance\t0.0011400022776797414\n",
      "batch loss nmt\t3.8178539276123047\tbatch loss relevance\t0.0009571920963935554\n",
      "batch loss nmt\t3.047370433807373\tbatch loss relevance\t0.0011305066291242838\n",
      "batch loss nmt\t2.756014823913574\tbatch loss relevance\t0.0008880557143129408\n",
      "batch loss nmt\t4.019787311553955\tbatch loss relevance\t0.0009282404789701104\n",
      "batch loss nmt\t3.090981960296631\tbatch loss relevance\t0.0009391355561092496\n",
      "batch loss nmt\t4.316593647003174\tbatch loss relevance\t0.001092683756724\n",
      "batch loss nmt\t3.519674301147461\tbatch loss relevance\t0.001088618068024516\n",
      "batch loss nmt\t3.4770009517669678\tbatch loss relevance\t0.0010194522328674793\n",
      "batch loss nmt\t4.304981708526611\tbatch loss relevance\t0.0010425894288346171\n",
      "batch loss nmt\t3.8405404090881348\tbatch loss relevance\t0.0011735622538253665\n",
      "batch loss nmt\t4.624718189239502\tbatch loss relevance\t0.0012340426910668612\n",
      "batch loss nmt\t3.382805824279785\tbatch loss relevance\t0.0010879025794565678\n",
      "batch loss nmt\t3.2058420181274414\tbatch loss relevance\t0.0009209199924953282\n",
      "batch loss nmt\t3.92805814743042\tbatch loss relevance\t0.0010442683706060052\n",
      "batch loss nmt\t2.2049434185028076\tbatch loss relevance\t0.0008587298216298223\n",
      "batch loss nmt\t3.634612560272217\tbatch loss relevance\t0.0009539495804347098\n",
      "batch loss nmt\t3.806204080581665\tbatch loss relevance\t0.0010253512300550938\n",
      "batch loss nmt\t3.809063673019409\tbatch loss relevance\t0.0011692831758409739\n",
      "batch loss nmt\t3.1849892139434814\tbatch loss relevance\t0.0008870261372067034\n",
      "batch loss nmt\t3.540908098220825\tbatch loss relevance\t0.0011501063127070665\n",
      "batch loss nmt\t3.4140594005584717\tbatch loss relevance\t0.0011584265157580376\n",
      "batch loss nmt\t4.054242134094238\tbatch loss relevance\t0.0011597094126045704\n",
      "batch loss nmt\t4.012429237365723\tbatch loss relevance\t0.0009159030742011964\n",
      "batch loss nmt\t3.2224109172821045\tbatch loss relevance\t0.0009788358584046364\n",
      "batch loss nmt\t3.251744270324707\tbatch loss relevance\t0.0009107905789278448\n",
      "batch loss nmt\t3.5157229900360107\tbatch loss relevance\t0.0011514120269566774\n",
      "batch loss nmt\t3.556046962738037\tbatch loss relevance\t0.0011599775170907378\n",
      "batch loss nmt\t3.8734323978424072\tbatch loss relevance\t0.0011393486056476831\n",
      "batch loss nmt\t3.7648773193359375\tbatch loss relevance\t0.0012040904257446527\n",
      "batch loss nmt\t3.710286855697632\tbatch loss relevance\t0.0009630460990592837\n",
      "batch loss nmt\t3.1422879695892334\tbatch loss relevance\t0.00104437000118196\n",
      "batch loss nmt\t3.2219078540802\tbatch loss relevance\t0.0011758193140849471\n",
      "batch loss nmt\t3.2410900592803955\tbatch loss relevance\t0.0011726459488272667\n",
      "batch loss nmt\t3.0870466232299805\tbatch loss relevance\t0.0010187550215050578\n",
      "batch loss nmt\t3.6378514766693115\tbatch loss relevance\t0.0011947285383939743\n",
      "batch loss nmt\t3.6861419677734375\tbatch loss relevance\t0.0009652939043007791\n",
      "batch loss nmt\t1.5641260147094727\tbatch loss relevance\t0.0008165993494912982\n",
      "batch loss nmt\t4.017619609832764\tbatch loss relevance\t0.0009876493131741881\n",
      "batch loss nmt\t3.716359853744507\tbatch loss relevance\t0.0014175573596730828\n",
      "batch loss nmt\t3.535097122192383\tbatch loss relevance\t0.0011590177891775966\n",
      "batch loss nmt\t3.844566583633423\tbatch loss relevance\t0.0010104126995429397\n",
      "batch loss nmt\t2.9803669452667236\tbatch loss relevance\t0.0008509440231136978\n",
      "batch loss nmt\t3.0317301750183105\tbatch loss relevance\t0.0008111469214782119\n",
      "batch loss nmt\t4.0606842041015625\tbatch loss relevance\t0.0011287404922768474\n",
      "batch loss nmt\t4.0870442390441895\tbatch loss relevance\t0.0012012042570859194\n",
      "batch loss nmt\t3.407320261001587\tbatch loss relevance\t0.0009104827768169343\n",
      "batch loss nmt\t4.553950309753418\tbatch loss relevance\t0.0009576189331710339\n",
      "batch loss nmt\t3.452702522277832\tbatch loss relevance\t0.0009410754428245127\n",
      "batch loss nmt\t3.186598539352417\tbatch loss relevance\t0.0010302027221769094\n",
      "batch loss nmt\t3.0442144870758057\tbatch loss relevance\t0.0010644966969266534\n",
      "batch loss nmt\t3.263558864593506\tbatch loss relevance\t0.0009041802841238678\n",
      "batch loss nmt\t3.344005584716797\tbatch loss relevance\t0.001174192875623703\n",
      "batch loss nmt\t4.035386085510254\tbatch loss relevance\t0.0011346233077347279\n",
      "batch loss nmt\t4.464595317840576\tbatch loss relevance\t0.0009226265246979892\n",
      "batch loss nmt\t3.6692512035369873\tbatch loss relevance\t0.0009161696652881801\n",
      "batch loss nmt\t3.8960142135620117\tbatch loss relevance\t0.001128993695601821\n",
      "batch loss nmt\t2.7943007946014404\tbatch loss relevance\t0.0009238418424502015\n",
      "batch loss nmt\t1.073207139968872\tbatch loss relevance\t0.0018025871831923723\n",
      "batch loss nmt\t3.5605406761169434\tbatch loss relevance\t0.0010865071089938283\n",
      "batch loss nmt\t3.4589641094207764\tbatch loss relevance\t0.0011474654311314225\n",
      "batch loss nmt\t3.044948101043701\tbatch loss relevance\t0.0011035579955205321\n",
      "batch loss nmt\t3.5555155277252197\tbatch loss relevance\t0.000984383630566299\n",
      "batch loss nmt\t3.597567319869995\tbatch loss relevance\t0.000955298834014684\n",
      "batch loss nmt\t3.414717435836792\tbatch loss relevance\t0.0009788110619410872\n",
      "batch loss nmt\t3.60174822807312\tbatch loss relevance\t0.0009757651714608073\n",
      "batch loss nmt\t4.198913097381592\tbatch loss relevance\t0.001188337686471641\n",
      "batch loss nmt\t2.9927878379821777\tbatch loss relevance\t0.0008275519357994199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss nmt\t3.8433010578155518\tbatch loss relevance\t0.001036760164424777\n",
      "batch loss nmt\t3.221762180328369\tbatch loss relevance\t0.0010226966114714742\n",
      "batch loss nmt\t4.306225299835205\tbatch loss relevance\t0.0009579447214491665\n",
      "batch loss nmt\t3.714390277862549\tbatch loss relevance\t0.0009655322646722198\n",
      "batch loss nmt\t4.9110307693481445\tbatch loss relevance\t0.0015229651471599936\n",
      "batch loss nmt\t3.4438843727111816\tbatch loss relevance\t0.0010113917523995042\n",
      "batch loss nmt\t3.3890650272369385\tbatch loss relevance\t0.0010376219870522618\n",
      "batch loss nmt\t3.846619129180908\tbatch loss relevance\t0.001236703828908503\n",
      "batch loss nmt\t3.359321117401123\tbatch loss relevance\t0.0011988348560407758\n",
      "batch loss nmt\t3.3098552227020264\tbatch loss relevance\t0.001184906461276114\n",
      "batch loss nmt\t3.334054946899414\tbatch loss relevance\t0.0011431622551754117\n",
      "batch loss nmt\t3.9990713596343994\tbatch loss relevance\t0.0011410469887778163\n",
      "batch loss nmt\t3.4776744842529297\tbatch loss relevance\t0.001178214093670249\n",
      "batch loss nmt\t3.4858062267303467\tbatch loss relevance\t0.0010349182412028313\n",
      "batch loss nmt\t3.695404291152954\tbatch loss relevance\t0.0008395238546654582\n",
      "batch loss nmt\t3.2931573390960693\tbatch loss relevance\t0.0010478078620508313\n",
      "batch loss nmt\t3.60011625289917\tbatch loss relevance\t0.0009314108174294233\n",
      "batch loss nmt\t3.2504935264587402\tbatch loss relevance\t0.0009475139668211341\n",
      "batch loss nmt\t3.704266309738159\tbatch loss relevance\t0.001174387289211154\n",
      "batch loss nmt\t3.075371026992798\tbatch loss relevance\t0.0010560511145740747\n",
      "batch loss nmt\t3.3278801441192627\tbatch loss relevance\t0.0010776532581076026\n",
      "batch loss nmt\t4.491158485412598\tbatch loss relevance\t0.0010774367256090045\n",
      "batch loss nmt\t3.4207820892333984\tbatch loss relevance\t0.0010788090294227004\n",
      "batch loss nmt\t3.363935947418213\tbatch loss relevance\t0.0010122146923094988\n",
      "batch loss nmt\t3.8391032218933105\tbatch loss relevance\t0.0010533964959904552\n",
      "batch loss nmt\t3.202152729034424\tbatch loss relevance\t0.0009168836986646056\n",
      "batch loss nmt\t3.2926578521728516\tbatch loss relevance\t0.0009233584860339761\n",
      "batch loss nmt\t3.9578278064727783\tbatch loss relevance\t0.0010635405778884888\n",
      "batch loss nmt\t4.465404510498047\tbatch loss relevance\t0.001203723601065576\n",
      "batch loss nmt\t2.9386558532714844\tbatch loss relevance\t0.0009077104623429477\n",
      "batch loss nmt\t3.465909719467163\tbatch loss relevance\t0.001117186271585524\n",
      "batch loss nmt\t4.603430271148682\tbatch loss relevance\t0.00141766422893852\n",
      "batch loss nmt\t3.624998092651367\tbatch loss relevance\t0.0010682973079383373\n",
      "batch loss nmt\t3.496063709259033\tbatch loss relevance\t0.0012674592435359955\n",
      "batch loss nmt\t3.1923422813415527\tbatch loss relevance\t0.001055473810993135\n",
      "batch loss nmt\t5.385542392730713\tbatch loss relevance\t0.0009856291580945253\n",
      "batch loss nmt\t3.8151421546936035\tbatch loss relevance\t0.0011278563179075718\n",
      "batch loss nmt\t3.431259870529175\tbatch loss relevance\t0.0008460201788693666\n",
      "batch loss nmt\t3.151242733001709\tbatch loss relevance\t0.0011621470330283046\n",
      "batch loss nmt\t3.4906423091888428\tbatch loss relevance\t0.0009818917606025934\n",
      "batch loss nmt\t3.2281265258789062\tbatch loss relevance\t0.0008913983474485576\n",
      "batch loss nmt\t3.0681934356689453\tbatch loss relevance\t0.0007323893369175494\n",
      "batch loss nmt\t3.450011968612671\tbatch loss relevance\t0.0012370436452329159\n",
      "batch loss nmt\t3.93475079536438\tbatch loss relevance\t0.0010588732548058033\n",
      "batch loss nmt\t3.6505863666534424\tbatch loss relevance\t0.0009806177113205194\n",
      "batch loss nmt\t3.209690809249878\tbatch loss relevance\t0.0009402346331626177\n",
      "batch loss nmt\t3.586745262145996\tbatch loss relevance\t0.0009357209783047438\n",
      "batch loss nmt\t3.773486614227295\tbatch loss relevance\t0.0010014035506173968\n",
      "batch loss nmt\t3.4199752807617188\tbatch loss relevance\t0.0010027704993262887\n",
      "batch loss nmt\t3.1497323513031006\tbatch loss relevance\t0.0009827115572988987\n",
      "batch loss nmt\t3.88513445854187\tbatch loss relevance\t0.0011993034277111292\n",
      "batch loss nmt\t3.447455644607544\tbatch loss relevance\t0.0010234079090878367\n",
      "batch loss nmt\t3.0733213424682617\tbatch loss relevance\t0.001102131325751543\n",
      "batch loss nmt\t3.4885640144348145\tbatch loss relevance\t0.0010647496674209833\n",
      "batch loss nmt\t3.985793113708496\tbatch loss relevance\t0.0010649982141330838\n",
      "batch loss nmt\t3.0952699184417725\tbatch loss relevance\t0.0007018244941718876\n",
      "batch loss nmt\t2.696805000305176\tbatch loss relevance\t0.0008344780071638525\n",
      "batch loss nmt\t4.605078220367432\tbatch loss relevance\t0.0008541550487279892\n",
      "batch loss nmt\t4.59581184387207\tbatch loss relevance\t0.0013841042527928948\n",
      "batch loss nmt\t2.18471097946167\tbatch loss relevance\t0.0007058904157020152\n",
      "batch loss nmt\t3.0811028480529785\tbatch loss relevance\t0.000995644018985331\n",
      "batch loss nmt\t3.556669235229492\tbatch loss relevance\t0.0012653806479647756\n",
      "batch loss nmt\t3.3600075244903564\tbatch loss relevance\t0.0009949870873242617\n",
      "batch loss nmt\t3.6122002601623535\tbatch loss relevance\t0.0009717378416098654\n",
      "batch loss nmt\t3.2396273612976074\tbatch loss relevance\t0.0011267649242654443\n",
      "batch loss nmt\t3.179713726043701\tbatch loss relevance\t0.0010670642368495464\n",
      "batch loss nmt\t3.1796624660491943\tbatch loss relevance\t0.000927549262996763\n",
      "batch loss nmt\t6.291244029998779\tbatch loss relevance\t0.0006538230227306485\n",
      "batch loss nmt\t5.415070056915283\tbatch loss relevance\t0.001049412414431572\n",
      "batch loss nmt\t3.4169487953186035\tbatch loss relevance\t0.0009307796717621386\n",
      "batch loss nmt\t4.016080856323242\tbatch loss relevance\t0.0008835602784529328\n",
      "batch loss nmt\t3.1455612182617188\tbatch loss relevance\t0.0011768671683967113\n",
      "batch loss nmt\t4.002960681915283\tbatch loss relevance\t0.0011570488568395376\n",
      "batch loss nmt\t3.2557389736175537\tbatch loss relevance\t0.0009119427413679659\n",
      "batch loss nmt\t3.7955968379974365\tbatch loss relevance\t0.0010779789881780744\n",
      "batch loss nmt\t2.942924976348877\tbatch loss relevance\t0.0011076374212279916\n",
      "batch loss nmt\t3.695976495742798\tbatch loss relevance\t0.0008785550016909838\n",
      "batch loss nmt\t3.029905319213867\tbatch loss relevance\t0.0010842903284355998\n",
      "batch loss nmt\t3.0438451766967773\tbatch loss relevance\t0.0008896929793991148\n",
      "batch loss nmt\t3.3770837783813477\tbatch loss relevance\t0.001171251991763711\n",
      "batch loss nmt\t2.6494014263153076\tbatch loss relevance\t0.0009004981257021427\n",
      "batch loss nmt\t4.860879898071289\tbatch loss relevance\t0.001118294894695282\n",
      "batch loss nmt\t3.5310099124908447\tbatch loss relevance\t0.0011840491788461804\n",
      "batch loss nmt\t3.843571901321411\tbatch loss relevance\t0.0011030853493139148\n",
      "batch loss nmt\t3.179844856262207\tbatch loss relevance\t0.0009461325244046748\n",
      "batch loss nmt\t3.671178102493286\tbatch loss relevance\t0.001030731131322682\n",
      "batch loss nmt\t3.455500602722168\tbatch loss relevance\t0.0011508357711136341\n",
      "batch loss nmt\t2.3743598461151123\tbatch loss relevance\t0.0006739648524671793\n",
      "batch loss nmt\t2.947066307067871\tbatch loss relevance\t0.0008393195457756519\n",
      "batch loss nmt\t2.9591000080108643\tbatch loss relevance\t0.0009077362483367324\n",
      "batch loss nmt\t2.897651195526123\tbatch loss relevance\t0.0009080241434276104\n",
      "batch loss nmt\t4.287871360778809\tbatch loss relevance\t0.0012112478725612164\n",
      "batch loss nmt\t3.3438198566436768\tbatch loss relevance\t0.000939812627620995\n",
      "batch loss nmt\t3.292771816253662\tbatch loss relevance\t0.0011180739384144545\n",
      "batch loss nmt\t4.093397617340088\tbatch loss relevance\t0.0009979248279705644\n",
      "batch loss nmt\t3.3243863582611084\tbatch loss relevance\t0.0011055211070924997\n",
      "batch loss nmt\t2.611778736114502\tbatch loss relevance\t0.0007740577566437423\n",
      "batch loss nmt\t4.1729583740234375\tbatch loss relevance\t0.0011436732020229101\n",
      "batch loss nmt\t4.0361247062683105\tbatch loss relevance\t0.0011480500688776374\n",
      "batch loss nmt\t3.3575119972229004\tbatch loss relevance\t0.0011823332170024514\n",
      "batch loss nmt\t3.5558700561523438\tbatch loss relevance\t0.0009220889187417924\n",
      "batch loss nmt\t3.83280348777771\tbatch loss relevance\t0.0012018971610814333\n",
      "batch loss nmt\t2.160327672958374\tbatch loss relevance\t0.0006994103896431625\n",
      "batch loss nmt\t2.943272590637207\tbatch loss relevance\t0.0009865626925602555\n",
      "batch loss nmt\t3.203892469406128\tbatch loss relevance\t0.0011418508365750313\n",
      "batch loss nmt\t3.5517330169677734\tbatch loss relevance\t0.0011257837759330869\n",
      "batch loss nmt\t3.572859048843384\tbatch loss relevance\t0.0011959210969507694\n",
      "batch loss nmt\t2.9284281730651855\tbatch loss relevance\t0.0010206582956016064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch loss nmt\t4.087344646453857\tbatch loss relevance\t0.0013444494688883424\n",
      "batch loss nmt\t3.4526517391204834\tbatch loss relevance\t0.0011506406590342522\n",
      "batch loss nmt\t3.597912073135376\tbatch loss relevance\t0.0012453872477635741\n",
      "batch loss nmt\t3.5420777797698975\tbatch loss relevance\t0.0009873275412246585\n",
      "batch loss nmt\t3.442775011062622\tbatch loss relevance\t0.001113839796744287\n",
      "batch loss nmt\t3.280423879623413\tbatch loss relevance\t0.0010476326569914818\n",
      "batch loss nmt\t5.552959442138672\tbatch loss relevance\t0.0010595674393698573\n",
      "batch loss nmt\t3.81675124168396\tbatch loss relevance\t0.0008955063531175256\n",
      "batch loss nmt\t3.235121488571167\tbatch loss relevance\t0.0008146936306729913\n",
      "batch loss nmt\t2.7223312854766846\tbatch loss relevance\t0.0007770402007736266\n",
      "batch loss nmt\t3.1471896171569824\tbatch loss relevance\t0.0010273174848407507\n",
      "batch loss nmt\t2.9530186653137207\tbatch loss relevance\t0.0008648690418340266\n",
      "batch loss nmt\t5.730668067932129\tbatch loss relevance\t0.0010244554141536355\n",
      "batch loss nmt\t4.239522933959961\tbatch loss relevance\t0.001087414100766182\n",
      "batch loss nmt\t3.9927306175231934\tbatch loss relevance\t0.0009432156221009791\n",
      "batch loss nmt\t3.1763079166412354\tbatch loss relevance\t0.001097600208595395\n",
      "batch loss nmt\t3.5062005519866943\tbatch loss relevance\t0.0011682917829602957\n",
      "batch loss nmt\t3.241377353668213\tbatch loss relevance\t0.000973760848864913\n",
      "batch loss nmt\t3.55818772315979\tbatch loss relevance\t0.0011508098104968667\n",
      "batch loss nmt\t3.8241539001464844\tbatch loss relevance\t0.0010403788182884455\n",
      "batch loss nmt\t3.347832441329956\tbatch loss relevance\t0.001154271769337356\n",
      "batch loss nmt\t3.6856207847595215\tbatch loss relevance\t0.0011205562623217702\n",
      "batch loss nmt\t3.367213726043701\tbatch loss relevance\t0.0010213542263954878\n",
      "batch loss nmt\t3.4145689010620117\tbatch loss relevance\t0.0010884650982916355\n",
      "batch loss nmt\t5.3554205894470215\tbatch loss relevance\t0.0009356302325613797\n",
      "batch loss nmt\t3.9651429653167725\tbatch loss relevance\t0.0010686630848795176\n",
      "batch loss nmt\t3.6552836894989014\tbatch loss relevance\t0.0011794157326221466\n",
      "batch loss nmt\t3.593010187149048\tbatch loss relevance\t0.0010419187601655722\n",
      "batch loss nmt\t3.512227773666382\tbatch loss relevance\t0.0010145806008949876\n",
      "batch loss nmt\t3.8263919353485107\tbatch loss relevance\t0.0010839328169822693\n",
      "batch loss nmt\t3.7195358276367188\tbatch loss relevance\t0.0010343806352466345\n",
      "batch loss nmt\t3.189065933227539\tbatch loss relevance\t0.0010271841892972589\n",
      "batch loss nmt\t3.546846389770508\tbatch loss relevance\t0.0008297741296701133\n",
      "batch loss nmt\t5.084716320037842\tbatch loss relevance\t0.0009541572071611881\n",
      "batch loss nmt\t3.3174922466278076\tbatch loss relevance\t0.0009998552268370986\n",
      "batch loss nmt\t3.625826120376587\tbatch loss relevance\t0.001070566475391388\n",
      "batch loss nmt\t5.340567588806152\tbatch loss relevance\t0.0012123676715418696\n",
      "batch loss nmt\t3.5888772010803223\tbatch loss relevance\t0.0011189518263563514\n",
      "batch loss nmt\t4.402196884155273\tbatch loss relevance\t0.0011554870288819075\n",
      "batch loss nmt\t3.519988775253296\tbatch loss relevance\t0.0010169749148190022\n",
      "batch loss nmt\t3.703773260116577\tbatch loss relevance\t0.0010049565462395549\n",
      "batch loss nmt\t3.175780773162842\tbatch loss relevance\t0.0009392102365382016\n",
      "batch loss nmt\t3.1249477863311768\tbatch loss relevance\t0.0009761204710230231\n",
      "batch loss nmt\t3.7673120498657227\tbatch loss relevance\t0.0012493340764194727\n",
      "batch loss nmt\t2.993584394454956\tbatch loss relevance\t0.0010723054874688387\n",
      "batch loss nmt\t3.183466672897339\tbatch loss relevance\t0.0011529618641361594\n",
      "batch loss nmt\t3.5865023136138916\tbatch loss relevance\t0.0012158508179709315\n",
      "batch loss nmt\t3.442255735397339\tbatch loss relevance\t0.0010414562420919538\n",
      "batch loss nmt\t4.096508979797363\tbatch loss relevance\t0.001107598771341145\n",
      "batch loss nmt\t3.2323031425476074\tbatch loss relevance\t0.0007719930727034807\n",
      "batch loss nmt\t2.6046276092529297\tbatch loss relevance\t0.0007282046135514975\n",
      "batch loss nmt\t3.375129222869873\tbatch loss relevance\t0.0011364652309566736\n",
      "batch loss nmt\t3.2581534385681152\tbatch loss relevance\t0.001044471631757915\n",
      "batch loss nmt\t3.449611186981201\tbatch loss relevance\t0.0011273300042375922\n",
      "batch loss nmt\t3.579235792160034\tbatch loss relevance\t0.0010899947956204414\n",
      "batch loss nmt\t3.6763100624084473\tbatch loss relevance\t0.001148554147221148\n",
      "batch loss nmt\t3.362603187561035\tbatch loss relevance\t0.001034012995660305\n",
      "batch loss nmt\t3.84244441986084\tbatch loss relevance\t0.0008956569945439696\n",
      "batch loss nmt\t3.221604824066162\tbatch loss relevance\t0.0011799384374171495\n",
      "batch loss nmt\t4.135711193084717\tbatch loss relevance\t0.0010130597511306405\n",
      "batch loss nmt\t3.5577316284179688\tbatch loss relevance\t0.000931081420276314\n",
      "batch loss nmt\t3.550766706466675\tbatch loss relevance\t0.001031064777635038\n",
      "batch loss nmt\t3.4506072998046875\tbatch loss relevance\t0.0011063158744946122\n",
      "batch loss nmt\t3.213864326477051\tbatch loss relevance\t0.0012652273289859295\n",
      "batch loss nmt\t3.6334035396575928\tbatch loss relevance\t0.0011981329880654812\n",
      "batch loss nmt\t3.4764134883880615\tbatch loss relevance\t0.0009183731744997203\n",
      "batch loss nmt\t3.2693469524383545\tbatch loss relevance\t0.0010161000536754727\n",
      "batch loss nmt\t3.452582836151123\tbatch loss relevance\t0.0013027553213760257\n",
      "batch loss nmt\t3.175546407699585\tbatch loss relevance\t0.00117390975356102\n",
      "batch loss nmt\t3.6511893272399902\tbatch loss relevance\t0.0009959796443581581\n",
      "batch loss nmt\t3.347012519836426\tbatch loss relevance\t0.0011080404510721564\n",
      "batch loss nmt\t4.150976181030273\tbatch loss relevance\t0.0010100530926138163\n",
      "batch loss nmt\t3.671713352203369\tbatch loss relevance\t0.0009028676431626081\n",
      "batch loss nmt\t6.757696151733398\tbatch loss relevance\t0.001034401124343276\n",
      "batch loss nmt\t4.304010391235352\tbatch loss relevance\t0.0010511233704164624\n",
      "batch loss nmt\t3.317326068878174\tbatch loss relevance\t0.0005391429294832051\n",
      "batch loss nmt\t3.7155110836029053\tbatch loss relevance\t0.0004665831511374563\n",
      "batch loss nmt\t3.7837419509887695\tbatch loss relevance\t0.0010120398364961147\n",
      "batch loss nmt\t4.521292209625244\tbatch loss relevance\t0.0009259383077733219\n",
      "batch loss nmt\t3.4361186027526855\tbatch loss relevance\t0.0009883437305688858\n",
      "batch loss nmt\t4.12595272064209\tbatch loss relevance\t0.001315398490987718\n",
      "batch loss nmt\t3.698612928390503\tbatch loss relevance\t0.0011272943811491132\n",
      "batch loss nmt\t4.5355753898620605\tbatch loss relevance\t0.0010446654632687569\n",
      "batch loss nmt\t3.203934669494629\tbatch loss relevance\t0.0008510251645930111\n",
      "batch loss nmt\t2.893035888671875\tbatch loss relevance\t0.0009161752532236278\n",
      "batch loss nmt\t3.6160645484924316\tbatch loss relevance\t0.001003124169073999\n",
      "batch loss nmt\t3.3587989807128906\tbatch loss relevance\t0.0007434244616888463\n",
      "batch loss nmt\t3.6562819480895996\tbatch loss relevance\t0.0010462054051458836\n",
      "batch loss nmt\t3.0232505798339844\tbatch loss relevance\t0.0008913932833820581\n",
      "batch loss nmt\t3.1938259601593018\tbatch loss relevance\t0.0009309184970334172\n",
      "batch loss nmt\t3.665553092956543\tbatch loss relevance\t0.0010027787648141384\n",
      "batch loss nmt\t3.2009313106536865\tbatch loss relevance\t0.0009323315462097526\n",
      "batch loss nmt\t3.7745258808135986\tbatch loss relevance\t0.0009618723415769637\n",
      "batch loss nmt\t3.7564990520477295\tbatch loss relevance\t0.0012098250444978476\n",
      "batch loss nmt\t3.7760820388793945\tbatch loss relevance\t0.0009248880669474602\n",
      "batch loss nmt\t3.416002035140991\tbatch loss relevance\t0.0010416170116513968\n",
      "batch loss nmt\t2.7390668392181396\tbatch loss relevance\t0.0008702101185917854\n",
      "batch loss nmt\t4.291713714599609\tbatch loss relevance\t0.001066097873263061\n",
      "batch loss nmt\t3.620575428009033\tbatch loss relevance\t0.0010842810152098536\n",
      "batch loss nmt\t3.6277172565460205\tbatch loss relevance\t0.0012020583963021636\n",
      "batch loss nmt\t3.5852367877960205\tbatch loss relevance\t0.0007214562501758337\n",
      "batch loss nmt\t3.676624059677124\tbatch loss relevance\t0.0011301115155220032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8589:\n",
      "Process Process-8587:\n",
      "Process Process-8590:\n",
      "Process Process-8586:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/smsarwar/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/client.py\", line 39, in execute_on_server\n",
      "    response = client.recv()\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/client.py\", line 39, in execute_on_server\n",
      "    response = client.recv()\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/client.py\", line 39, in execute_on_server\n",
      "    response = client.recv()\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/client.py\", line 39, in execute_on_server\n",
      "    response = client.recv()\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 93, in recv\n",
      "    return _recv(self.socket)\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 93, in recv\n",
      "    return _recv(self.socket)\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 93, in recv\n",
      "    return _recv(self.socket)\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 93, in recv\n",
      "    return _recv(self.socket)\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 121, in _recv\n",
      "    char = socket.recv(1).decode()\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 121, in _recv\n",
      "    char = socket.recv(1).decode()\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 121, in _recv\n",
      "    char = socket.recv(1).decode()\n",
      "  File \"/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/jsonsocket.py\", line 121, in _recv\n",
      "    char = socket.recv(1).decode()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-40034144d097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrelevance_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-82bbd0d8034c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, opt, SRC, TRG)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrelevance_training\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mtrg_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mtrg_strings_rm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_expansion_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtrg_strings_rm_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrg_strings_rm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nfs/work1/allan/smsarwar/material/pytorch_transformer/client.py\u001b[0m in \u001b[0;36mquery_expansion_distributed\u001b[0;34m(self, query_list)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Exit the completed processes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;31m# Get process results from the output queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
<<<<<<< HEAD
=======
    "relevance_training = 1\n",
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
    "model = model.cuda()\n",
    "train_model(model, opt, SRC, TRG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true
   },
=======
   "metadata": {},
>>>>>>> 16ab0bdfe00297d324a897271dadd1709bf248d1
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{load_vocab}/model_weights')\n",
    "\n",
    "# x = torch.randn(4,6,1)\n",
    "# print (x)\n",
    "# x = x.view(4, -1)\n",
    "# print (x)\n",
    "# # print(x)\n",
    "# # probs, ix = x[:, :].data.topk(1)\n",
    "# # print(probs)\n",
    "# # print(ix)\n",
    "\n",
    "# x = torch.randn(3,2)\n",
    "# print(x)\n",
    "# y = torch.randn(3,2)\n",
    "# print(y)\n",
    "# print (((x - y)**2).mean())\n",
    "# #F.cosine_embedding_loss(x, y, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(SRC.vocab.itos[4880])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
