{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from Models import get_model\n",
    "from Process import *\n",
    "import torch.nn.functional as F\n",
    "from Optim import CosineWithRestarts\n",
    "from Batch import create_masks\n",
    "import dill as pickle\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import os\n",
    "import whoosh, glob, time, pickle\n",
    "import whoosh.fields as wf\n",
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import index\n",
    "import threading\n",
    "from whoosh import filedb\n",
    "from whoosh.filedb.filestore import FileStorage\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from InMemorySearch import *\n",
    "from client import *\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from logger import Logger\n",
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#At first checking our super clients\n",
    "# query_list = [\"european crime records\", \"crime records\", \"european crime\", \"european records\", \"crime crimes violent sheriff enforcement re criminals stresak bill strikes\", \"LA times corpus\", \"crime records\"]    \n",
    "# super_client = SuperClient()\n",
    "# print(super_client.hosts)\n",
    "# final_result = super_client.query_expansion_distributed(query_list)\n",
    "# print(len(final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#If we are working on small dataset\n",
    "small = 0\n",
    "#If we want to activate relevance based training\n",
    "relevance_training = 0\n",
    "    \n",
    "if small==1:\n",
    "    parser.add_argument('-src_data', type=str, default='data/italian_small.txt')\n",
    "    parser.add_argument('-trg_data', type=str, default='data/english_small.txt')\n",
    "    parser.add_argument('-trg_data_retrieval', type=str, default='data/english_retrieval.txt')\n",
    "\n",
    "else:\n",
    "    parser.add_argument('-src_data', type=str, default='data/italian.txt')\n",
    "    parser.add_argument('-trg_data', type=str, default='data/english.txt')  \n",
    "    parser.add_argument('-trg_data_retrieval', type=str, default='data/LATIMESTEXT2.txt')\n",
    "    parser.add_argument('-rm_data', type=str, default='data/english_rm.txt') ##\n",
    "\n",
    "parser.add_argument('-src_lang', type=str, default='it')\n",
    "parser.add_argument('-trg_lang', type=str, default='en')\n",
    "parser.add_argument('-no_cuda', action='store_true')\n",
    "parser.add_argument('-SGDR', action='store_true')\n",
    "parser.add_argument('-epochs', type=int, default=10)\n",
    "parser.add_argument('-d_model', type=int, default=200)\n",
    "parser.add_argument('-n_layers', type=int, default=6)\n",
    "parser.add_argument('-heads', type=int, default=8)\n",
    "parser.add_argument('-dropout', type=int, default=0.1)\n",
    "parser.add_argument('-batchsize', type=int, default=1000)\n",
    "parser.add_argument('-printevery', type=int, default=5)\n",
    "parser.add_argument('-load_vocab', type=str, default='clir_it_en')\n",
    "\n",
    "if relevance_training == 1:\n",
    "    my_file = Path(\"weights/model_weights\")\n",
    "    if my_file.is_file():\n",
    "        parser.add_argument('-load_weights', type=str, default='weights')\n",
    "    else:\n",
    "        parser.add_argument('-load_weights', type=str, default=None)\n",
    "    parser.add_argument('-lr', type=int, default=0.01)\n",
    "else: \n",
    "    my_file = Path(\"weights/model_weights\")\n",
    "    if my_file.is_file():\n",
    "        parser.add_argument('-load_weights', type=str, default='weights')\n",
    "    else:\n",
    "        parser.add_argument('-load_weights', type=str, default=None)         \n",
    "    parser.add_argument('-lr', type=int, default=0.0001)\n",
    "    \n",
    "parser.add_argument('-create_valset', action='store_true')\n",
    "parser.add_argument('-max_strlen', type=int, default=80)\n",
    "parser.add_argument('-floyd', action='store_true')\n",
    "parser.add_argument('-checkpoint', type=int, default=5)\n",
    "\n",
    "opt = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):  # create a tokenizer function\n",
    "    return text.split()\n",
    "    \n",
    "def create_fields(opt):    \n",
    "    print(\"loading tokenizers...\") \n",
    "    TRG = data.Field(lower=True, tokenize=tokenizer, init_token='<sos>', eos_token='<eos>')\n",
    "    TRG_REL = data.Field(lower=True, tokenize=tokenizer, init_token='<sos>', eos_token='<eos>')    \n",
    "    #RM = data.Field(lower=True, tokenize=tokenizer, init_token='<sos>', eos_token='<eos>') ##     \n",
    "    SRC = data.Field(lower=True, tokenize=tokenizer)   \n",
    "    SRC = pickle.load(open(f'{opt.load_vocab}/SRC.pkl', 'rb'))\n",
    "    TRG = pickle.load(open(f'{opt.load_vocab}/TRG.pkl', 'rb'))\n",
    "    TRG_REL = pickle.load(open(f'{opt.load_vocab}/TRG.pkl', 'rb'))\n",
    "    return(SRC, TRG, TRG_REL)\n",
    "\n",
    "#this function will consider both europarl and CLEF\n",
    "def create_dataset(opt, SRC, TRG, TRG_REL):\n",
    "    print(\"creating dataset and iterator... \")\n",
    "    translation_data = [line for line in opt.trg_data] ###\n",
    "    relevance_data = [line for line in open(opt.rm_data)] ###    \n",
    "    \n",
    "    raw_data = {'src' : [line.strip() for line in opt.src_data], 'trg': translation_data, 'trg_rel': relevance_data} ###  \n",
    "    raw_data_retrieval = {'trg': [line for line in opt.trg_data_retrieval]}\n",
    "    \n",
    "    df = pd.DataFrame(raw_data, columns=[\"src\", \"trg\", \"trg_rel\"])\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(use_idf=True)\n",
    "    vectorizer.fit_transform(raw_data['trg'] + raw_data_retrieval['trg'])\n",
    "    \n",
    "    tokens = vectorizer.get_feature_names()\n",
    "    idf_values = vectorizer.idf_\n",
    "    opt.idf_dict = {}\n",
    "     \n",
    "    for i in range(len(tokens)):\n",
    "        opt.idf_dict.setdefault(tokens[i],idf_values[i]) \n",
    "    \n",
    "    mask = (df['src'].str.count(' ') < opt.max_strlen) & (df['trg'].str.count(' ') < opt.max_strlen)\n",
    "    df = df.loc[mask]\n",
    "\n",
    "    df.to_csv(\"translate_transformer_temp.csv\", index=False)\n",
    "\n",
    "    data_fields = [('src', SRC), ('trg', TRG) , ('trg_rel', TRG_REL)]\n",
    "    \n",
    "    train = data.TabularDataset('./translate_transformer_temp.csv', format='csv', fields=data_fields)\n",
    "\n",
    "    train_iter = MyIterator(train, batch_size=opt.batchsize, device=opt.device,\n",
    "                        repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                        batch_size_fn=batch_size_fn, train=True, shuffle=True)\n",
    "      \n",
    "    os.remove('translate_transformer_temp.csv')   \n",
    "    \n",
    "    if opt.load_vocab is None:\n",
    "        print(\"creating dataset for retrieval corpus... \")\n",
    "        raw_data = {'trg': [line for line in opt.trg_data_retrieval]}\n",
    "        df = pd.DataFrame(raw_data, columns=[\"trg\"])\n",
    "        mask = (df['trg'].str.count(' ') > 1)\n",
    "        df = df.loc[mask]\n",
    "        df.to_csv(\"translate_transformer_retrieval_temp.csv\", index=False)\n",
    "        data_fields = [('trg', TRG)]\n",
    "        train_retrieval = data.TabularDataset('./translate_transformer_retrieval_temp.csv', format='csv', fields=data_fields)\n",
    "        os.remove('translate_transformer_retrieval_temp.csv')    \n",
    "\n",
    "        print(\"building vocabulary for both europarl and retrieval corpus\")\n",
    "\n",
    "        SRC.build_vocab(train)\n",
    "        TRG.build_vocab(train, train_retrieval)\n",
    "\n",
    "    opt.src_pad = SRC.vocab.stoi['<pad>']\n",
    "    opt.trg_pad = TRG.vocab.stoi['<pad>']\n",
    "    opt.trg_pad = TRG.vocab.stoi['<pad>']\n",
    "    \n",
    "    opt.train_len = get_len(train_iter)\n",
    "    return train_iter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loading tokenizers...\n",
      "creating dataset and iterator... \n",
      "1894217\n",
      "1894217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model weights will be saved every 5 minutes and at end of epoch to directory weights/\n"
     ]
    }
   ],
   "source": [
    "opt.device = 0 if opt.no_cuda is False else -1\n",
    "if opt.device == 0:\n",
    "    assert torch.cuda.is_available()\n",
    "print(opt.device)\n",
    "read_data(opt)\n",
    "\n",
    "SRC, TRG, TRG_REL = create_fields(opt)\n",
    "opt.train = create_dataset(opt, SRC, TRG, TRG_REL)\n",
    "dst = ''\n",
    "#TRG = create_retrieval_vocabulary(opt, TRG)\n",
    "\n",
    "if opt.checkpoint > 0:\n",
    "    print(\"model weights will be saved every %d minutes and at end of epoch to directory weights/\"%(opt.checkpoint))\n",
    "    \n",
    "if opt.load_vocab is None:\n",
    "    pickle.dump(SRC, open(f'{dst}/SRC.pkl', 'wb'))\n",
    "    pickle.dump(TRG, open(f'{dst}/TRG.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained weights...\n",
      "<unk>\n",
      "240229\n"
     ]
    }
   ],
   "source": [
    "model = get_model(opt, len(SRC.vocab), len(TRG.vocab))\n",
    "opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "if opt.SGDR == True:\n",
    "    opt.sched = CosineWithRestarts(opt.optimizer, T_max=opt.train_len)\n",
    "    \n",
    "import subprocess \n",
    "super_client = SuperClient()\n",
    "print(TRG.vocab.itos[0])\n",
    "print(len(TRG.vocab))\n",
    "opt.idf_dict[\"<sos>\"] = 1\n",
    "opt.idf_dict[\"<eos>\"] = 1\n",
    "class_weights = []\n",
    "for i in range(len(TRG.vocab)):\n",
    "    if TRG.vocab.itos[i] in opt.idf_dict:\n",
    "        class_weights.append(opt.idf_dict[TRG.vocab.itos[i]])\n",
    "    else:\n",
    "        class_weights.append(0.0001)\n",
    "class_weights = torch.FloatTensor(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.checkpoint = 1\n",
    "def train_model(model, opt, SRC, TRG):\n",
    "    torch.cuda.empty_cache()\n",
    "    best_mAP = 0.15\n",
    "    inmem = WhooshInMemorySearch()\n",
    "    print(\"training model...\")\n",
    "    opt.idf_dict[\"<sos>\"] = 1\n",
    "    opt.idf_dict[\"<eos>\"] = 1\n",
    "    class_weights = []\n",
    "    for i in range(len(TRG.vocab)):\n",
    "        if TRG.vocab.itos[i] in opt.idf_dict:\n",
    "            class_weights.append(opt.idf_dict[TRG.vocab.itos[i]])            \n",
    "        else:\n",
    "            class_weights.append(0.0001)\n",
    "    \n",
    "    class_weights = torch.FloatTensor(class_weights)\n",
    "    model.train()\n",
    "    class_weights = class_weights.cuda()\n",
    "    start = time.time()\n",
    "    if opt.checkpoint > 0:\n",
    "        cptime = time.time()\n",
    "    \n",
    "    global_step = 0\n",
    "    for epoch in range(opt.epochs):\n",
    "        #print(\"beginning epoch:\")\n",
    "        total_loss = 0\n",
    "        \n",
    "        #print(\"   %dm: epoch %d [%s]  %d%%  loss = %s\" %\\\n",
    "        #((time.time() - start)//60, epoch + 1, \"\".join(' '*20), 0, '...'), end='\\r')\n",
    "\n",
    "        if opt.checkpoint > 0:\n",
    "            torch.save(model.state_dict(), 'weights/model_weights')\n",
    "                    \n",
    "        for i, batch in enumerate(opt.train):\n",
    "            torch.cuda.empty_cache()\n",
    "            start = time.clock()\n",
    "            src = batch.src.transpose(0,1) # src_size = (187, 4)\n",
    "            trg = batch.trg.transpose(0,1) # trg_size = (187, 8)             \n",
    "            trg_rel = batch.trg_rel.transpose(0,1)\n",
    "#           trg_idf = [[opt.idf_dict[TRG.vocab.itos[ind]] for ind in ex] for ex in trg]\n",
    "#           trg_idf = np.array(trg_idf)\n",
    "#           trg_idf = torch.FloatTensor(trg_idf)\n",
    "            #print (trg_idf.size())\n",
    "            \n",
    "            if relevance_training == 1:\n",
    "                trg_strings = [' '.join([TRG.vocab.itos[ind] for ind in ex]) for ex in trg]               \n",
    "                trg_strings_rm = super_client.query_expansion_distributed(trg_strings)                \n",
    "                trg_strings_rm_id = torch.LongTensor([[TRG.vocab.stoi[token] for token in sentence] for sentence in trg_strings_rm]).cuda()            \n",
    "                embed_trg = model.decoder.embed(trg_strings_rm_id)\n",
    "                #old loss\n",
    "                #embed_trg = embed_trg.view(embed_trg.size(0), -1)\n",
    "                #new loss \n",
    "                embed_trg = embed_trg.sum(1)\n",
    "            \n",
    "            if relevance_training == 2:\n",
    "                trg_strings_rm_id = torch.LongTensor([token_id for token_id in token_ids] for token_ids in trg_rel]).cuda()            \n",
    "                embed_trg = model.decoder.embed(trg_strings_rm_id)\n",
    "                #old loss\n",
    "                #embed_trg = embed_trg.view(embed_trg.size(0), -1)\n",
    "                #new loss \n",
    "                embed_trg = embed_trg.sum(1)\n",
    "            \n",
    "            \n",
    "            trg_input = trg[:, :-1]\n",
    "            src_mask, trg_mask = create_masks(src, trg_input, opt)            \n",
    "            src_mask = src_mask.cuda()            \n",
    "            trg_mask = trg_mask.cuda()\n",
    "            src = src.cuda() \n",
    "            trg_input = trg_input.cuda()                                  \n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            \n",
    "            #the goal is to find the embedding of the predictions \n",
    "            if relevance_training == 1: \n",
    "                out = F.softmax(preds, dim=-1)\n",
    "                probs, ix = out[:, :].data.topk(1)\n",
    "                preds_token_ids = ix.view(ix.size(0), -1)\n",
    "                #new loss function \n",
    "                embed_pred = model.decoder.embed(preds_token_ids)\n",
    "                embed_pred = embed_pred.sum(1)\n",
    "                #print(\"embed preds size \" + str(embed_pred_sum.size()))            \n",
    "\n",
    "                #old loss function\n",
    "#                 pred_strings = [' '.join([TRG.vocab.itos[ind] for ind in ex]) for ex in preds_token_ids]\n",
    "#                 pred_strings_rm = super_client.query_expansion_distributed(pred_strings)                                \n",
    "#                 pred_strings_rm_id = torch.LongTensor([[TRG.vocab.stoi[token] for token in sentence] for sentence in pred_strings_rm]).cuda()            \n",
    "#                 embed_pred = model.decoder.embed(pred_strings_rm_id)\n",
    "#                 embed_pred = embed_pred.view(embed_pred.size(0), -1)            \n",
    "                     \n",
    "            #ys_w = trg_idf[:, 1:].contiguous().view(-1).cuda()\n",
    "            if relevance_training == 2: \n",
    "                out = F.softmax(preds, dim=-1)\n",
    "                probs, ix = out[:, :].data.topk(1)\n",
    "                preds_token_ids = ix.view(ix.size(0), -1)\n",
    "                #new loss function \n",
    "                embed_pred = model.decoder.embed(preds_token_ids)\n",
    "                embed_pred = embed_pred.sum(1)\n",
    "\n",
    "            ys = trg[:, 1:].contiguous().view(-1).cuda()\n",
    "            opt.optimizer.zero_grad()\n",
    "            \n",
    "            if relevance_training == 1:\n",
    "                #loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad).add(\n",
    "                #((embed_trg.cuda() - embed_pred.cuda()) **2).mean())\n",
    "                loss1 = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, weight=ys_w, ignore_index=opt.trg_pad)              \n",
    "                loss2 = ((embed_trg.cuda() - embed_pred.cuda()) **2).mean()\n",
    "                \n",
    "                print(\"batch loss nmt\\t\" + str(loss1.item()) + \"\\tbatch loss relevance\\t\" + str(loss2.item()))\n",
    "                loss1.backward(retain_graph=True)\n",
    "                loss2.backward()      \n",
    "            if relevance_training == 2:\n",
    "                loss1 = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, weight=ys_w, ignore_index=opt.trg_pad)              \n",
    "                loss2 = ((embed_trg.cuda() - embed_pred.cuda()) **2).mean()\n",
    "                \n",
    "                print(\"batch loss nmt\\t\" + str(loss1.item()) + \"\\tbatch loss relevance\\t\" + str(loss2.item()))\n",
    "                loss1.backward(retain_graph=True)\n",
    "                loss2.backward()         \n",
    "            \n",
    "            else:\n",
    "                loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, weight=class_weights, ignore_index=opt.trg_pad)              \n",
    "                #loss = F.cross_entropy(preds.view(-1, preds.size(-1)), ys, ignore_index=opt.trg_pad)              \n",
    "                loss.backward()             \n",
    "            \n",
    "            opt.optimizer.step()\n",
    "            \n",
    "            if opt.SGDR == True: \n",
    "                opt.sched.step()\n",
    "            #total_loss += loss1.item() + loss2.item()\n",
    "            total_loss+= loss.item()\n",
    "            \n",
    "            if (i + 1) % opt.printevery == 0:\n",
    "                #print(\"lost after some iterations \" + str(total_loss))\n",
    "                \n",
    "                p = int(100 * (i + 1) / opt.train_len)\n",
    "                avg_loss = total_loss/opt.printevery\n",
    "                \n",
    "                #print(\"   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %\\\n",
    "                #((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss), end='\\r')\n",
    "                #print(avg_loss)\n",
    "                total_loss = 0\n",
    "            #We are saving the model every five minutes \n",
    "            if opt.checkpoint > 0 and ((time.time()-cptime)//60) // opt.checkpoint >= 1:\n",
    "                torch.save(model.state_dict(), 'weights/model_weights')                            \n",
    "                p = subprocess.Popen('CUDA_VISIBLE_DEVICES=2 python translate_validation.py', shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "                line = p.stdout.readlines()[0]\n",
    "                #print(line)\n",
    "                mAP = float(line.decode(\"utf-8\").strip().split()[1])\n",
    "                #print(\"current mAP is\\t\" + str(mAP))\n",
    "                #print(\"best mAP so far is\\t\" + str(best_mAP))     \n",
    "                print(str(global_step) + \"\\t\" + str(loss.item()) + \"\\t\" + str(mAP))\n",
    "                if mAP > best_mAP:\n",
    "                    #print(\"best mAP so far is \" + str(mAP)) \n",
    "                    #print(\"saving the model at model_weights_best_validation\")\n",
    "                    best_mAP = mAP\n",
    "                    torch.save(model.state_dict(), 'weights/model_weights_best_validation')\n",
    "                \n",
    "                #torch.save(model.state_dict(), 'weights/model_weights')  \n",
    "                \n",
    "                cptime = time.time()\n",
    "                # 1. Log scalar values (scalar summary)\n",
    "                info = { 'loss': loss.item(), 'map': mAP}\n",
    "                for tag, value in info.items():\n",
    "                    logger.scalar_summary(tag, value, global_step+1)\n",
    "                global_step+=1\n",
    "        print(\"%dm: epoch %d [%s%s]  %d%%  loss = %.3f\\nepoch %d complete, loss = %.03f\" %\\\n",
    "        ((time.time() - start)//60, epoch + 1, \"\".join('#'*(100//5)), \"\".join(' '*(20-(100//5))), 100, avg_loss, epoch + 1, avg_loss))\n",
    "        torch.save(model.state_dict(), 'weights/model_weights_8_' + str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n",
      "0\t3.7884838581085205\t0.1225\n",
      "1\t4.234820365905762\t0.1164\n",
      "2\t3.9458653926849365\t0.1252\n",
      "3\t6.230319499969482\t0.1449\n",
      "4\t3.608670234680176\t0.1403\n",
      "5\t3.5625908374786377\t0.1311\n",
      "6\t3.8527517318725586\t0.1347\n",
      "7\t4.155653953552246\t0.1222\n",
      "8\t4.225128173828125\t0.0879\n",
      "9\t4.1235198974609375\t0.0984\n",
      "10\t3.967794418334961\t0.1268\n",
      "11\t4.156708240509033\t0.1415\n",
      "12\t4.160446643829346\t0.1336\n",
      "13\t3.8999078273773193\t0.1091\n",
      "14\t3.716236114501953\t0.1027\n",
      "15\t4.504022121429443\t0.1351\n",
      "16\t3.8989346027374268\t0.1444\n",
      "17\t4.1869025230407715\t0.1426\n",
      "18\t3.788221597671509\t0.1398\n",
      "19\t4.45277738571167\t0.094\n",
      "20\t3.871441602706909\t0.1389\n",
      "21\t3.6745269298553467\t0.137\n",
      "22\t2.9278037548065186\t0.1282\n",
      "23\t3.819335699081421\t0.1138\n",
      "24\t4.125905513763428\t0.1326\n",
      "25\t3.6772305965423584\t0.1392\n",
      "26\t3.890035629272461\t0.1518\n",
      "27\t3.9780538082122803\t0.1411\n",
      "28\t4.294170379638672\t0.1271\n",
      "29\t3.6222739219665527\t0.1125\n",
      "30\t3.8926122188568115\t0.1188\n",
      "31\t4.538330078125\t0.1179\n",
      "32\t4.631744384765625\t0.1103\n",
      "33\t3.634626865386963\t0.1023\n",
      "34\t4.408799648284912\t0.1385\n",
      "35\t4.12120246887207\t0.118\n",
      "36\t3.9404807090759277\t0.1452\n",
      "37\t4.254159450531006\t0.1346\n",
      "38\t4.0202155113220215\t0.1344\n",
      "39\t3.766936779022217\t0.1522\n",
      "40\t3.94270396232605\t0.1295\n",
      "41\t3.6906237602233887\t0.1528\n",
      "42\t2.830595016479492\t0.1433\n",
      "43\t3.67138409614563\t0.1558\n",
      "44\t3.6494369506835938\t0.1459\n",
      "45\t3.618882417678833\t0.1315\n",
      "46\t4.198955059051514\t0.1459\n",
      "47\t3.916611433029175\t0.1434\n",
      "48\t4.27268123626709\t0.1471\n",
      "49\t3.624645948410034\t0.1416\n",
      "50\t4.37923526763916\t0.1362\n",
      "51\t4.1200666427612305\t0.1529\n",
      "52\t3.75400972366333\t0.1228\n",
      "53\t3.275911569595337\t0.1558\n",
      "54\t4.554801940917969\t0.116\n",
      "55\t3.945227861404419\t0.1382\n",
      "56\t4.255743026733398\t0.148\n",
      "57\t4.07435941696167\t0.1329\n",
      "58\t3.7149078845977783\t0.1337\n",
      "59\t3.6685268878936768\t0.1494\n",
      "60\t4.289419174194336\t0.1327\n",
      "61\t3.6989967823028564\t0.1376\n",
      "62\t3.878528356552124\t0.1334\n",
      "63\t3.6356046199798584\t0.1236\n",
      "64\t3.8784382343292236\t0.1312\n",
      "65\t3.6951842308044434\t0.1175\n",
      "66\t4.052004814147949\t0.1254\n",
      "67\t4.995370388031006\t0.1367\n",
      "68\t3.4747867584228516\t0.1176\n",
      "69\t4.539793491363525\t0.1379\n",
      "70\t3.646291971206665\t0.1397\n",
      "71\t4.429090976715088\t0.1448\n",
      "72\t3.735353469848633\t0.119\n",
      "73\t4.252101898193359\t0.1385\n",
      "74\t4.235543251037598\t0.1365\n",
      "75\t3.6915485858917236\t0.1232\n",
      "76\t3.6549925804138184\t0.1013\n",
      "77\t3.7607452869415283\t0.1198\n",
      "78\t3.8917720317840576\t0.1399\n",
      "79\t4.249714374542236\t0.0972\n",
      "80\t3.3401265144348145\t0.1253\n",
      "81\t3.8874995708465576\t0.1357\n",
      "82\t3.8983154296875\t0.1367\n",
      "83\t3.7479848861694336\t0.1297\n",
      "84\t3.8502118587493896\t0.1123\n",
      "85\t4.0792317390441895\t0.1579\n",
      "86\t3.7838592529296875\t0.1196\n",
      "87\t4.066050052642822\t0.1403\n",
      "88\t3.7024569511413574\t0.0962\n",
      "89\t3.6402385234832764\t0.1087\n",
      "90\t4.68551778793335\t0.1141\n",
      "91\t3.632761240005493\t0.1028\n",
      "92\t4.149399757385254\t0.1202\n",
      "93\t4.046103000640869\t0.1026\n",
      "94\t4.438033580780029\t0.1251\n",
      "95\t4.350517749786377\t0.1337\n",
      "96\t3.6991453170776367\t0.1143\n",
      "97\t4.340528964996338\t0.1174\n",
      "98\t3.9053149223327637\t0.1145\n",
      "99\t3.835841655731201\t0.1387\n",
      "100\t3.649318218231201\t0.1298\n",
      "101\t3.804295063018799\t0.1208\n",
      "102\t4.7929840087890625\t0.1191\n",
      "103\t3.895665168762207\t0.1409\n",
      "104\t3.7934176921844482\t0.1454\n",
      "105\t3.9429571628570557\t0.1164\n",
      "106\t3.5394062995910645\t0.1531\n",
      "107\t3.581589460372925\t0.1343\n",
      "108\t4.222898006439209\t0.16\n",
      "109\t3.88993239402771\t0.1378\n",
      "110\t3.7201249599456787\t0.1561\n",
      "111\t3.6086065769195557\t0.1013\n",
      "112\t4.217131614685059\t0.1061\n",
      "113\t4.185116767883301\t0.1086\n",
      "114\t3.796088933944702\t0.1406\n",
      "115\t4.080997943878174\t0.1135\n",
      "116\t3.931384563446045\t0.1356\n",
      "117\t3.8090991973876953\t0.1416\n",
      "118\t4.114957332611084\t0.1424\n",
      "119\t3.4247403144836426\t0.1172\n",
      "120\t3.6655876636505127\t0.1696\n",
      "121\t3.936568260192871\t0.1418\n",
      "122\t3.702504873275757\t0.1353\n",
      "123\t3.835325002670288\t0.1377\n",
      "124\t3.358037233352661\t0.1221\n",
      "125\t3.666076898574829\t0.1166\n",
      "126\t3.9094645977020264\t0.1326\n",
      "127\t3.862516403198242\t0.1133\n",
      "128\t4.228300094604492\t0.122\n",
      "129\t3.8250131607055664\t0.1257\n",
      "130\t4.068791389465332\t0.1199\n",
      "131\t3.7906711101531982\t0.1337\n",
      "132\t3.8781957626342773\t0.1467\n",
      "133\t3.631291151046753\t0.1211\n",
      "134\t4.478201866149902\t0.1482\n",
      "135\t3.995116949081421\t0.1508\n",
      "136\t3.7998578548431396\t0.1368\n",
      "137\t3.6747241020202637\t0.1484\n",
      "138\t4.1401591300964355\t0.0985\n",
      "139\t3.8587827682495117\t0.1294\n",
      "140\t3.840001106262207\t0.1437\n",
      "141\t4.757163047790527\t0.1323\n",
      "142\t3.576521635055542\t0.1114\n",
      "143\t3.6228621006011963\t0.1398\n",
      "144\t3.6053576469421387\t0.1293\n",
      "145\t3.604579448699951\t0.1292\n",
      "146\t3.70623517036438\t0.1477\n",
      "147\t3.9605371952056885\t0.1314\n",
      "148\t3.709620237350464\t0.1259\n",
      "149\t3.6896283626556396\t0.1086\n",
      "150\t3.824298620223999\t0.1342\n",
      "151\t3.9096670150756836\t0.107\n",
      "152\t3.6624667644500732\t0.1185\n",
      "153\t3.8777050971984863\t0.1318\n",
      "154\t3.6583752632141113\t0.1259\n",
      "155\t3.81435489654541\t0.1227\n",
      "156\t3.935037136077881\t0.1001\n",
      "157\t3.956935167312622\t0.119\n",
      "158\t4.6547112464904785\t0.0934\n",
      "159\t3.81266450881958\t0.1047\n",
      "160\t3.8305442333221436\t0.1104\n",
      "161\t4.024970531463623\t0.1006\n",
      "162\t3.948024034500122\t0.0985\n",
      "163\t4.092216491699219\t0.1358\n",
      "164\t4.023827075958252\t0.1218\n",
      "165\t4.128114700317383\t0.1315\n",
      "166\t3.8450868129730225\t0.1188\n",
      "167\t3.6345930099487305\t0.1307\n",
      "168\t3.9509835243225098\t0.1044\n",
      "169\t3.6374945640563965\t0.1379\n",
      "170\t3.825409173965454\t0.1364\n",
      "171\t4.02919340133667\t0.1439\n",
      "172\t3.5460991859436035\t0.1086\n",
      "173\t3.805877923965454\t0.1431\n",
      "174\t3.6586709022521973\t0.1233\n",
      "175\t3.6552255153656006\t0.1368\n",
      "176\t3.7946531772613525\t0.1225\n",
      "177\t3.6872503757476807\t0.1339\n",
      "178\t4.290874481201172\t0.1346\n",
      "179\t4.12180233001709\t0.1232\n",
      "180\t3.8021302223205566\t0.1146\n",
      "181\t3.856332778930664\t0.127\n",
      "182\t4.404448986053467\t0.1292\n",
      "183\t4.291302680969238\t0.125\n",
      "184\t3.6113948822021484\t0.1217\n",
      "185\t3.8481626510620117\t0.1209\n",
      "186\t3.9504663944244385\t0.1239\n",
      "187\t3.616541862487793\t0.1187\n",
      "188\t4.01279878616333\t0.124\n",
      "189\t4.302597522735596\t0.1056\n",
      "190\t3.504467010498047\t0.116\n",
      "191\t4.369464874267578\t0.1223\n",
      "192\t3.6431972980499268\t0.1233\n",
      "193\t3.5217854976654053\t0.1339\n",
      "194\t3.7067558765411377\t0.1107\n",
      "195\t4.489256858825684\t0.1311\n",
      "196\t3.6025636196136475\t0.1364\n",
      "197\t4.314231872558594\t0.112\n",
      "198\t4.022974491119385\t0.1052\n",
      "199\t3.568350076675415\t0.1064\n",
      "200\t4.062739372253418\t0.1149\n",
      "201\t4.001182556152344\t0.1288\n",
      "202\t4.213492393493652\t0.1058\n",
      "203\t3.966399669647217\t0.1193\n",
      "204\t3.6215405464172363\t0.1102\n",
      "205\t4.836109638214111\t0.1275\n",
      "206\t3.8366358280181885\t0.1309\n",
      "207\t3.7509865760803223\t0.129\n",
      "208\t3.461388111114502\t0.1311\n",
      "209\t4.080687046051025\t0.1243\n",
      "210\t3.8764820098876953\t0.1382\n",
      "211\t3.620426654815674\t0.1181\n",
      "212\t3.993588924407959\t0.1102\n",
      "213\t4.262438774108887\t0.1192\n",
      "214\t3.5950369834899902\t0.1073\n",
      "215\t3.836998224258423\t0.1133\n",
      "216\t3.5216822624206543\t0.1098\n",
      "217\t3.9666521549224854\t0.1268\n",
      "218\t4.249114990234375\t0.1209\n",
      "219\t4.153464317321777\t0.1299\n",
      "220\t3.6756742000579834\t0.0957\n",
      "221\t3.8920814990997314\t0.135\n",
      "222\t5.059423923492432\t0.126\n",
      "223\t4.786459445953369\t0.1164\n",
      "224\t3.923225164413452\t0.1174\n",
      "225\t3.5875399112701416\t0.1162\n",
      "226\t4.259035110473633\t0.0926\n",
      "227\t3.5735082626342773\t0.1116\n",
      "228\t4.112349987030029\t0.1233\n",
      "229\t1.6125545501708984\t0.1404\n",
      "230\t3.7468245029449463\t0.1091\n",
      "231\t3.608689546585083\t0.1196\n",
      "232\t3.539208173751831\t0.1474\n",
      "233\t4.214618682861328\t0.1524\n",
      "234\t3.553417921066284\t0.1301\n",
      "235\t3.686718225479126\t0.0951\n",
      "236\t3.688018560409546\t0.1009\n",
      "237\t3.811617374420166\t0.1109\n",
      "238\t3.7106101512908936\t0.1361\n",
      "239\t3.9305379390716553\t0.1263\n",
      "240\t3.391839027404785\t0.1033\n",
      "241\t3.727079391479492\t0.1391\n",
      "242\t3.840085983276367\t0.0964\n",
      "243\t4.125241279602051\t0.1276\n",
      "244\t4.166757106781006\t0.1363\n",
      "245\t3.611163854598999\t0.1315\n",
      "246\t4.05658483505249\t0.1458\n",
      "247\t4.25109338760376\t0.1057\n",
      "248\t3.5122909545898438\t0.1163\n",
      "249\t4.15136194229126\t0.1133\n",
      "250\t3.956389904022217\t0.1417\n",
      "251\t3.4040639400482178\t0.1324\n",
      "252\t4.687286853790283\t0.1233\n",
      "253\t4.83812141418457\t0.0959\n",
      "254\t4.089211463928223\t0.1296\n",
      "255\t3.746089458465576\t0.1493\n",
      "256\t4.373818397521973\t0.1557\n",
      "257\t3.71982741355896\t0.1215\n",
      "258\t3.6649057865142822\t0.1377\n",
      "259\t3.805938243865967\t0.1105\n",
      "260\t4.680771350860596\t0.1229\n",
      "261\t3.663198232650757\t0.1532\n",
      "262\t3.687347412109375\t0.1601\n",
      "263\t3.528639078140259\t0.1213\n",
      "264\t3.3384146690368652\t0.1438\n",
      "265\t4.071770668029785\t0.1532\n",
      "266\t3.883960008621216\t0.1487\n",
      "267\t3.905466079711914\t0.1382\n",
      "268\t3.8799896240234375\t0.1186\n",
      "269\t3.8771486282348633\t0.1425\n",
      "270\t3.9800190925598145\t0.145\n",
      "271\t3.9564855098724365\t0.1028\n",
      "272\t3.696049928665161\t0.1159\n",
      "273\t3.999630928039551\t0.1476\n",
      "274\t4.269918441772461\t0.1362\n",
      "275\t3.637850761413574\t0.1542\n",
      "276\t4.1750712394714355\t0.1593\n",
      "277\t1.3676549196243286\t0.145\n",
      "278\t3.962766170501709\t0.1534\n",
      "279\t3.448394536972046\t0.1569\n",
      "280\t3.337618827819824\t0.1117\n",
      "281\t4.05487060546875\t0.0915\n",
      "282\t3.930065155029297\t0.1229\n",
      "283\t3.67527437210083\t0.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\t4.180558204650879\t0.149\n",
      "285\t3.5520238876342773\t0.1088\n",
      "286\t3.931853771209717\t0.1124\n",
      "287\t3.9226174354553223\t0.1156\n",
      "288\t3.5832507610321045\t0.1366\n",
      "289\t3.6951212882995605\t0.1289\n",
      "290\t3.846214532852173\t0.1246\n",
      "291\t3.5974676609039307\t0.1269\n",
      "292\t3.8336257934570312\t0.1038\n",
      "293\t4.22176456451416\t0.136\n",
      "294\t4.41612434387207\t0.1252\n",
      "295\t4.144439697265625\t0.1213\n",
      "296\t3.6642966270446777\t0.1218\n",
      "297\t3.780883312225342\t0.1264\n",
      "298\t3.8099570274353027\t0.105\n",
      "299\t4.332866668701172\t0.1353\n",
      "300\t4.009336948394775\t0.1134\n",
      "301\t4.259526252746582\t0.1452\n",
      "302\t3.9161629676818848\t0.1094\n",
      "303\t4.116866588592529\t0.1009\n",
      "304\t4.424443244934082\t0.1304\n",
      "305\t4.112651824951172\t0.1157\n",
      "306\t4.087150573730469\t0.1109\n",
      "307\t4.200462341308594\t0.1361\n",
      "308\t3.2811808586120605\t0.1141\n",
      "309\t4.295328617095947\t0.1267\n",
      "310\t2.2064003944396973\t0.1093\n",
      "311\t4.091166019439697\t0.1177\n",
      "312\t3.575411796569824\t0.1109\n",
      "313\t3.7301833629608154\t0.1091\n",
      "314\t4.081258773803711\t0.1181\n",
      "315\t3.1733953952789307\t0.1012\n",
      "316\t3.768211603164673\t0.116\n",
      "317\t3.287606716156006\t0.1077\n",
      "318\t4.180471420288086\t0.1184\n",
      "319\t3.6795289516448975\t0.1451\n",
      "320\t3.901918649673462\t0.1351\n",
      "321\t3.5636985301971436\t0.1058\n",
      "322\t4.243492126464844\t0.1193\n",
      "323\t3.794502019882202\t0.1219\n",
      "324\t4.040070533752441\t0.1152\n",
      "325\t4.629956245422363\t0.1057\n",
      "326\t3.8951704502105713\t0.0977\n",
      "327\t3.5991766452789307\t0.1047\n",
      "328\t3.736088514328003\t0.1611\n",
      "329\t3.342822790145874\t0.1261\n",
      "330\t3.4681339263916016\t0.1355\n",
      "331\t3.685535430908203\t0.1573\n",
      "332\t4.525730133056641\t0.1277\n",
      "333\t3.6485743522644043\t0.1256\n",
      "334\t4.007820129394531\t0.1274\n",
      "335\t4.3712592124938965\t0.136\n",
      "336\t3.969463586807251\t0.1168\n",
      "337\t3.7730772495269775\t0.13\n",
      "338\t3.9024572372436523\t0.121\n",
      "339\t4.357235908508301\t0.126\n",
      "340\t3.59155011177063\t0.1294\n",
      "341\t4.106928825378418\t0.1219\n",
      "342\t3.8718597888946533\t0.1279\n",
      "343\t4.507061004638672\t0.1246\n",
      "344\t3.455264091491699\t0.1259\n",
      "345\t0.1845232993364334\t0.1264\n",
      "346\t4.070279598236084\t0.1445\n",
      "347\t3.855714797973633\t0.1474\n",
      "348\t4.637484073638916\t0.1324\n",
      "349\t3.772860050201416\t0.1487\n",
      "350\t3.9115803241729736\t0.145\n",
      "351\t4.11955451965332\t0.1176\n",
      "352\t3.986337423324585\t0.1117\n",
      "353\t3.7920162677764893\t0.1171\n",
      "354\t3.9213967323303223\t0.1217\n",
      "355\t3.7040374279022217\t0.1472\n",
      "356\t4.065990924835205\t0.1136\n",
      "357\t3.915372848510742\t0.1193\n",
      "358\t3.492083787918091\t0.1238\n",
      "359\t3.6670761108398438\t0.1051\n",
      "360\t3.759671688079834\t0.1083\n",
      "361\t3.3469808101654053\t0.1184\n",
      "362\t3.826911687850952\t0.11\n",
      "363\t4.591104507446289\t0.1007\n",
      "364\t4.04056978225708\t0.128\n",
      "365\t3.88362979888916\t0.1343\n",
      "366\t3.2580082416534424\t0.1091\n",
      "367\t3.8533689975738525\t0.1002\n",
      "368\t3.6039624214172363\t0.12\n",
      "369\t3.430239200592041\t0.1169\n",
      "370\t3.60286808013916\t0.1054\n",
      "371\t3.9491817951202393\t0.1326\n",
      "372\t3.6687302589416504\t0.1099\n",
      "373\t4.163804054260254\t0.1276\n",
      "374\t4.299777507781982\t0.1161\n",
      "375\t3.646636724472046\t0.127\n",
      "376\t4.582789421081543\t0.1356\n",
      "377\t3.7987844944000244\t0.1331\n",
      "378\t3.1988394260406494\t0.1155\n",
      "379\t3.081707000732422\t0.1259\n",
      "380\t3.58242130279541\t0.1224\n",
      "381\t4.241805076599121\t0.1184\n",
      "382\t3.9263627529144287\t0.1235\n",
      "383\t3.784926176071167\t0.1166\n",
      "384\t4.431690216064453\t0.118\n",
      "385\t3.5793237686157227\t0.1392\n",
      "386\t3.7213127613067627\t0.1417\n",
      "387\t3.9256467819213867\t0.0981\n",
      "388\t3.3254950046539307\t0.1117\n",
      "389\t4.096802711486816\t0.1437\n",
      "390\t3.43471622467041\t0.1244\n",
      "391\t3.4767234325408936\t0.1447\n",
      "392\t3.9165327548980713\t0.1189\n",
      "393\t4.055421829223633\t0.1292\n",
      "394\t3.9386353492736816\t0.1239\n",
      "395\t4.160141944885254\t0.1006\n",
      "396\t3.800197124481201\t0.0937\n",
      "397\t3.5917203426361084\t0.117\n",
      "398\t3.745814561843872\t0.1097\n",
      "399\t4.29567289352417\t0.1132\n",
      "400\t3.4902992248535156\t0.1092\n",
      "401\t3.8965749740600586\t0.126\n",
      "402\t3.9111828804016113\t0.0925\n",
      "403\t3.5077221393585205\t0.1291\n",
      "404\t3.9584474563598633\t0.1578\n",
      "405\t3.867466688156128\t0.1286\n",
      "406\t4.083051681518555\t0.1319\n",
      "407\t4.140568256378174\t0.1247\n",
      "408\t3.825552225112915\t0.1139\n",
      "409\t4.316129684448242\t0.1095\n",
      "410\t4.048329830169678\t0.1178\n",
      "411\t4.839705944061279\t0.1427\n",
      "412\t3.7608702182769775\t0.123\n",
      "413\t3.9798784255981445\t0.119\n",
      "414\t3.855273485183716\t0.1221\n",
      "415\t3.7670092582702637\t0.1344\n",
      "416\t3.30928635597229\t0.0985\n",
      "417\t3.3144686222076416\t0.1142\n",
      "418\t3.9413084983825684\t0.1234\n",
      "419\t3.723074436187744\t0.1165\n",
      "420\t3.3919293880462646\t0.1359\n",
      "421\t3.9560582637786865\t0.1345\n",
      "422\t4.055492877960205\t0.1361\n",
      "423\t3.6719236373901367\t0.1285\n",
      "424\t3.2723701000213623\t0.1273\n",
      "425\t4.057528495788574\t0.1291\n",
      "426\t3.980555772781372\t0.1382\n",
      "427\t3.555201292037964\t0.1124\n",
      "428\t3.6976754665374756\t0.1367\n",
      "429\t3.9950575828552246\t0.1368\n",
      "430\t4.457656383514404\t0.14\n",
      "431\t3.8900609016418457\t0.1293\n",
      "432\t3.7627172470092773\t0.1215\n",
      "433\t3.6864397525787354\t0.1191\n",
      "434\t3.372248888015747\t0.1157\n",
      "435\t3.810883045196533\t0.1195\n",
      "436\t3.6935007572174072\t0.1126\n",
      "437\t1.126662015914917\t0.1166\n",
      "438\t3.752443552017212\t0.1204\n",
      "439\t3.8683600425720215\t0.1219\n",
      "440\t3.7447402477264404\t0.1119\n",
      "441\t3.7213399410247803\t0.128\n",
      "442\t3.945537567138672\t0.125\n",
      "443\t3.9755308628082275\t0.1531\n",
      "444\t3.63692569732666\t0.1093\n",
      "445\t3.601168632507324\t0.139\n",
      "446\t3.9621963500976562\t0.1292\n",
      "447\t3.648171901702881\t0.1257\n",
      "448\t4.332463264465332\t0.1316\n",
      "449\t3.835505723953247\t0.1169\n",
      "450\t3.5881993770599365\t0.1251\n",
      "451\t3.6288084983825684\t0.11\n",
      "452\t4.234906196594238\t0.098\n",
      "453\t3.559242010116577\t0.1224\n",
      "454\t3.7929983139038086\t0.1006\n",
      "455\t4.23481559753418\t0.1229\n",
      "456\t3.9911773204803467\t0.1078\n",
      "457\t3.4609124660491943\t0.1034\n",
      "458\t3.7959160804748535\t0.1186\n",
      "459\t3.804521083831787\t0.1206\n",
      "460\t3.8598008155822754\t0.1268\n",
      "461\t4.382070064544678\t0.0975\n",
      "462\t3.5648245811462402\t0.1055\n",
      "463\t3.5801103115081787\t0.1127\n",
      "464\t3.7745659351348877\t0.1181\n",
      "465\t3.5107593536376953\t0.117\n",
      "466\t3.8320202827453613\t0.1171\n",
      "467\t4.0825676918029785\t0.1074\n",
      "468\t3.975492238998413\t0.1331\n",
      "469\t4.089849472045898\t0.1237\n",
      "470\t6.398855209350586\t0.0957\n",
      "471\t3.968411922454834\t0.1083\n",
      "472\t4.178274154663086\t0.1263\n",
      "473\t3.7263126373291016\t0.1378\n",
      "25823649m: epoch 1 [####################]  100%  loss = 3.835\n",
      "epoch 1 complete, loss = 3.835\n",
      "474\t3.892916440963745\t0.1138\n",
      "475\t3.9346611499786377\t0.1108\n",
      "476\t4.569705963134766\t0.0989\n",
      "477\t3.526531219482422\t0.132\n",
      "478\t3.7782177925109863\t0.1162\n",
      "479\t3.6798810958862305\t0.1159\n",
      "480\t4.534987926483154\t0.1445\n",
      "481\t3.6059463024139404\t0.1254\n",
      "482\t3.414926528930664\t0.1492\n",
      "483\t4.0629096031188965\t0.1151\n",
      "484\t3.811462163925171\t0.1156\n",
      "485\t3.588923931121826\t0.1101\n",
      "486\t4.032083034515381\t0.116\n",
      "487\t3.407548666000366\t0.1157\n",
      "488\t3.8635690212249756\t0.1281\n",
      "489\t3.787313461303711\t0.1133\n",
      "490\t4.012941360473633\t0.1034\n",
      "491\t4.3075666427612305\t0.1315\n",
      "492\t3.5557892322540283\t0.1367\n",
      "493\t3.4608285427093506\t0.1243\n",
      "494\t3.78070068359375\t0.1117\n",
      "495\t3.6398165225982666\t0.1227\n",
      "496\t3.7857565879821777\t0.1256\n",
      "497\t3.574347972869873\t0.1022\n",
      "498\t3.4830503463745117\t0.1274\n",
      "499\t3.8677773475646973\t0.1365\n",
      "500\t3.5544159412384033\t0.1106\n",
      "501\t3.447998285293579\t0.1236\n",
      "502\t3.8056273460388184\t0.1059\n",
      "503\t5.246589660644531\t0.1244\n",
      "504\t3.9496943950653076\t0.1112\n",
      "505\t4.000967025756836\t0.107\n",
      "506\t3.6366164684295654\t0.1301\n",
      "507\t3.2831931114196777\t0.1191\n",
      "508\t3.9130775928497314\t0.1064\n",
      "509\t3.3965578079223633\t0.1391\n",
      "510\t3.790043354034424\t0.1375\n",
      "511\t3.0210115909576416\t0.16\n",
      "512\t4.152797698974609\t0.1277\n",
      "513\t4.24473762512207\t0.1111\n",
      "514\t4.04093074798584\t0.1072\n",
      "515\t3.7192790508270264\t0.1387\n",
      "516\t3.652585506439209\t0.1232\n",
      "517\t3.4122660160064697\t0.1396\n",
      "518\t3.465284585952759\t0.1486\n",
      "519\t3.995673894882202\t0.1362\n",
      "520\t3.883725881576538\t0.1293\n",
      "521\t3.666335344314575\t0.1392\n",
      "522\t3.7781152725219727\t0.1276\n",
      "523\t4.106687545776367\t0.1329\n",
      "524\t4.0467352867126465\t0.1152\n",
      "525\t3.733558177947998\t0.1039\n",
      "526\t3.8519349098205566\t0.1353\n",
      "527\t3.940807819366455\t0.1107\n",
      "528\t3.702303171157837\t0.1637\n",
      "529\t3.950918197631836\t0.1283\n",
      "530\t4.013375759124756\t0.1212\n",
      "531\t4.040633201599121\t0.1574\n",
      "532\t4.015963077545166\t0.1284\n",
      "533\t3.6413888931274414\t0.119\n",
      "534\t3.5476763248443604\t0.1387\n",
      "535\t3.860042095184326\t0.1386\n",
      "536\t3.272977352142334\t0.1144\n",
      "537\t3.501972198486328\t0.1244\n",
      "538\t3.42167067527771\t0.1152\n",
      "539\t3.9145920276641846\t0.1284\n",
      "540\t3.464768886566162\t0.1363\n",
      "541\t3.6899545192718506\t0.0997\n",
      "542\t3.8935387134552\t0.125\n",
      "543\t3.691490888595581\t0.1054\n",
      "544\t4.203343868255615\t0.1192\n",
      "545\t3.5925328731536865\t0.1232\n",
      "546\t3.5985538959503174\t0.1054\n",
      "547\t3.8137850761413574\t0.1432\n",
      "548\t4.166223526000977\t0.122\n",
      "549\t3.206617593765259\t0.134\n",
      "550\t3.580195426940918\t0.0892\n",
      "551\t3.797199249267578\t0.0947\n",
      "552\t4.15365743637085\t0.1091\n",
      "553\t3.8398759365081787\t0.1154\n",
      "554\t3.4057810306549072\t0.112\n",
      "555\t4.0742316246032715\t0.1182\n",
      "556\t4.161370754241943\t0.1186\n",
      "557\t4.087749004364014\t0.1354\n",
      "558\t3.3254079818725586\t0.1144\n",
      "559\t3.8945791721343994\t0.1134\n",
      "560\t3.375393867492676\t0.114\n",
      "561\t4.106378078460693\t0.1478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562\t4.026952743530273\t0.1288\n",
      "563\t3.7012569904327393\t0.1161\n",
      "564\t3.9194936752319336\t0.1258\n",
      "565\t3.9520022869110107\t0.1287\n",
      "566\t3.6345441341400146\t0.1138\n",
      "567\t3.899383068084717\t0.1072\n",
      "568\t4.044710636138916\t0.1083\n",
      "569\t3.638409376144409\t0.1269\n",
      "570\t3.497030019760132\t0.14\n",
      "571\t3.4805984497070312\t0.1396\n",
      "572\t3.638235569000244\t0.1509\n",
      "573\t3.4710140228271484\t0.113\n",
      "574\t3.617884874343872\t0.1044\n",
      "575\t3.409316062927246\t0.1212\n",
      "576\t4.45103645324707\t0.1242\n",
      "577\t3.4970669746398926\t0.1239\n",
      "578\t3.3639256954193115\t0.1421\n",
      "579\t4.9568657875061035\t0.1146\n",
      "580\t3.9203896522521973\t0.1337\n",
      "581\t3.8524386882781982\t0.146\n",
      "582\t3.6283345222473145\t0.1085\n",
      "583\t3.6385562419891357\t0.096\n",
      "584\t3.705982208251953\t0.1192\n",
      "585\t3.5681405067443848\t0.1334\n",
      "586\t3.7330286502838135\t0.1329\n",
      "587\t3.6243698596954346\t0.115\n",
      "588\t3.38537859916687\t0.1223\n",
      "589\t3.7507612705230713\t0.1216\n",
      "590\t3.3929483890533447\t0.1184\n",
      "591\t3.860651969909668\t0.1341\n",
      "592\t2.9980154037475586\t0.1315\n",
      "593\t4.1174726486206055\t0.1327\n",
      "594\t3.728353977203369\t0.1265\n",
      "595\t4.090984344482422\t0.1372\n",
      "596\t3.600748300552368\t0.1218\n",
      "597\t3.990502119064331\t0.1084\n",
      "598\t3.618299722671509\t0.1328\n",
      "599\t3.6736366748809814\t0.1358\n",
      "600\t4.107479095458984\t0.1168\n",
      "601\t3.1915364265441895\t0.1042\n",
      "602\t3.658458709716797\t0.1201\n",
      "603\t3.4234867095947266\t0.1478\n",
      "604\t3.586681842803955\t0.1159\n",
      "605\t3.9184696674346924\t0.1209\n",
      "606\t4.002195358276367\t0.1183\n",
      "607\t3.4464187622070312\t0.1056\n",
      "608\t3.765930652618408\t0.1031\n",
      "609\t3.9406304359436035\t0.1319\n",
      "610\t3.2011406421661377\t0.1368\n",
      "611\t4.339470386505127\t0.117\n",
      "612\t3.4018208980560303\t0.1164\n",
      "613\t3.459650993347168\t0.1329\n",
      "614\t3.982935905456543\t0.114\n",
      "615\t2.7736024856567383\t0.1362\n",
      "616\t4.046878337860107\t0.1244\n",
      "617\t3.7583816051483154\t0.1431\n",
      "618\t3.905574083328247\t0.1199\n",
      "619\t3.754405975341797\t0.1247\n",
      "620\t3.767007827758789\t0.1213\n",
      "621\t3.794839859008789\t0.1283\n",
      "622\t3.7041714191436768\t0.1238\n",
      "623\t3.8986167907714844\t0.1038\n",
      "624\t3.8770627975463867\t0.1031\n",
      "625\t3.4774956703186035\t0.1213\n",
      "626\t3.970538377761841\t0.1139\n",
      "627\t2.978307008743286\t0.101\n",
      "628\t4.221346855163574\t0.1158\n",
      "629\t3.898117780685425\t0.0933\n",
      "630\t3.5850069522857666\t0.1131\n",
      "631\t3.834815502166748\t0.1355\n",
      "632\t3.2949793338775635\t0.1422\n",
      "633\t3.689210891723633\t0.1123\n",
      "634\t3.8975915908813477\t0.0978\n",
      "635\t3.528446674346924\t0.1073\n",
      "636\t4.294792652130127\t0.1268\n",
      "637\t4.233399868011475\t0.1085\n",
      "638\t4.221960544586182\t0.107\n",
      "639\t3.5095818042755127\t0.1009\n",
      "640\t4.246638298034668\t0.1172\n",
      "641\t3.713707208633423\t0.1429\n",
      "642\t0.5627553462982178\t0.1256\n",
      "643\t3.3928210735321045\t0.1235\n",
      "644\t3.770010232925415\t0.1216\n",
      "645\t3.8123743534088135\t0.1275\n",
      "646\t4.219485282897949\t0.1381\n",
      "647\t4.022872447967529\t0.1508\n",
      "648\t3.485078811645508\t0.1384\n",
      "649\t3.9299352169036865\t0.1278\n",
      "650\t3.710665464401245\t0.1218\n",
      "651\t4.272150039672852\t0.1223\n",
      "652\t3.7691962718963623\t0.095\n",
      "653\t3.6737923622131348\t0.1136\n",
      "654\t3.4744203090667725\t0.1182\n",
      "655\t3.5193746089935303\t0.126\n",
      "656\t3.915215492248535\t0.1165\n",
      "657\t3.6398024559020996\t0.114\n",
      "658\t4.144503116607666\t0.1364\n",
      "659\t4.066447734832764\t0.1229\n",
      "660\t3.7219901084899902\t0.1207\n",
      "661\t3.805294990539551\t0.1306\n",
      "662\t3.8296093940734863\t0.1253\n",
      "663\t3.7078511714935303\t0.1131\n",
      "664\t3.4499294757843018\t0.1369\n",
      "665\t3.2554240226745605\t0.1384\n",
      "666\t3.4150121212005615\t0.1269\n",
      "667\t3.7830653190612793\t0.1308\n",
      "668\t4.141863822937012\t0.1409\n",
      "669\t3.6082851886749268\t0.1196\n",
      "670\t4.095395088195801\t0.1185\n",
      "671\t3.523953437805176\t0.1143\n",
      "672\t3.6217687129974365\t0.1224\n",
      "673\t4.017801761627197\t0.1238\n",
      "674\t3.548891544342041\t0.1194\n",
      "675\t3.7300426959991455\t0.1339\n",
      "676\t3.8624448776245117\t0.1308\n",
      "677\t3.847379207611084\t0.1344\n",
      "678\t3.785959005355835\t0.1094\n",
      "679\t3.2807836532592773\t0.1218\n",
      "680\t3.9981539249420166\t0.1353\n",
      "681\t3.9805638790130615\t0.1084\n",
      "682\t3.557253360748291\t0.1593\n",
      "683\t4.061285018920898\t0.144\n",
      "684\t3.6518235206604004\t0.1251\n",
      "685\t3.793940544128418\t0.1227\n",
      "686\t3.30960750579834\t0.1578\n",
      "687\t3.6602141857147217\t0.1146\n",
      "688\t3.741417169570923\t0.1151\n",
      "689\t3.864466905593872\t0.1264\n",
      "690\t1.9809296131134033\t0.105\n",
      "691\t3.808734893798828\t0.1384\n",
      "692\t3.6735546588897705\t0.1368\n",
      "693\t3.6533451080322266\t0.1087\n",
      "694\t3.775538444519043\t0.1378\n",
      "695\t3.617358922958374\t0.0839\n",
      "696\t4.00778341293335\t0.118\n",
      "697\t3.3916749954223633\t0.136\n",
      "698\t3.4433822631835938\t0.1089\n",
      "699\t3.6120734214782715\t0.1049\n",
      "700\t3.4389781951904297\t0.1045\n",
      "701\t4.144984722137451\t0.0914\n",
      "702\t3.772831678390503\t0.1338\n",
      "703\t3.3435568809509277\t0.1358\n",
      "704\t3.5641541481018066\t0.1136\n",
      "705\t4.150755882263184\t0.1276\n",
      "706\t3.7215466499328613\t0.1414\n",
      "707\t3.334289789199829\t0.1099\n",
      "708\t3.689793586730957\t0.096\n",
      "709\t3.6537563800811768\t0.1329\n",
      "710\t4.280359745025635\t0.118\n",
      "711\t4.242412567138672\t0.1258\n",
      "712\t4.212873458862305\t0.1216\n",
      "713\t3.9848952293395996\t0.1324\n",
      "714\t3.539741277694702\t0.1368\n",
      "715\t3.763657569885254\t0.122\n",
      "716\t3.6177682876586914\t0.1195\n",
      "717\t3.61891770362854\t0.147\n",
      "718\t3.7873291969299316\t0.1351\n",
      "719\t3.5999624729156494\t0.1348\n",
      "720\t3.415947437286377\t0.1327\n",
      "721\t3.4706077575683594\t0.1396\n",
      "722\t3.701246500015259\t0.1406\n",
      "723\t3.7185163497924805\t0.1136\n",
      "724\t4.253828048706055\t0.1191\n",
      "725\t3.7490992546081543\t0.1156\n",
      "726\t3.8242781162261963\t0.1279\n",
      "727\t3.523639678955078\t0.11\n",
      "728\t5.230822563171387\t0.1287\n",
      "729\t3.723968744277954\t0.1136\n",
      "730\t3.7021985054016113\t0.1283\n",
      "731\t4.290334701538086\t0.114\n",
      "732\t3.7531578540802\t0.1256\n",
      "733\t3.7272815704345703\t0.1452\n",
      "734\t4.030740261077881\t0.1084\n",
      "735\t3.675081729888916\t0.1237\n",
      "736\t3.324098587036133\t0.1306\n",
      "737\t3.88352370262146\t0.1247\n",
      "738\t4.009068012237549\t0.1064\n",
      "739\t4.187717914581299\t0.1103\n",
      "740\t4.241209030151367\t0.1084\n",
      "741\t4.55808162689209\t0.1112\n",
      "742\t3.381455898284912\t0.1079\n",
      "743\t3.618112087249756\t0.1379\n",
      "744\t3.449676513671875\t0.1241\n",
      "745\t3.843655824661255\t0.1399\n",
      "746\t3.8441312313079834\t0.1242\n",
      "747\t3.4725992679595947\t0.1339\n",
      "748\t3.4117774963378906\t0.1302\n",
      "749\t3.7326622009277344\t0.1313\n",
      "750\t3.3138716220855713\t0.1404\n",
      "751\t3.5448074340820312\t0.1313\n",
      "752\t3.787595272064209\t0.1023\n",
      "753\t3.651839017868042\t0.1281\n",
      "754\t3.518950939178467\t0.1366\n",
      "755\t4.032787322998047\t0.158\n",
      "756\t4.167116165161133\t0.1312\n",
      "757\t3.730396032333374\t0.1266\n",
      "758\t3.9532642364501953\t0.1259\n",
      "759\t4.015796661376953\t0.1051\n",
      "760\t3.4244349002838135\t0.1408\n",
      "761\t3.617323637008667\t0.1098\n",
      "762\t3.398361921310425\t0.1155\n",
      "763\t3.676621198654175\t0.1421\n",
      "764\t4.2062788009643555\t0.1337\n",
      "765\t4.019139289855957\t0.1287\n",
      "766\t4.055509567260742\t0.1375\n",
      "767\t3.6457574367523193\t0.1459\n",
      "768\t4.0118279457092285\t0.1312\n",
      "769\t3.416771411895752\t0.1263\n",
      "770\t3.8586971759796143\t0.1385\n",
      "771\t3.5841100215911865\t0.1137\n",
      "772\t3.763979911804199\t0.1274\n",
      "773\t3.7189528942108154\t0.1624\n",
      "774\t3.617597818374634\t0.1196\n",
      "775\t3.6751163005828857\t0.1043\n",
      "776\t3.690650224685669\t0.1317\n",
      "777\t3.8453171253204346\t0.128\n",
      "778\t4.088212966918945\t0.14\n",
      "779\t3.7541983127593994\t0.1388\n",
      "780\t3.860689640045166\t0.1414\n",
      "781\t3.5553605556488037\t0.1532\n",
      "782\t3.829646348953247\t0.1373\n",
      "783\t3.5754029750823975\t0.1204\n",
      "784\t3.60113787651062\t0.13\n",
      "785\t3.714738607406616\t0.1298\n",
      "786\t3.8112382888793945\t0.1238\n",
      "787\t3.5787885189056396\t0.1249\n",
      "788\t3.752730131149292\t0.106\n",
      "789\t3.8830292224884033\t0.1124\n",
      "790\t3.7614004611968994\t0.1147\n",
      "791\t3.657496690750122\t0.127\n",
      "792\t3.6742892265319824\t0.1193\n",
      "793\t3.8683407306671143\t0.1266\n",
      "794\t3.6699278354644775\t0.1406\n",
      "795\t4.0437092781066895\t0.1193\n",
      "796\t3.6982524394989014\t0.1134\n",
      "797\t4.56431245803833\t0.1261\n",
      "798\t3.3013241291046143\t0.1183\n",
      "799\t3.6994059085845947\t0.1419\n",
      "800\t3.5613906383514404\t0.0992\n",
      "801\t3.6958563327789307\t0.125\n",
      "802\t3.452152729034424\t0.1158\n",
      "803\t3.6052589416503906\t0.0939\n",
      "804\t3.181318521499634\t0.0839\n",
      "805\t3.8486416339874268\t0.1341\n",
      "806\t3.965024948120117\t0.1124\n",
      "807\t3.352855920791626\t0.1587\n",
      "808\t3.819504976272583\t0.1323\n",
      "809\t3.846158027648926\t0.1205\n",
      "810\t3.836740493774414\t0.1194\n",
      "811\t4.127979278564453\t0.1193\n",
      "812\t3.4022340774536133\t0.1168\n",
      "813\t4.109687328338623\t0.1181\n",
      "814\t3.913564920425415\t0.1193\n",
      "815\t3.5135343074798584\t0.1275\n",
      "816\t3.862086534500122\t0.1404\n",
      "817\t3.426621198654175\t0.1081\n",
      "818\t3.325183868408203\t0.121\n",
      "819\t3.6870360374450684\t0.1181\n",
      "820\t3.6273961067199707\t0.1009\n",
      "821\t4.354398250579834\t0.1148\n",
      "822\t4.272198677062988\t0.1258\n",
      "823\t3.5723817348480225\t0.1179\n",
      "824\t3.6259982585906982\t0.1207\n",
      "825\t3.6485936641693115\t0.1143\n",
      "826\t3.41428804397583\t0.139\n",
      "827\t4.0351786613464355\t0.1182\n",
      "828\t4.212143898010254\t0.1293\n",
      "829\t3.92146372795105\t0.1325\n",
      "830\t3.9024529457092285\t0.1292\n",
      "831\t3.5669562816619873\t0.1199\n",
      "832\t3.914269208908081\t0.1245\n",
      "833\t3.8256676197052\t0.108\n",
      "834\t3.719663619995117\t0.1174\n",
      "835\t3.703773260116577\t0.1131\n",
      "836\t3.4348955154418945\t0.1388\n",
      "837\t3.82521653175354\t0.1011\n",
      "838\t3.9237122535705566\t0.1546\n",
      "839\t4.492525100708008\t0.1185\n",
      "840\t4.113147258758545\t0.1312\n",
      "841\t3.6343443393707275\t0.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842\t3.574740171432495\t0.1106\n",
      "843\t3.537802219390869\t0.1079\n",
      "844\t7.040840148925781\t0.0944\n",
      "845\t4.069217681884766\t0.104\n",
      "846\t3.348811149597168\t0.0935\n",
      "847\t3.695591926574707\t0.1206\n",
      "848\t3.8270301818847656\t0.1011\n",
      "849\t3.8808112144470215\t0.1365\n",
      "850\t3.49353289604187\t0.1263\n",
      "851\t3.6216282844543457\t0.1278\n",
      "852\t3.261204242706299\t0.1332\n",
      "853\t3.35603666305542\t0.1339\n",
      "854\t3.7005863189697266\t0.1251\n",
      "855\t3.9174134731292725\t0.1088\n",
      "856\t3.4096601009368896\t0.1229\n",
      "857\t3.904186248779297\t0.1366\n",
      "858\t3.3514020442962646\t0.1401\n",
      "859\t4.511240005493164\t0.1239\n",
      "860\t4.234770774841309\t0.1205\n",
      "861\t4.186304569244385\t0.1551\n",
      "862\t4.093225955963135\t0.1288\n",
      "863\t3.710198402404785\t0.1189\n",
      "864\t3.616549015045166\t0.1462\n",
      "865\t3.551891803741455\t0.1349\n",
      "866\t3.7881581783294678\t0.1336\n",
      "867\t3.323939561843872\t0.1244\n",
      "868\t3.6540143489837646\t0.1142\n",
      "869\t3.884939193725586\t0.1357\n",
      "870\t3.5279858112335205\t0.1024\n",
      "871\t3.713823080062866\t0.1145\n",
      "872\t3.917747974395752\t0.147\n",
      "873\t4.324295520782471\t0.1444\n",
      "874\t4.28816556930542\t0.1314\n",
      "875\t3.5879554748535156\t0.1184\n",
      "876\t3.7903223037719727\t0.1187\n",
      "877\t3.8717808723449707\t0.1229\n",
      "878\t3.711318254470825\t0.1215\n",
      "879\t4.314592361450195\t0.1128\n",
      "880\t3.545069932937622\t0.1033\n",
      "881\t3.7235641479492188\t0.1368\n",
      "882\t3.83858060836792\t0.1406\n",
      "883\t3.539257287979126\t0.1301\n",
      "884\t3.4901034832000732\t0.1469\n",
      "885\t3.7928528785705566\t0.1322\n",
      "886\t4.387236595153809\t0.1347\n",
      "887\t4.00874137878418\t0.1405\n",
      "888\t2.5813026428222656\t0.1343\n",
      "889\t4.062050819396973\t0.1365\n",
      "890\t3.4034805297851562\t0.1122\n",
      "891\t3.5712361335754395\t0.1294\n",
      "892\t4.456344127655029\t0.1305\n",
      "893\t3.803093433380127\t0.1157\n",
      "894\t4.011409759521484\t0.1499\n",
      "895\t3.5386881828308105\t0.1494\n",
      "896\t3.356067180633545\t0.1101\n",
      "897\t3.3985934257507324\t0.1402\n",
      "898\t3.750072717666626\t0.1357\n",
      "899\t3.6495957374572754\t0.1363\n",
      "900\t3.767773389816284\t0.1141\n",
      "901\t4.090635299682617\t0.1165\n",
      "902\t3.529747486114502\t0.1409\n",
      "903\t3.9046144485473633\t0.1174\n",
      "904\t4.253521919250488\t0.1312\n",
      "905\t3.2213780879974365\t0.1288\n",
      "906\t3.305046558380127\t0.1399\n",
      "907\t3.7588648796081543\t0.1257\n",
      "908\t5.2511773109436035\t0.1458\n",
      "909\t3.2264113426208496\t0.126\n",
      "910\t4.049945831298828\t0.1338\n",
      "911\t3.550093173980713\t0.1269\n",
      "912\t3.424879550933838\t0.1238\n",
      "913\t3.6254146099090576\t0.1239\n",
      "914\t3.689638376235962\t0.1099\n",
      "915\t3.1593666076660156\t0.1297\n",
      "916\t3.88517689704895\t0.0977\n",
      "917\t3.6249709129333496\t0.1186\n",
      "918\t3.7419960498809814\t0.1419\n",
      "919\t3.7539079189300537\t0.1014\n",
      "920\t3.3784046173095703\t0.1218\n",
      "921\t4.696004867553711\t0.1003\n",
      "922\t3.3314778804779053\t0.1051\n",
      "923\t3.5960071086883545\t0.1115\n",
      "924\t4.614121913909912\t0.1149\n",
      "925\t3.7702996730804443\t0.1268\n",
      "926\t3.6464450359344482\t0.0997\n",
      "927\t4.168426990509033\t0.1159\n",
      "928\t3.1730270385742188\t0.1053\n",
      "929\t3.886803388595581\t0.1033\n",
      "930\t4.264165878295898\t0.0902\n",
      "931\t3.3665213584899902\t0.099\n",
      "932\t3.795675039291382\t0.1224\n",
      "933\t4.594769477844238\t0.1135\n",
      "934\t3.7098147869110107\t0.1293\n",
      "935\t4.106024742126465\t0.1425\n",
      "936\t3.608376979827881\t0.116\n",
      "937\t3.3508448600769043\t0.1293\n",
      "938\t3.9190256595611572\t0.1362\n",
      "939\t4.158244609832764\t0.1236\n",
      "940\t2.363457441329956\t0.1013\n",
      "25823944m: epoch 2 [####################]  100%  loss = 3.581\n",
      "epoch 2 complete, loss = 3.581\n",
      "941\t2.369723320007324\t0.1125\n",
      "942\t4.15231990814209\t0.0954\n",
      "943\t3.419142007827759\t0.1458\n",
      "944\t3.645662307739258\t0.1321\n",
      "945\t3.362238883972168\t0.1336\n",
      "946\t4.149392604827881\t0.1171\n",
      "947\t4.400598049163818\t0.1258\n",
      "948\t3.46882700920105\t0.0942\n",
      "949\t3.8612070083618164\t0.0991\n",
      "950\t4.033749580383301\t0.1611\n",
      "951\t3.5138468742370605\t0.1026\n",
      "952\t4.2239251136779785\t0.1234\n",
      "953\t3.7642602920532227\t0.1304\n",
      "954\t3.5983598232269287\t0.1396\n",
      "955\t3.6616604328155518\t0.1171\n",
      "956\t3.5670166015625\t0.1372\n",
      "957\t3.5877318382263184\t0.1184\n",
      "958\t3.841691732406616\t0.118\n",
      "959\t3.923116445541382\t0.1402\n",
      "960\t3.6098837852478027\t0.1249\n",
      "961\t4.308462619781494\t0.1298\n",
      "962\t3.345775842666626\t0.1213\n",
      "963\t3.4243993759155273\t0.1299\n",
      "964\t3.580791711807251\t0.1347\n",
      "965\t3.7197165489196777\t0.1147\n",
      "966\t2.718130111694336\t0.1003\n",
      "967\t4.0009684562683105\t0.1059\n",
      "968\t3.88311505317688\t0.1177\n",
      "969\t3.7033886909484863\t0.1229\n",
      "970\t4.738832950592041\t0.0946\n",
      "971\t3.5469446182250977\t0.1377\n",
      "972\t3.65454363822937\t0.1265\n",
      "973\t3.783616781234741\t0.1251\n",
      "974\t3.8776814937591553\t0.1154\n",
      "975\t3.4153435230255127\t0.0897\n",
      "976\t3.3018598556518555\t0.1353\n",
      "977\t3.4411959648132324\t0.1199\n",
      "978\t3.2649030685424805\t0.1274\n",
      "979\t3.651482105255127\t0.1108\n",
      "980\t4.2509307861328125\t0.132\n",
      "981\t3.6356756687164307\t0.1228\n",
      "982\t4.14185905456543\t0.1233\n",
      "983\t3.429711103439331\t0.1014\n",
      "984\t3.498185634613037\t0.126\n",
      "985\t3.6141369342803955\t0.1313\n",
      "986\t3.427546262741089\t0.1109\n",
      "987\t3.6966071128845215\t0.124\n",
      "988\t3.2535762786865234\t0.1182\n",
      "989\t3.708214282989502\t0.1339\n",
      "990\t3.5096662044525146\t0.1364\n",
      "991\t3.917982578277588\t0.1572\n",
      "992\t4.036849498748779\t0.1454\n",
      "993\t3.50833797454834\t0.1426\n",
      "994\t3.9210727214813232\t0.1231\n",
      "995\t3.4424688816070557\t0.1237\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '(most'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-54f5f479f5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#torch.cuda.empty_cache()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSRC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-1ce3ca2585d0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, opt, SRC, TRG)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;31m#print(line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mmAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0;31m#print(\"current mAP is\\t\" + str(mAP))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m#print(\"best mAP so far is\\t\" + str(best_mAP))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '(most'"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "model = model.cuda()\n",
    "train_model(model, opt, SRC, TRG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{load_vocab}/model_weights')\n",
    "\n",
    "# x = torch.randn(4,6,1)\n",
    "# print (x)\n",
    "# x = x.view(4, -1)\n",
    "# print (x)\n",
    "# # print(x)\n",
    "# # probs, ix = x[:, :].data.topk(1)\n",
    "# # print(probs)\n",
    "# # print(ix)\n",
    "\n",
    "# x = torch.randn(3,2)\n",
    "# print(x)\n",
    "# y = torch.randn(3,2)\n",
    "# print(y)\n",
    "# print (((x - y)**2).mean())\n",
    "# #F.cosine_embedding_loss(x, y, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(SRC.vocab.itos[4880])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
